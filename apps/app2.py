# ship_app_tab2.py â€”â€” ä»…å¯ç”¨ æŒ‰æ‰˜ç›˜å‘è´§ï¼ˆTab2 çš„é€»è¾‘ï¼Œå»æ‰ Tab1ï¼‰
# åŠŸèƒ½ï¼š
# - æ‰˜ç›˜é‡é‡/ä½“ç§¯ï¼šé‡é‡åªæ¥è‡ªã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹å¹¶æŒ‰æ‰˜ç›˜æ±‚å’Œï¼›ä½“ç§¯ç”±é•¿å®½é«˜ï¼ˆinchï¼‰è®¡ç®—ä¸º CBMï¼ˆæ¯ä¸ªæ‰˜ç›˜åªè®¡ç®—ä¸€æ¬¡ï¼Œé¿å…é‡å¤ï¼‰
# - ETA/ATAï¼ˆåˆå¹¶åˆ—ï¼‰ã€ETD/ATDï¼ˆExcelåºåˆ— 45824 ç­‰ï¼‰â†’ æ—¥æœŸå­—ç¬¦ä¸²
# - å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´å¦‚â€œ19-21â€â†’ ä¸ä»Šå¤©çš„å¤©æ•°å·®ï¼šx-yï¼ˆé”šå®š ETA/ATA çš„æœˆä»½ï¼Œç¼ºå¤±ç”¨å½“æœˆï¼‰
# - å·²å‘æ‰˜ç›˜è¯»å–è‡ªã€å‘è´§è¿½è¸ªã€ï¼Œå†æ¬¡è¿›å…¥é¡µé¢è‡ªåŠ¨éšè—
# - ä¸Šä¼ åˆ°ã€å‘è´§è¿½è¸ªã€åï¼Œè‡ªåŠ¨ã€éƒ¨åˆ†æ›´æ–°ã€‘ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€
#   ä»…æ›´æ–°ä»¥ä¸‹åˆ—ï¼šå®¢æˆ·å•å·ã€å‘å‡º(ETD/ATD)ã€åˆ°æ¸¯(ETA/ATA)ã€åˆ°BCFæ—¥æœŸã€åˆ°BCFå¡è½¦å·ã€åˆ°BCFè´¹ç”¨ã€å‘èµ°æ—¥æœŸã€å‘èµ°å¡è½¦å·ã€å‘èµ°è´¹ç”¨
# - åªé’ˆå¯¹ã€å‘è´§è¿½è¸ªã€é‡Œå‡ºç°è¿‡çš„è¿å•å·è¿›è¡Œæ±‡æ€»/æ›´æ–°
# - å…¼å®¹ã€bolè‡ªææ˜ç»†ã€/ã€å‘è´§è¿½è¸ªã€å®é™…åˆ—åï¼ˆå¡è½¦å·/è´¹ç”¨/æ—¥æœŸ/å®¢æˆ·å•å·ç­‰ï¼‰
# - æ–°å¢ï¼šåœ¨æ‰˜ç›˜å±•ç¤ºä¸­æ˜¾ç¤ºã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹æäº¤æ—¶å†™å…¥çš„ã€æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ / æ‰˜ç›˜åˆ›å»ºæ—¶é—´ã€‘
# - é˜² 429ï¼šé€€é¿é‡è¯• + å±€éƒ¨ç¼“å­˜ bustï¼ˆä¸æ¸…å…¨ç«™ï¼‰

import streamlit as st
import pandas as pd
import numpy as np
import gspread
from google.oauth2.service_account import Credentials
from gspread.exceptions import SpreadsheetNotFound, APIError
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from datetime import datetime, timedelta, date
import calendar
import re
import random, time
import math

# ========= æˆæƒèŒƒå›´ =========
SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

def get_gspread_client():
    # 1) Cloudï¼šä¼˜å…ˆä» st.secrets è¯»å–ï¼ˆStreamlit Cloud é…ç½®çš„æœºå¯†ï¼‰
    if "gcp_service_account" in st.secrets:
        sa_info = st.secrets["gcp_service_account"]  # è¿™æ˜¯ä¸€ä¸ª dictï¼ˆæˆ‘ä»¬ç¨ååœ¨ Cloud é‡Œé…ç½®ï¼‰
        creds = Credentials.from_service_account_info(sa_info, scopes=SCOPES)
        return gspread.authorize(creds)
    # 2) æœ¬åœ°ï¼šå…¼å®¹ä½ åŸæ¥çš„ JSON æ–‡ä»¶
    else:
        creds = Credentials.from_service_account_file("service_accounts.json", scopes=SCOPES)
        return gspread.authorize(creds)

client = get_gspread_client()

# ========= è¡¨åé…ç½® =========
SHEET_ARRIVALS_NAME   = "åˆ°ä»“æ•°æ®è¡¨"       # ETD/ATDã€ETA/ATAï¼ˆåˆå¹¶ï¼‰ã€å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´ã€é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰
SHEET_PALLET_DETAIL   = "æ‰˜ç›˜æ˜ç»†è¡¨"       # æ‰˜ç›˜æ•°æ®ï¼ˆé‡é‡/ä½“ç§¯æ¥è‡ªæ­¤è¡¨ï¼›ä½“ç§¯ç”± L/W/H(inch) è®¡ç®—ä¸º CBMï¼‰
SHEET_SHIP_TRACKING   = "å‘è´§è¿½è¸ªtest"         # æ‰˜ç›˜ç»´åº¦å‡ºä»“è®°å½•ï¼ˆåˆ†æ‘Šåˆ°æ‰˜ç›˜ï¼‰
SHEET_BOL_DETAIL      = "bolè‡ªææ˜ç»†"      # åˆ°BCF æ˜ç»†ï¼ˆåˆ†æ‘Šåˆ°è¿å•ï¼‰
SHEET_WB_SUMMARY      = "è¿å•å…¨é“¾è·¯æ±‡æ€»test"    # ä»…éƒ¨åˆ†æ›´æ–°

# ========= é€šç”¨å·¥å…· =========
def _norm_header(cols):
    return [c.replace("\u00A0"," ").replace("\n","").strip().replace(" ","") for c in cols]

def _to_num(x):
    try: return float(str(x).strip())
    except: return None

def _to_num_safe(x):
    try:
        s = str(x).strip().replace(",","")
        s = re.sub(r"[^\d\.\-]", "", s)
        return float(s)
    except:
        return None

def _is_blank(v):
    try:
        if v is None: return True
        if pd.isna(v): return True
        if isinstance(v, str) and v.strip()=="": return True
        return False
    except Exception:
        try: return bool(pd.isna(v))
        except Exception: return False

# ==== é€€é¿é‡è¯•çš„ get_all_valuesï¼ˆé‡ 429 è‡ªåŠ¨é‡è¯•ï¼‰====
def _safe_get_all_values(ws, value_render_option="UNFORMATTED_VALUE", date_time_render_option="SERIAL_NUMBER"):
    """å¯¹ get_all_values åš 429 é€€é¿é‡è¯•ï¼Œå¹³æ»‘ç¬æ—¶è¯»å³°å€¼ã€‚"""
    backoffs = [0.5, 1.0, 2.0, 4.0, 8.0]  # æœ€å¤š 5 æ¬¡ï¼Œåˆè®¡ ~15s
    for i, delay in enumerate([0.0] + backoffs):
        if delay:
            time.sleep(delay + random.random()*0.2)
        try:
            return ws.get_all_values(
                value_render_option=value_render_option,
                date_time_render_option=date_time_render_option
            )
        except APIError as e:
            msg = str(e)
            if ("Quota exceeded" in msg) or ("Read requests per minute" in msg) or ("429" in msg):
                if i < len(backoffs):
                    continue
            raise

# ==== è½»é‡ bustï¼šåªåˆ·æ–°ç›¸å…³ç¼“å­˜ï¼Œä¸æ¸…å…¨ç«™ ====
def _bust(name: str):
    key = f"_bust_{name}"
    st.session_state[key] = int(st.session_state.get(key, 0)) + 1
    return st.session_state[key]

def _get_bust(name: str) -> int:
    return int(st.session_state.get(f"_bust_{name}", 0))

def _norm_waybill_str(v):
    if _is_blank(v): return ""
    s = str(v).strip()
    if s.endswith(".0"): s = s[:-2]
    try:
        f = float(s)
        if abs(f - round(f)) < 1e-9: s = str(int(round(f)))
    except: pass
    return s

# Excel/GS åºåˆ—èµ·ç‚¹
_BASE = datetime(1899, 12, 30)

def _coerce_excel_serial_sum(v):
    """
    å°† v åˆå¹¶ä¸º Excel/GS åºåˆ—å¤©æ•°ï¼ˆå¯å«å°æ•°ï¼‰ã€‚
    å…¼å®¹å¤šæ ¼å¼ï¼Œè§£æå¤±è´¥è¿”å› None
    """
    try:
        if isinstance(v, (int, float)) and not pd.isna(v):
            return float(v)
    except Exception:
        pass
    if isinstance(v, str):
        s = v.strip()
        s = re.sub(r'[\u00A0\u2000-\u200B]', ' ', s)
        s = s.replace(',', '.')
        nums = re.findall(r'[-+]?\d+(?:\.\d+)?', s)
        total, ok = 0.0, False
        for n in nums:
            try:
                total += float(n); ok = True
            except Exception:
                pass
        if ok: return total
    if isinstance(v, (list, tuple)):
        total, ok = 0.0, False
        for x in v:
            if x is None or (isinstance(x, float) and pd.isna(x)):
                continue
            try:
                xs = str(x).strip().replace(',', '.')
                total += float(xs); ok = True
            except Exception:
                pass
        if ok: return total
    return None

def _parse_sheet_value_to_date(v):
    """æ›´å®‰å…¨çš„å€¼->date è§£æï¼šä¼˜å…ˆçœ‹èµ·æ¥åƒæ—¥æœŸçš„å­—ç¬¦ä¸²ï¼Œå¦åˆ™æŒ‰åºåˆ—æ•°è§£æã€‚"""
    if _is_blank(v): return None
    if isinstance(v, str):
        s = v.strip()
        if any(tok in s for tok in ["-", "/", "å¹´", "æœˆ", "æ—¥", ":"]):
            dt = pd.to_datetime(s, errors="coerce")
            if pd.notna(dt): return dt.date()
    serial = _coerce_excel_serial_sum(v)
    if serial is not None:
        try:
            dt = _BASE + timedelta(days=float(serial))
            return dt.date()
        except Exception:
            pass
    try:
        dt = pd.to_datetime(v, errors="coerce")
        if pd.isna(dt): return None
        return dt.date()
    except Exception:
        return None

def _excel_serial_to_dt(v):
    """å°†ä»»æ„å½¢æ€çš„ Excel/GS åºåˆ—æ•°æˆ–æ—¥æœŸ/æ—¶é—´å­—ç¬¦ä¸²è½¬ä¸º datetimeã€‚"""
    if _is_blank(v): return None
    if isinstance(v, str):
        s = v.strip()
        if any(tok in s for tok in ["-", "/", "å¹´", "æœˆ", "æ—¥", ":"]):
            ts = pd.to_datetime(s, errors="coerce")
            if pd.notna(ts): return ts.to_pydatetime()
    serial = _coerce_excel_serial_sum(v)
    if serial is not None:
        try:
            return _BASE + timedelta(days=float(serial))
        except Exception:
            pass
    try:
        ts = pd.to_datetime(v, errors="coerce")
        if pd.isna(ts): return None
        return ts.to_pydatetime()
    except Exception:
        return None

def _fmt_date(d: date, out_fmt="%Y-%m-%d"):
    return d.strftime(out_fmt) if isinstance(d, date) else ""

def _parse_time_window_days(win: str):
    if not isinstance(win, str): return (None, None)
    s = win.strip()
    if "-" not in s: return (None, None)
    a, b = s.split("-", 1)
    try:
        sa, sb = int(a), int(b)
        if 1 <= sa <= 31 and 1 <= sb <= 31 and sa <= sb:
            return (sa, sb)
    except: pass
    return (None, None)

def _clamp_dom(year, month, dom):
    last = calendar.monthrange(year, month)[1]
    dom = max(1, min(last, dom))
    return date(year, month, dom)

def _promise_diff_days_str(win: str, anchor: date | None):
    sa, sb = _parse_time_window_days(win)
    if sa is None: return ""
    today = date.today()
    if anchor is None: anchor = today
    y, m = anchor.year, anchor.month
    start_d = _clamp_dom(y, m, sa)
    end_d   = _clamp_dom(y, m, sb)
    x = (start_d - today).days
    y2 = (end_d   - today).days
    return f"{x}-{y2}"

def _fmt_time_from_any(v, out_fmt="%H:%M"):
    dt = _excel_serial_to_dt(v)
    return dt.strftime(out_fmt) if isinstance(dt, datetime) else ""

def _split_dt_to_date_time_str(date_raw, time_raw):
    d_dt = _excel_serial_to_dt(date_raw)
    t_dt = _excel_serial_to_dt(time_raw)
    if isinstance(d_dt, datetime):
        date_str = d_dt.date().strftime("%Y-%m-%d")
    elif isinstance(t_dt, datetime):
        date_str = date.today().strftime("%Y-%m-%d")
    else:
        date_str = ""
    time_str = ""
    if isinstance(t_dt, datetime):
        time_str = t_dt.strftime("%H:%M")
    elif isinstance(d_dt, datetime):
        time_str = d_dt.strftime("%H:%M")
    return date_str, time_str

def _split_waybill_list(s):
    if _is_blank(s): return []
    parts = re.split(r"[,\ï¼Œ;\ï¼›ã€\|\/\s]+", str(s))
    return [_norm_waybill_str(p) for p in parts if _norm_waybill_str(p)]

def _first_nonblank_str(s):
    for x in s:
        if not _is_blank(x):
            return str(x).strip()
    return ""

# ========= æ•°æ®è¯»å– =========
@st.cache_data(ttl=300)
def load_arrivals_df(_bust=0):
    ws = client.open(SHEET_ARRIVALS_NAME).sheet1
    data = _safe_get_all_values(
        ws,
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not data: return pd.DataFrame()
    header = _norm_header(data[0])
    df = pd.DataFrame(data[1:], columns=header)

    for need in ["è¿å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡"]:
        if need not in df.columns: df[need] = pd.NA

    vol_col = next((c for c in ["ä½“ç§¯","CBM","ä½“ç§¯m3","ä½“ç§¯(m3)","ä½“ç§¯ï¼ˆm3ï¼‰"] if c in df.columns), None)
    if vol_col is None:
        df["ä½“ç§¯"] = pd.NA
    else:
        df["ä½“ç§¯"] = pd.to_numeric(df[vol_col], errors="coerce")

    etaata_col = None
    for cand in ["ETA/ATA","ETAATA"]:
        if cand in df.columns:
            etaata_col = cand; break
    if "ETD/ATD" not in df.columns: df["ETD/ATD"] = pd.NA
    if "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´" not in df.columns: df["å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´"] = pd.NA

    eta_wh_col = None
    for cand in ["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰","é¢„è®¡åˆ°ä»“æ—¶é—´(æ—¥)","é¢„è®¡åˆ°ä»“æ—¶é—´æ—¥"]:
        if cand in df.columns:
            eta_wh_col = cand; break
    if eta_wh_col is None:
        df["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"] = pd.NA
        eta_wh_col = "é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"

    df["è¿å•å·"] = df["è¿å•å·"].apply(_norm_waybill_str)
    df["ä»“åº“ä»£ç "] = df["ä»“åº“ä»£ç "].astype(str).str.strip()
    df["æ”¶è´¹é‡"] = pd.to_numeric(df["æ”¶è´¹é‡"], errors="coerce")

    if etaata_col is not None:
        df["_ETAATA_date"] = df[etaata_col].apply(_parse_sheet_value_to_date)
        df["ETA/ATA"] = df["_ETAATA_date"].apply(_fmt_date).replace("", pd.NA)
    else:
        df["_ETAATA_date"] = pd.NA
        df["ETA/ATA"] = pd.NA

    df["_ETD_ATD_date"] = df["ETD/ATD"].apply(_parse_sheet_value_to_date)
    df["ETD/ATD"] = df["_ETD_ATD_date"].apply(_fmt_date).replace("", pd.NA)

    df["_ETA_WH_date"] = df[eta_wh_col].apply(_parse_sheet_value_to_date)
    df["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"] = df["_ETA_WH_date"].apply(_fmt_date).replace("", pd.NA)

    df = df.drop_duplicates(subset=["è¿å•å·"], keep="last")

    keep = ["ä»“åº“ä»£ç ","è¿å•å·","æ”¶è´¹é‡","ä½“ç§¯",
            "ETA/ATA","ETD/ATD","å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰",
            "_ETAATA_date"]
    return df[keep]

@st.cache_data(ttl=300)
def load_pallet_detail_df(arrivals_df: pd.DataFrame | None = None, bol_cost_df: pd.DataFrame | None = None, _bust=0):
    """
    æ‰˜ç›˜ç»´åº¦ï¼šä»ã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹èšåˆï¼Œå¹¶ä¸ã€Šåˆ°ä»“æ•°æ®è¡¨ã€‹åŒ¹é…æ—¶é—´/æ‰¿è¯ºå­—æ®µ
    """
    ws = client.open(SHEET_PALLET_DETAIL).sheet1
    vals = _safe_get_all_values(
        ws,
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not vals:
        return pd.DataFrame()

    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)

    if "æ‰˜ç›˜å·" not in df.columns:
        for cand in ["æ‰˜ç›˜ID","æ‰˜ç›˜ç¼–å·","PalletID","PalletNo","palletid","palletno"]:
            if cand in df.columns:
                df = df.rename(columns={cand: "æ‰˜ç›˜å·"})
                break
    if "æ‰˜ç›˜å·" not in df.columns:
        df["æ‰˜ç›˜å·"] = pd.NA

    if "ä»“åº“ä»£ç " not in df.columns:
        df["ä»“åº“ä»£ç "] = pd.NA

    if "è¿å•å·" not in df.columns:
        for cand in ["Waybill","waybill","è¿å•ç¼–å·"]:
            if cand in df.columns:
                df = df.rename(columns={cand: "è¿å•å·"})
                break
    if "è¿å•å·" not in df.columns:
        df["è¿å•å·"] = pd.NA

    df["æ‰˜ç›˜å·"] = df["æ‰˜ç›˜å·"].astype(str).str.strip()
    df["ä»“åº“ä»£ç "] = df["ä»“åº“ä»£ç "].astype(str).str.strip()
    df["è¿å•å·"] = df["è¿å•å·"].apply(_norm_waybill_str)

    weight_col = None
    for cand in ["æ‰˜ç›˜é‡é‡","æ‰˜ç›˜é‡","æ”¶è´¹é‡","æ‰˜ç›˜æ”¶è´¹é‡","è®¡è´¹é‡","è®¡è´¹é‡é‡","é‡é‡"]:
        if cand in df.columns:
            weight_col = cand
            break
    if weight_col is None:
        df["æ‰˜ç›˜é‡é‡"] = pd.NA
        weight_col = "æ‰˜ç›˜é‡é‡"
    df[weight_col] = pd.to_numeric(df[weight_col], errors="coerce")

    len_col = next((c for c in ["æ‰˜ç›˜é•¿","é•¿","é•¿åº¦","Length","length","L"] if c in df.columns), None)
    wid_col = next((c for c in ["æ‰˜ç›˜å®½","å®½","å®½åº¦","Width","width","W"] if c in df.columns), None)
    hei_col = next((c for c in ["æ‰˜ç›˜é«˜","é«˜","é«˜åº¦","Height","height","H"] if c in df.columns), None)

    qty_col = next((c for c in [
        "ç®±æ•°","ç®±","ä»¶æ•°","ç®±ä»¶æ•°","Packages","Package","Cartons","Carton",
        "Qty","QTY","æ•°é‡"
    ] if c in df.columns), None)
    if qty_col is None:
        df["ç®±æ•°"] = pd.NA
        qty_col = "ç®±æ•°"
    df[qty_col] = pd.to_numeric(df[qty_col], errors="coerce")

    INCH_TO_M = 0.0254
    def _cbm_row(r):
        if not all([len_col, wid_col, hei_col]):
            return None
        try:
            L = float(pd.to_numeric(r.get(len_col), errors="coerce"))
            W = float(pd.to_numeric(r.get(wid_col), errors="coerce"))
            H = float(pd.to_numeric(r.get(hei_col), errors="coerce"))
            if L > 0 and W > 0 and H > 0:
                return (L * W * H) * (INCH_TO_M ** 3)
        except Exception:
            pass
        return None
    df["_cbm_row"] = df.apply(_cbm_row, axis=1)

    def _first_valid_num(s):
        s_num = pd.to_numeric(s, errors="coerce").dropna()
        return float(s_num.iloc[0]) if len(s_num) > 0 else None

    def _wb_list(s):
        vals = [x for x in s if isinstance(x, str) and x.strip()]
        return vals

    create_date_col = next((c for c in ["æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ","åˆ›å»ºæ—¥æœŸ","PalletCreateDate","CreateDate"] if c in df.columns), None)
    create_time_col = next((c for c in ["æ‰˜ç›˜åˆ›å»ºæ—¶é—´","åˆ›å»ºæ—¶é—´","PalletCreateTime","CreateTime"] if c in df.columns), None)
    if create_date_col is None:
        df["æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ"] = ""
        create_date_col = "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ"
    if create_time_col is None:
        df["æ‰˜ç›˜åˆ›å»ºæ—¶é—´"] = ""
        create_time_col = "æ‰˜ç›˜åˆ›å»ºæ—¶é—´"

    agg_dict = {
        "æ‰˜ç›˜é‡é‡": (weight_col, _first_valid_num),
        "æ‰˜ç›˜ä½“ç§¯": ("_cbm_row", _first_valid_num),
        "è¿å•æ¸…å•_list": ("è¿å•å·", _wb_list),
        "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ_raw": (create_date_col, _first_nonblank_str),
        "æ‰˜ç›˜åˆ›å»ºæ—¶é—´_raw": (create_time_col, _first_nonblank_str),
    }
    if len_col: agg_dict["æ‰˜ç›˜é•¿in"] = (len_col, _first_valid_num)
    if wid_col: agg_dict["æ‰˜ç›˜å®½in"] = (wid_col, _first_valid_num)
    if hei_col: agg_dict["æ‰˜ç›˜é«˜in"] = (hei_col, _first_valid_num)

    base = (
        df.groupby(["æ‰˜ç›˜å·", "ä»“åº“ä»£ç "], as_index=False, dropna=False)
          .agg(**agg_dict)
    )

    # ä¾èµ–è¡¨ï¼šå°½é‡å¤ç”¨ä¼ å…¥çš„æ•°æ®ï¼Œå‡å°‘é‡å¤è¯»
    arrivals = arrivals_df if arrivals_df is not None else load_arrivals_df(_bust=_get_bust("arrivals"))

    df_join = df.merge(
        arrivals[["è¿å•å·", "ETA/ATA", "ETD/ATD", "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´", "_ETAATA_date"]],
        on="è¿å•å·", how="left"
    )

    # å®¢æˆ·å•å·æ˜ å°„ï¼ˆä¼˜å…ˆæ¥è‡ªã€bolè‡ªææ˜ç»†ã€ï¼‰
    bol_cust_df = bol_cost_df if bol_cost_df is not None else load_bol_waybill_costs(_bust=_get_bust("bol_detail"))
    cust_map = {}
    if not bol_cust_df.empty and "è¿å•å·" in bol_cust_df.columns and "å®¢æˆ·å•å·" in bol_cust_df.columns:
        for _, rr in bol_cust_df.iterrows():
            wb = _norm_waybill_str(rr.get("è¿å•å·", ""))
            cust = str(rr.get("å®¢æˆ·å•å·", "")).strip()
            if wb and cust:
                cust_map[wb] = cust

    pallets = []
    for _, brow in base.iterrows():
        pid, wh = brow["æ‰˜ç›˜å·"], brow["ä»“åº“ä»£ç "]
        if _is_blank(pid):
            continue

        p_wt = brow.get("æ‰˜ç›˜é‡é‡", None)
        p_vol = brow.get("æ‰˜ç›˜ä½“ç§¯", None)

        waybills = brow.get("è¿å•æ¸…å•_list", []) or []
        waybills_disp = []
        for wb in waybills:
            wb_norm = _norm_waybill_str(wb)
            cust = cust_map.get(wb_norm, "")
            waybills_disp.append(f"{wb}({cust})" if cust else f"{wb}")

        create_date_str, create_time_str = _split_dt_to_date_time_str(
            brow.get("æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ_raw", ""),
            brow.get("æ‰˜ç›˜åˆ›å»ºæ—¶é—´_raw", "")
        )

        sub_qty = df[(df["æ‰˜ç›˜å·"] == pid) & (df["ä»“åº“ä»£ç "] == wh)].copy()
        sub_qty["è¿å•å·_norm"] = sub_qty["è¿å•å·"].map(_norm_waybill_str)
        qty_col_local = qty_col
        qty_map = (
            sub_qty.groupby("è¿å•å·_norm")[qty_col_local]
                   .sum(min_count=1)
                   .to_dict()
        )

        waybills_disp_qty = []
        for wb in waybills:
            wb_norm = _norm_waybill_str(wb)
            q = qty_map.get(wb_norm, None)
            if q is None or pd.isna(q):
                q_str = "-"
            else:
                q_str = str(int(q)) if abs(q - round(q)) < 1e-9 else f"{q:.2f}"
            waybills_disp_qty.append(f"{wb}({q_str})")

        sub = df_join[(df_join["æ‰˜ç›˜å·"] == pid) & (df_join["ä»“åº“ä»£ç "] == wh)]
        lines_etaata, lines_etdatd, promised = [], [], []
        diffs_days = []
        for _, r in sub.iterrows():
            wb = r.get("è¿å•å·", "")
            etaata_s = r.get("ETA/ATA", pd.NA)
            etdatd_s = r.get("ETD/ATD", "")
            promise = r.get("å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´", "")
            anchor = r.get("_ETAATA_date", None)
            lines_etaata.append(f"{wb}: ETA/ATA {etaata_s if not _is_blank(etaata_s) else '-'}")
            lines_etdatd.append(f"{wb}: {'' if _is_blank(etdatd_s) else str(etdatd_s)}")
            if not _is_blank(promise):
                diffs_days.append(_promise_diff_days_str(str(promise).strip(), anchor or date.today()))
                promised.append(str(promise).strip())

        readable_etaata = " ; ".join(lines_etaata) if lines_etaata else ""
        readable_etdatd = " ; ".join(lines_etdatd) if lines_etdatd else ""
        promised_set = list(dict.fromkeys([p for p in promised if p]))
        promised_str = " , ".join(promised_set)

        diff_days_str = ""
        if diffs_days:
            def keyfn(s):
                try:
                    a, _ = s.split("-", 1)
                    return int(a)
                except Exception:
                    return 10**9
            diff_days_str = sorted(diffs_days, key=keyfn)[0]

        L_in = brow.get("æ‰˜ç›˜é•¿in", None)
        W_in = brow.get("æ‰˜ç›˜å®½in", None)
        H_in = brow.get("æ‰˜ç›˜é«˜in", None)

        pallets.append({
            "æ‰˜ç›˜å·": pid,
            "ä»“åº“ä»£ç ": wh,
            "æ‰˜ç›˜é‡é‡": float(p_wt) if pd.notna(p_wt) else None,
            "æ‰˜ç›˜ä½“ç§¯": float(p_vol) if p_vol is not None else None,  # mÂ³
            "é•¿(in)": round(float(L_in), 2) if pd.notna(L_in) else None,
            "å®½(in)": round(float(W_in), 2) if pd.notna(W_in) else None,
            "é«˜(in)": round(float(H_in), 2) if pd.notna(H_in) else None,
            "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ": create_date_str,
            "æ‰˜ç›˜åˆ›å»ºæ—¶é—´": create_time_str,
            "è¿å•æ•°é‡": len(waybills),
            "è¿å•æ¸…å•": ", ".join(waybills_disp) if waybills_disp else "",
            "è¿å•ç®±æ•°": ", ".join(waybills_disp_qty) if waybills_disp_qty else "",
            "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´": promised_str,
            "é€ä»“æ—¶æ®µå·®å€¼(å¤©)": diff_days_str,
            "ETA/ATA(æŒ‰è¿å•)": readable_etaata,
            "ETD/ATD(æŒ‰è¿å•)": readable_etdatd,
        })

    out = pd.DataFrame(pallets)
    if out.empty:
        return out
    out = out[out["æ‰˜ç›˜å·"].astype(str).str.strip() != ""].copy()

    for c in ["æ‰˜ç›˜ä½“ç§¯","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)"]:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce")
    out["æ‰˜ç›˜ä½“ç§¯"] = out["æ‰˜ç›˜ä½“ç§¯"].round(2)
    out["é•¿(in)"] = out["é•¿(in)"].round(2)
    out["å®½(in)"] = out["å®½(in)"].round(2)
    out["é«˜(in)"] = out["é«˜(in)"].round(2)

    return out

@st.cache_data(ttl=300)
def load_shipped_pallet_ids(_bust=0):
    try:
        ws = client.open(SHEET_SHIP_TRACKING).sheet1
    except SpreadsheetNotFound:
        return set()
    vals = _safe_get_all_values(ws)
    if not vals: return set()
    raw_header = vals[0]
    norm_header = _norm_header(raw_header)
    norm_header_lower = [h.lower() for h in norm_header]
    candidates = ["æ‰˜ç›˜å·", "æ‰˜ç›˜ç¼–å·", "æ‰˜ç›˜id", "palletid", "palletno", "palletç¼–å·"]
    col_idx = None
    for name in candidates:
        n = name.replace(" ","")
        if n in norm_header: col_idx = norm_header.index(n); break
        if n.lower() in norm_header_lower: col_idx = norm_header_lower.index(n.lower()); break
    if col_idx is None: return set()
    shipped = set()
    for r in vals[1:]:
        if len(r)>col_idx:
            pid = str(r[col_idx]).strip()
            if pid: shipped.add(pid)
    return shipped

@st.cache_data(ttl=300)
def load_bol_waybill_costs(_bust=0):
    try:
        ws = client.open(SHEET_BOL_DETAIL).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame()
    vals = _safe_get_all_values(
        ws,
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not vals:
        return pd.DataFrame()
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header) if len(vals)>1 else pd.DataFrame(columns=header)

    col_wb    = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    col_truck = next((c for c in ["å¡è½¦å•å·","å¡è½¦å·","TruckNo","truckno","Truck","truck"] if c in df.columns), None)
    col_cost  = next((c for c in ["åˆ†æ‘Šè´¹ç”¨","è´¹ç”¨","Amount","amount","cost"] if c in df.columns), None)
    col_date  = next((c for c in ["ETA(åˆ°BCF)","ETAåˆ°BCF","åˆ°BCFETA","æ—¥æœŸ","Date","date"] if c in df.columns), None)
    col_cust  = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)

    if col_wb is None or col_cost is None:
        return pd.DataFrame()

    df[col_wb] = df[col_wb].apply(_norm_waybill_str)
    df[col_cost] = df[col_cost].apply(_to_num_safe)
    if col_truck: df[col_truck] = df[col_truck].astype(str).str.strip()
    if col_cust:  df[col_cust]  = df[col_cust].astype(str).str.strip()
    if col_date:
        df["_date"] = df[col_date].apply(_parse_sheet_value_to_date)
        df[col_date] = df["_date"].apply(_fmt_date).replace("", pd.NA)

    if df.empty:
        return pd.DataFrame()

    agg_dict = {col_cost: "sum"}
    if col_truck:
        agg_dict[col_truck] = lambda s: ", ".join(sorted(set([x.strip() for x in s if not _is_blank(x)])))
    if col_date:
        agg_dict[col_date] = "min"
    if col_cust:
        def _first_nonblank(s):
            for x in s:
                if not _is_blank(x): return x
            return ""
        agg_dict[col_cust] = _first_nonblank

    g = df.groupby(col_wb, dropna=False).agg(agg_dict).reset_index()

    rename_map = {col_wb:"è¿å•å·"}
    if col_truck: rename_map[col_truck] = "åˆ°BCFå¡è½¦å·"
    if col_cost:  rename_map[col_cost]  = "åˆ°BCFè´¹ç”¨"
    if col_date:  rename_map[col_date]  = "åˆ°BCFæ—¥æœŸ"
    if col_cust:  rename_map[col_cust]  = "å®¢æˆ·å•å·"
    g = g.rename(columns=rename_map)
    for c in ["è¿å•å·","å®¢æˆ·å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]:
        if c not in g.columns: g[c] = pd.NA
    g["åˆ°BCFè´¹ç”¨"] = pd.to_numeric(g["åˆ°BCFè´¹ç”¨"], errors="coerce").round(2)
    return g[["è¿å•å·","å®¢æˆ·å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]]

@st.cache_data(ttl=300)
def load_ship_tracking_raw(_bust=0):
    try:
        ws = client.open(SHEET_SHIP_TRACKING).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame()
    vals = _safe_get_all_values(
        ws,
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not vals: return pd.DataFrame()
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header) if len(vals)>1 else pd.DataFrame(columns=header)

    if "æ‰˜ç›˜å·" not in df.columns:
        for c in ["æ‰˜ç›˜ç¼–å·","PalletID","PalletNo","palletid","palletno"]:
            if c in df.columns: df = df.rename(columns={c:"æ‰˜ç›˜å·"}); break
    if "è¿å•æ¸…å•" not in df.columns:
        for c in ["è¿å•å·æ¸…å•","è¿å•åˆ—è¡¨","Waybills","waybills"]:
            if c in df.columns: df = df.rename(columns={c:"è¿å•æ¸…å•"}); break
    if "å¡è½¦å•å·" not in df.columns:
        for c in ["TruckNo","truckno","Truck","truck","å¡è½¦å·"]:
            if c in df.columns: df = df.rename(columns={c:"å¡è½¦å•å·"}); break
    if "åˆ†æ‘Šè´¹ç”¨" not in df.columns:
        for c in ["è´¹ç”¨","Amount","amount","cost"]:
            if c in df.columns: df = df.rename(columns={c:"åˆ†æ‘Šè´¹ç”¨"}); break
    if "æ—¥æœŸ" not in df.columns:
        for c in ["Date","date"]:
            if c in df.columns: df = df.rename(columns={c:"æ—¥æœŸ"}); break

    df["æ‰˜ç›˜å·"]   = df.get("æ‰˜ç›˜å·","").astype(str).str.strip()
    df["å¡è½¦å•å·"] = df.get("å¡è½¦å•å·","").astype(str).str.strip()
    df["åˆ†æ‘Šè´¹ç”¨"] = df.get("åˆ†æ‘Šè´¹ç”¨","").apply(_to_num_safe)
    df["æ—¥æœŸ_raw"] = df.get("æ—¥æœŸ","")
    df["_date"]    = df["æ—¥æœŸ_raw"].apply(_parse_sheet_value_to_date)
    df["æ—¥æœŸ"]     = df["_date"].apply(_fmt_date).replace("", pd.NA)
    df["è¿å•æ¸…å•"] = df.get("è¿å•æ¸…å•","")
    return df[["æ‰˜ç›˜å·","è¿å•æ¸…å•","å¡è½¦å•å·","åˆ†æ‘Šè´¹ç”¨","æ—¥æœŸ"]]

@st.cache_data(ttl=300)
def load_customer_refs_from_arrivals(_bust=0):
    try:
        ws = client.open(SHEET_ARRIVALS_NAME).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    vals = _safe_get_all_values(ws)
    if not vals:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)
    cust_col = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)
    wb_col   = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    if not cust_col or not wb_col:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    out = df[[wb_col, cust_col]].copy()
    out[wb_col] = out[wb_col].apply(_norm_waybill_str)
    out[cust_col] = out[cust_col].astype(str).str.strip()
    out = out.rename(columns={wb_col:"è¿å•å·", cust_col:"å®¢æˆ·å•å·"})
    out = out[out["è¿å•å·"]!=""].drop_duplicates(subset=["è¿å•å·"])
    return out[["è¿å•å·","å®¢æˆ·å•å·"]]

@st.cache_data(ttl=300)
def load_customer_refs_from_pallet(_bust=0):
    try:
        ws = client.open(SHEET_PALLET_DETAIL).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    vals = _safe_get_all_values(ws)
    if not vals:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)
    cust_col = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)
    wb_col   = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    if not cust_col or not wb_col:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    out = df[[wb_col, cust_col]].copy()
    out[wb_col] = out[wb_col].apply(_norm_waybill_str)
    out[cust_col] = out[cust_col].astype(str).str.strip()
    out = out.rename(columns={wb_col:"è¿å•å·", cust_col:"å®¢æˆ·å•å·"})
    out = out[out["è¿å•å·"]!=""].drop_duplicates(subset=["è¿å•å·"])
    return out[["è¿å•å·","å®¢æˆ·å•å·"]]

# ===================== è¿å•å¢é‡æ„å»º =====================
def _extract_pure_waybills(mixed: str) -> list[str]:
    """
    ä»ã€Šå‘è´§è¿½è¸ªã€‹çš„â€œè¿å•æ¸…å•â€å­—æ®µä¸­æå–çº¯è¿å•å·åˆ—è¡¨ã€‚
    """
    if _is_blank(mixed):
        return []
    s = str(mixed).strip()
    s_no_paren = re.sub(r"[\(\ï¼ˆ][\s\S]*?[\)\ï¼‰]", "", s, flags=re.DOTALL).strip()
    if not s_no_paren:
        return []
    parts = re.split(r"[,\ï¼Œ;\ï¼›ã€\|\/\s]+", s_no_paren)
    out = []
    for p in parts:
        if not p:
            continue
        token = _norm_waybill_str(p)
        if not token:
            continue
        if token.upper().startswith("IP"):
            continue
        if not (re.search(r"[A-Za-z]", token) and re.search(r"\d", token) and len(token) >= 8):
            continue
        out.append(token)
    return out

def build_waybill_delta():
    """
    èšåˆåˆ°â€œè¿å•ç²’åº¦â€çš„å¢é‡æ•°æ®ï¼Œä¾›éƒ¨åˆ†æ›´æ–°ã€Šè¿å•å…¨é“¾è·¯æ±‡æ€»ã€‹
    """
    arrivals = load_arrivals_df(_bust=_get_bust("arrivals"))
    bol      = load_bol_waybill_costs(_bust=_get_bust("bol_detail"))
    track    = load_ship_tracking_raw(_bust=_get_bust("ship_tracking"))

    wb_from_track = set()
    for _, r in track.iterrows():
        for wb in _extract_pure_waybills(r.get("è¿å•æ¸…å•", "")):
            if wb: wb_from_track.add(wb)

    if not wb_from_track:
        return pd.DataFrame(columns=[
            "è¿å•å·","å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
            "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
            "åˆ°BCFæ—¥æœŸ","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ",
            "åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
            "å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
        ])

    arrivals = arrivals[arrivals["è¿å•å·"].isin(wb_from_track)].copy()
    if not bol.empty:
        bol = bol[bol["è¿å•å·"].isin(wb_from_track)].copy()

    weight_map = dict(zip(
        arrivals["è¿å•å·"],
        pd.to_numeric(arrivals["æ”¶è´¹é‡"], errors="coerce")
    ))

    wb2_cost, wb2_trucks, wb2_date = {}, {}, {}
    for _, r in track.iterrows():
        waybills = _extract_pure_waybills(r.get("è¿å•æ¸…å•", ""))
        waybills = [wb for wb in waybills if wb in wb_from_track]
        if not waybills:
            continue
        pallet_cost = _to_num_safe(r.get("åˆ†æ‘Šè´¹ç”¨"))
        truck_no    = r.get("å¡è½¦å•å·", "")
        dt_str      = r.get("æ—¥æœŸ", None)
        dt_obj      = _parse_sheet_value_to_date(dt_str) if not _is_blank(dt_str) else None

        weights = [weight_map.get(wb, None) for wb in waybills]
        valid   = [w for w in weights if w and w > 0]
        if valid and sum(valid) > 0:
            total_w = sum(valid)
            shares  = [(w/total_w if (w and w > 0) else 0.0) for w in weights]
        else:
            shares  = [1.0/len(waybills)] * len(waybills)

        if pallet_cost is not None:
            for wb, s in zip(waybills, shares):
                wb2_cost[wb] = wb2_cost.get(wb, 0.0) + pallet_cost * s
        if truck_no:
            for wb in waybills:
                wb2_trucks.setdefault(wb, set()).add(truck_no)
        if dt_obj:
            for wb in waybills:
                if (wb not in wb2_date) or (dt_obj < wb2_date[wb]):
                    wb2_date[wb] = dt_obj

    out = pd.DataFrame({"è¿å•å·": sorted(wb_from_track)})

    if not arrivals.empty:
        arr2 = arrivals[["è¿å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯","ETD/ATD","ETA/ATA","é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"]].copy()
        arr2 = arr2.rename(columns={
            "ETD/ATD": "å‘å‡º(ETD/ATD)",
            "ETA/ATA": "åˆ°æ¸¯(ETA/ATA)",
            "é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰": "åˆ°ä»“æ—¥æœŸ"
        })
        out = out.merge(arr2, on="è¿å•å·", how="left")
    else:
        out["ä»“åº“ä»£ç "] = pd.NA
        out["æ”¶è´¹é‡"] = pd.NA
        out["ä½“ç§¯"]   = pd.NA
        out["å‘å‡º(ETD/ATD)"] = pd.NA
        out["åˆ°æ¸¯(ETA/ATA)"] = pd.NA
        out["åˆ°ä»“æ—¥æœŸ"]       = pd.NA

    cust_bol = bol[["è¿å•å·","å®¢æˆ·å•å·"]] if (not bol.empty and "å®¢æˆ·å•å·" in bol.columns) \
               else pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    cust_pal = load_customer_refs_from_pallet(_bust=_get_bust("pallet_detail"))
    cust_arr = load_customer_refs_from_arrivals(_bust=_get_bust("arrivals"))
    for d in (cust_pal, cust_arr):
        if not d.empty:
            d.drop_duplicates(subset=["è¿å•å·"], inplace=True)
            d["è¿å•å·"] = d["è¿å•å·"].map(_norm_waybill_str)
    cust_all = pd.concat([cust_bol.assign(_pri=1), cust_pal.assign(_pri=2), cust_arr.assign(_pri=3)], ignore_index=True)
    if not cust_all.empty:
        cust_all = cust_all[cust_all["è¿å•å·"].isin(wb_from_track)]
        cust_all = cust_all[~cust_all["å®¢æˆ·å•å·"].isna() & (cust_all["å®¢æˆ·å•å·"].astype(str)!="")]
        cust_all = (cust_all.sort_values(["è¿å•å·","_pri"])
                            .drop_duplicates(subset=["è¿å•å·"], keep="first")[["è¿å•å·","å®¢æˆ·å•å·"]])
        out = out.merge(cust_all, on="è¿å•å·", how="left")
    else:
        out["å®¢æˆ·å•å·"] = pd.NA

    if not bol.empty:
        out = out.merge(bol[["è¿å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]], on="è¿å•å·", how="left")
    else:
        for c in ["åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]:
            out[c] = pd.NA

    out["å‘èµ°è´¹ç”¨"]   = out["è¿å•å·"].map(lambda wb: round(wb2_cost.get(wb, 0.0), 2) if wb in wb2_cost else pd.NA)
    out["å‘èµ°å¡è½¦å·"] = out["è¿å•å·"].map(lambda wb: ", ".join(sorted(wb2_trucks.get(wb, []))) if wb in wb2_trucks else pd.NA)
    out["å‘èµ°æ—¥æœŸ"]   = out["è¿å•å·"].map(lambda wb: _fmt_date(wb2_date.get(wb)) if wb in wb2_date else pd.NA)

    out["æ”¶è´¹é‡"]   = pd.to_numeric(out["æ”¶è´¹é‡"], errors="coerce")
    out["ä½“ç§¯"]     = pd.to_numeric(out["ä½“ç§¯"], errors="coerce").round(2)
    out["åˆ°BCFè´¹ç”¨"] = pd.to_numeric(out["åˆ°BCFè´¹ç”¨"], errors="coerce").round(2)
    out["å‘èµ°è´¹ç”¨"]  = pd.to_numeric(out["å‘èµ°è´¹ç”¨"], errors="coerce").round(2)

    final_cols = [
        "è¿å•å·","å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
        "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
        "åˆ°BCFæ—¥æœŸ","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ",
        "åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
        "å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
    ]
    for c in final_cols:
        if c not in out.columns:
            out[c] = pd.NA
    return out[final_cols]

MANAGED_COLS = [
    "è¿å•å·","å®¢æˆ·å•å·","å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
    "åˆ°BCFæ—¥æœŸ","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
    "å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯"
]

def _is_effective(v):
    if v is None: return False
    if isinstance(v, float) and pd.isna(v): return False
    if isinstance(v, str) and v.strip() == "": return False
    return True

def _to_jsonable_cell(v):
    try:
        if v is None or pd.isna(v):
            return ""
    except Exception:
        if v is None:
            return ""
    if isinstance(v, (np.integer,)):
        return int(v)
    if isinstance(v, (np.floating,)):
        return "" if np.isnan(v) or np.isinf(v) else float(v)
    if isinstance(v, float):
        return "" if (math.isnan(v) or math.isinf(v)) else v
    return v if isinstance(v, (str, int, float, bool)) else str(v)

def upsert_waybill_summary_partial(df_delta: pd.DataFrame):
    """
    åªå¯¹ MANAGED_COLS åšâ€œå®šç‚¹å€¼æ›´æ–°â€æˆ–â€œè¿½åŠ æ–°è¡Œâ€ï¼Œå¹¶åŠ å…¥ã€å†™å…¥ç­–ç•¥ã€ä¿æŠ¤äººå·¥ä¿®æ”¹ï¼š
      - blank_onlyï¼šä»…å½“ç›®æ ‡å•å…ƒæ ¼ä¸ºç©ºæ—¶æ‰å†™
      - merge_setï¼šæŠŠæ–°æ—§å­—ç¬¦ä¸²æŒ‰åˆ†éš”ç¬¦åˆå¹¶å»é‡
      - default  ï¼šæœ‰æœ‰æ•ˆå€¼å°±å†™ã€ç©ºå€¼ä¸å†™
    """
    WRITE_POLICY = {
        "åˆ°ä»“æ—¥æœŸ": "blank_only",
        "å‘èµ°æ—¥æœŸ": "blank_only",
        "åˆ°BCFæ—¥æœŸ": "blank_only",
        "åˆ°BCFè´¹ç”¨": "blank_only",
        "å‘èµ°è´¹ç”¨": "blank_only",
        "åˆ°BCFå¡è½¦å·": "merge_set",
        "å‘èµ°å¡è½¦å·": "merge_set",
        "ä»“åº“ä»£ç ": "blank_only",
        "å®¢æˆ·å•å·": "blank_only",
    }
    MERGE_SEP = ","

    def _cell_blank(x):
        return (x is None) or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and x.strip()=="")

    def _merge_set(old, new):
        def toks(s):
            if _cell_blank(s): return []
            parts = re.split(r"[,\ï¼Œ;\ï¼›\|/ ]+", str(s).strip())
            return [p for p in parts if p]
        seen = []
        for t in toks(old) + toks(new):
            if t not in seen:
                seen.append(t)
        return MERGE_SEP.join(seen)

    try:
        ws = client.open(SHEET_WB_SUMMARY).sheet1
    except SpreadsheetNotFound:
        st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_WB_SUMMARY}ã€ã€‚è¯·å…ˆåˆ›å»ºå¹¶åœ¨ç¬¬1è¡Œå†™å…¥è¡¨å¤´ï¼ˆè‡³å°‘åŒ…å«ï¼šè¿å•å·ï¼‰ã€‚")
        return False

    vals = _safe_get_all_values(ws, value_render_option="UNFORMATTED_VALUE", date_time_render_option="SERIAL_NUMBER")
    if not vals or not vals[0]:
        st.error("ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ä¸ºç©ºä¸”æ— è¡¨å¤´ã€‚è¯·å…ˆåœ¨ç¬¬ä¸€è¡Œå†™å¥½è¡¨å¤´ï¼ˆè‡³å°‘åŒ…å«ï¼šè¿å•å·ï¼‰ã€‚")
        return False

    header = list(vals[0])
    if "è¿å•å·" not in header:
        st.error("ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ç¼ºå°‘â€œè¿å•å·â€è¡¨å¤´ï¼Œæ— æ³•æ›´æ–°ã€‚")
        return False

    df_delta = df_delta.copy()
    if "è¿å•å·" not in df_delta.columns:
        st.error("å¢é‡æ•°æ®ç¼ºå°‘â€œè¿å•å·â€ã€‚")
        return False
    df_delta["è¿å•å·"] = df_delta["è¿å•å·"].map(_norm_waybill_str)

    missing_cols = [c for c in MANAGED_COLS if c not in header]
    if missing_cols:
        ws.update(f"{ws.title}!1:1", [header + missing_cols], value_input_option="USER_ENTERED")
        header = header + missing_cols

    exist_df = pd.DataFrame(vals[1:], columns=header) if len(vals) > 1 else pd.DataFrame(columns=header)
    if "è¿å•å·" not in exist_df.columns:
        exist_df["è¿å•å·"] = ""
    exist_df["è¿å•å·"] = exist_df["è¿å•å·"].map(_norm_waybill_str)
    exist_df["_rowno"] = np.arange(2, 2 + len(exist_df))

    idx_exist = exist_df.set_index("è¿å•å·", drop=False)
    idx_delta = df_delta.set_index("è¿å•å·", drop=False)

    common  = idx_delta.index.intersection(idx_exist.index)
    new_ids = list(idx_delta.index.difference(idx_exist.index))

    updates = []

    for col in MANAGED_COLS:
        if col == "è¿å•å·":
            continue
        if col not in header or col not in idx_delta.columns:
            continue
        col_idx = header.index(col) + 1

        rows_payload = []
        policy = WRITE_POLICY.get(col, "default")

        for wb in common:
            new_v = idx_delta.loc[wb, col]
            if not _is_effective(new_v):
                continue
            rno = int(idx_exist.loc[wb, "_rowno"])
            old_v = idx_exist.loc[wb, col] if col in idx_exist.columns else ""

            if policy == "blank_only":
                if not _cell_blank(old_v):
                    continue
                write_v = new_v
            elif policy == "merge_set":
                write_v = _merge_set(old_v, new_v)
            else:
                write_v = new_v

            rows_payload.append((rno, [_to_jsonable_cell(write_v)]))

        if not rows_payload:
            continue

        rows_payload.sort(key=lambda x: x[0])
        s = p = None
        buf = []
        for r, val in rows_payload:
            if s is None:
                s = p = r; buf = [val]
            elif r == p + 1:
                p = r; buf.append(val)
            else:
                a1_start = gspread.utils.rowcol_to_a1(s, col_idx)
                a1_end   = gspread.utils.rowcol_to_a1(p, col_idx)
                updates.append({"range": f"{ws.title}!{a1_start}:{a1_end}", "values": buf})
                s = p = r; buf = [val]
        if s is not None:
            a1_start = gspread.utils.rowcol_to_a1(s, col_idx)
            a1_end   = gspread.utils.rowcol_to_a1(p, col_idx)
            updates.append({"range": f"{ws.title}!{a1_start}:{a1_end}", "values": buf})

    if updates:
        ws.spreadsheet.values_batch_update(body={"valueInputOption": "USER_ENTERED", "data": updates})

    if new_ids:
        cols_out = [c for c in header if c in MANAGED_COLS]
        if "è¿å•å·" not in cols_out:
            cols_out = ["è¿å•å·"] + cols_out

        new_rows = []
        for wb in new_ids:
            row_dict = {c: "" for c in header}
            row_dict["è¿å•å·"] = wb
            for c in MANAGED_COLS:
                if c == "è¿å•å·" or c not in header:
                    continue
                if c in idx_delta.columns:
                    v = idx_delta.loc[wb, c]
                    if _is_effective(v):
                        if WRITE_POLICY.get(c) == "merge_set":
                            v = v  # æ–°è¡Œæ˜¯ç©ºï¼Œç­‰åŒç›´æ¥å†™
                        row_dict[c] = _to_jsonable_cell(v)
            new_rows.append([row_dict.get(c, "") for c in header])

        if new_rows:
            ws.append_rows(new_rows, value_input_option="USER_ENTERED")

    return True

# ========= UIï¼šä»…å¯ç”¨â€œæŒ‰æ‰˜ç›˜å‘è´§â€ + ã€ŒæŒ‰å¡è½¦å›å¡«åˆ°ä»“æ—¥æœŸã€ =========
st.set_page_config(page_title="BCF å‘è´§è°ƒåº¦ï¼ˆä»…æ‰˜ç›˜ï¼‰", layout="wide")
st.title("ğŸšš BCF å‘è´§è°ƒåº¦ï¼ˆä»…æ‰˜ç›˜ï¼‰")

# ======= ä¸Šä¼ æŒ‰é’®æ”¾å¤§ + é«˜äº®æ ·å¼ï¼ˆå…¨å±€ï¼‰=======
st.markdown("""
    <style>
    div.stButton > button[kind="secondary"] {
        font-size: 28px !important;
        font-weight: 900 !important;
        padding: 0.8em 1.6em !important;
        background-color: #ff9800 !important;
        color: white !important;
        border-radius: 10px !important;
        border: 3px solid #e65100 !important;
    }
    </style>
""", unsafe_allow_html=True)

tab1, tab2 = st.tabs(["æŒ‰æ‰˜ç›˜å‘è´§","æŒ‰å¡è½¦å›å¡«åˆ°ä»“æ—¥æœŸ"])

with tab1:
    # åˆ·æ–°
    c1,_ = st.columns([1,6])
    with c1:
        if st.button("ğŸ”„ åˆ·æ–°æ‰˜ç›˜æ•°æ®ç¼“å­˜", key="btn_refresh_pallet"):
            # å±€éƒ¨ bust æ‰˜ç›˜æ˜ç»†ï¼Œä¸æ¸…å…¨ç«™
            _bust("pallet_detail")
            st.rerun()

    # å¯é€‰ï¼šå…ˆè¯»ä¾èµ–è¡¨ï¼Œå†æ³¨å…¥åˆ°æ‰˜ç›˜è¯»å–ï¼Œå‡å°‘é‡å¤è¯»
    arrivals_df = load_arrivals_df(_bust=_get_bust("arrivals"))
    bol_df      = load_bol_waybill_costs(_bust=_get_bust("bol_detail"))
    pallet_df   = load_pallet_detail_df(arrivals_df=arrivals_df, bol_cost_df=bol_df, _bust=_get_bust("pallet_detail"))

    if pallet_df.empty:
        st.warning("æœªä»ã€æ‰˜ç›˜æ˜ç»†è¡¨ã€è¯»å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥è¡¨å/æƒé™/è¡¨å¤´ã€‚")
        st.stop()

    shipped_pallets = load_shipped_pallet_ids(_bust=_get_bust("ship_tracking"))
    if shipped_pallets:
        pallet_df = pallet_df[~pallet_df["æ‰˜ç›˜å·"].isin(shipped_pallets)]

    if pallet_df.empty:
        st.info("å½“å‰å¯å‘è´§çš„æ‰˜ç›˜ä¸ºç©ºï¼ˆå¯èƒ½éƒ½å·²è®°å½•åœ¨ã€å‘è´§è¿½è¸ªã€ï¼‰ã€‚")
        st.stop()

    # ä»“åº“ç­›é€‰
    wh_opts = ["ï¼ˆå…¨éƒ¨ï¼‰"] + sorted([w for w in pallet_df["ä»“åº“ä»£ç "].dropna().unique() if str(w).strip()])
    wh_pick = st.selectbox("é€‰æ‹©ä»“åº“ä»£ç ï¼ˆå¯é€‰ï¼‰", options=wh_opts, key="wh_pallet")
    if wh_pick != "ï¼ˆå…¨éƒ¨ï¼‰":
        pallet_df = pallet_df[pallet_df["ä»“åº“ä»£ç "]==wh_pick]

    # è¡¨æ ¼ä¸å‹¾é€‰
    show_cols = [
        "æ‰˜ç›˜å·","ä»“åº“ä»£ç ","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)","æ‰˜ç›˜ä½“ç§¯",
        "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ","æ‰˜ç›˜åˆ›å»ºæ—¶é—´",
        "è¿å•æ•°é‡","è¿å•æ¸…å•","è¿å•ç®±æ•°",
        "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é€ä»“æ—¶æ®µå·®å€¼(å¤©)",
        "ETA/ATA(æŒ‰è¿å•)","ETD/ATD(æŒ‰è¿å•)"
    ]
    for c in show_cols:
        if c not in pallet_df.columns:
            pallet_df[c] = ""

    disp_df = pallet_df.copy().reset_index(drop=True)
    for c in ["æ‰˜ç›˜ä½“ç§¯","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)"]:
        disp_df[c] = pd.to_numeric(disp_df.get(c, pd.Series()), errors="coerce")
    disp_df["æ‰˜ç›˜ä½“ç§¯"] = disp_df["æ‰˜ç›˜ä½“ç§¯"].round(2)
    disp_df["é•¿(in)"] = disp_df["é•¿(in)"].round(2)
    disp_df["å®½(in)"] = disp_df["å®½(in)"].round(2)
    disp_df["é«˜(in)"] = disp_df["é«˜(in)"].round(2)

    if "é€‰æ‹©" not in disp_df.columns:
        disp_df["é€‰æ‹©"] = False
    cols_order = ["é€‰æ‹©"] + show_cols

    if "sel_locked" not in st.session_state:
        st.session_state.sel_locked = False
    if "locked_df" not in st.session_state:
        st.session_state.locked_df = pd.DataFrame()

    if not st.session_state.sel_locked:
        with st.form("pick_pallets_form", clear_on_submit=False):
            edited_pal = st.data_editor(
                disp_df[cols_order],
                hide_index=True,
                use_container_width=True,
                height=500,
                column_config={"é€‰æ‹©": st.column_config.CheckboxColumn("é€‰æ‹©")},
                disabled=[c for c in show_cols],
                key="pallet_select_editor"
            )
            submitted = st.form_submit_button("ğŸ”’ é”å®šé€‰æ‹©å¹¶è¿›å…¥è®¡ç®—")
        if submitted:
            selected_pal = edited_pal[edited_pal["é€‰æ‹©"]==True].copy()
            if len(selected_pal) == 0:
                st.warning("è¯·è‡³å°‘å‹¾é€‰ä¸€ä¸ªæ‰˜ç›˜å†ç‚¹å‡»ã€é”å®šé€‰æ‹©å¹¶è¿›å…¥è®¡ç®—ã€ã€‚")
                st.stop()
            st.session_state.locked_df = selected_pal.reset_index(drop=True)
            st.session_state.all_snapshot_df = disp_df[cols_order].copy()
            st.session_state.sel_locked = True
            st.rerun()

    if st.session_state.sel_locked:
        st.success("âœ… å·²é”å®šæ‰˜ç›˜é€‰æ‹©")
        if st.button("ğŸ”“ é‡æ–°é€‰æ‹©"):
            st.session_state.sel_locked = False
            st.session_state.locked_df = pd.DataFrame()
            st.rerun()

        selected_pal = st.session_state.locked_df.copy()
        locked_ids = set(selected_pal["æ‰˜ç›˜å·"].astype(str))
        others_df = disp_df[~disp_df["æ‰˜ç›˜å·"].astype(str).isin(locked_ids)].copy()
        if "é€‰æ‹©" in others_df.columns:
            others_df["é€‰æ‹©"] = False

        left, right = st.columns([2, 2], gap="large")
        with left:
            st.markdown("**ğŸ“¦ å·²é”å®šæ‰˜ç›˜ï¼ˆç”¨äºè®¡ç®—ï¼‰**")
            st.dataframe(
                selected_pal[cols_order],
                use_container_width=True,
                height=320
            )
            st.caption(f"å·²é”å®šæ•°é‡ï¼š{len(selected_pal)}")
        with right:
            st.markdown("**ğŸ—‚ å…¶ä»–æ‰˜ç›˜ï¼ˆæœªé”å®šï¼Œä»…æŸ¥çœ‹ï¼‰**")
            st.dataframe(
                others_df[cols_order],
                use_container_width=True,
                height=320
            )
            st.caption(f"æœªé”å®šæ•°é‡ï¼š{len(others_df)}")

        sel_count = int(len(selected_pal))
        sel_vol_sum = pd.to_numeric(selected_pal.get("æ‰˜ç›˜ä½“ç§¯", pd.Series()), errors="coerce").sum()
        m1, m2 = st.columns(2)
        with m1: st.metric("å·²é€‰æ‹©æ‰˜ç›˜æ•°", sel_count)
        with m2: st.metric("é€‰ä¸­ä½“ç§¯åˆè®¡ï¼ˆCBMï¼‰", round(float(sel_vol_sum or 0.0), 2))

        if sel_count == 0:
            st.info("å½“å‰æ²¡æœ‰é”å®šçš„æ‰˜ç›˜ã€‚ç‚¹å‡»ã€é‡æ–°é€‰æ‹©ã€è¿”å›ã€‚")
            st.stop()

        st.subheader("ğŸ§¾ è½¦æ¬¡ä¿¡æ¯ï¼ˆæ‰˜ç›˜ç»´åº¦åˆ†æ‘Šï¼‰")
        cc1, cc2 = st.columns([2,2])
        with cc1:
            pallet_truck_no = st.text_input("å¡è½¦å•å·ï¼ˆå¿…å¡«ï¼‰", key="pallet_truck_no")
        with cc2:
            pallet_total_cost = st.number_input("æœ¬è½¦æ€»è´¹ç”¨ï¼ˆå¿…å¡«ï¼‰", min_value=0.0, step=1.0, format="%.2f", key="pallet_total_cost")

        if not pallet_truck_no or pallet_total_cost <= 0:
            st.info("è¯·å¡«å†™å¡è½¦å•å·ä¸æœ¬è½¦æ€»è´¹ç”¨ã€‚")
            st.stop()

        selected_pal["æ‰˜ç›˜é‡é‡"] = pd.to_numeric(selected_pal["æ‰˜ç›˜é‡é‡"], errors="coerce")
        weights = selected_pal["æ‰˜ç›˜é‡é‡"]
        if weights.isna().any() or (weights.dropna() <= 0).any():
            st.error("æ‰€é€‰æ‰˜ç›˜å­˜åœ¨ç¼ºå¤±æˆ–éæ­£çš„ã€æ‰˜ç›˜é‡é‡ã€ï¼Œæ— æ³•åˆ†æ‘Šã€‚è¯·å…ˆåœ¨ã€æ‰˜ç›˜æ˜ç»†è¡¨ã€ä¿®æ­£ã€‚")
            st.stop()

        wt_sum = float(weights.sum())
        if wt_sum <= 0:
            st.error("æ€»æ‰˜ç›˜é‡é‡ä¸º 0ï¼Œæ— æ³•åˆ†æ‘Šã€‚")
            st.stop()

        selected_pal["åˆ†æ‘Šæ¯”ä¾‹"] = weights / wt_sum
        selected_pal["åˆ†æ‘Šè´¹ç”¨_raw"] = selected_pal["åˆ†æ‘Šæ¯”ä¾‹"] * float(pallet_total_cost)
        selected_pal["åˆ†æ‘Šè´¹ç”¨"] = selected_pal["åˆ†æ‘Šè´¹ç”¨_raw"].round(2)
        diff_cost = round(float(pallet_total_cost) - selected_pal["åˆ†æ‘Šè´¹ç”¨"].sum(), 2)
        if abs(diff_cost) >= 0.01:
            selected_pal.loc[selected_pal.index[-1], "åˆ†æ‘Šè´¹ç”¨"] += diff_cost

        upload_df = selected_pal.copy()
        upload_df["å¡è½¦å•å·"] = pallet_truck_no
        upload_df["æ€»è´¹ç”¨"] = round(float(pallet_total_cost), 2)
        upload_df["åˆ†æ‘Šæ¯”ä¾‹"] = (upload_df["åˆ†æ‘Šæ¯”ä¾‹"]*100).round(2).astype(str) + "%"
        upload_df["åˆ†æ‘Šè´¹ç”¨"] = upload_df["åˆ†æ‘Šè´¹ç”¨"].map(lambda x: f"{x:.2f}")
        upload_df["æ€»è´¹ç”¨"] = upload_df["æ€»è´¹ç”¨"].map(lambda x: f"{x:.2f}")
        upload_df["æ‰˜ç›˜ä½“ç§¯"] = pd.to_numeric(upload_df.get("æ‰˜ç›˜ä½“ç§¯", pd.Series()), errors="coerce").round(2)

        preview_cols_pal = [
            "å¡è½¦å•å·","ä»“åº“ä»£ç ","æ‰˜ç›˜å·","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)","æ‰˜ç›˜ä½“ç§¯",
            "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ","æ‰˜ç›˜åˆ›å»ºæ—¶é—´",
            "è¿å•æ•°é‡","è¿å•æ¸…å•",
            "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é€ä»“æ—¶æ®µå·®å€¼(å¤©)",
            "ETA/ATA(æŒ‰è¿å•)","ETD/ATD(æŒ‰è¿å•)",
            "åˆ†æ‘Šæ¯”ä¾‹","åˆ†æ‘Šè´¹ç”¨","æ€»è´¹ç”¨"
        ]
        for c in preview_cols_pal:
            if c not in upload_df.columns:
                upload_df[c] = ""

        st.subheader("âœ… ä¸Šä¼ é¢„è§ˆï¼ˆæ‰˜ç›˜ â†’ å‘è´§è¿½è¸ªï¼‰")
        st.dataframe(upload_df[preview_cols_pal], use_container_width=True, height=360)

        st.markdown("""
        **åˆ†æ‘Šæ¯”ä¾‹è®¡ç®—å…¬å¼ï¼š** æ¯ä¸ªæ‰˜ç›˜çš„åˆ†æ‘Šæ¯”ä¾‹ = è¯¥æ‰˜ç›˜é‡é‡ Ã· æ‰€æœ‰é€‰ä¸­æ‰˜ç›˜é‡é‡æ€»å’Œ  
        **åˆ†æ‘Šè´¹ç”¨è®¡ç®—å…¬å¼ï¼š** æ¯ä¸ªæ‰˜ç›˜çš„åˆ†æ‘Šè´¹ç”¨ = åˆ†æ‘Šæ¯”ä¾‹ Ã— æœ¬è½¦æ€»è´¹ç”¨  
        ï¼ˆæœ€åä¸€æ‰˜ç›˜è‡ªåŠ¨è°ƒæ•´å‡ åˆ†é’±å·®é¢ï¼Œç¡®ä¿æ€»é¢=æœ¬è½¦æ€»è´¹ç”¨ï¼‰
        """)

        if st.button("ğŸ“¤ è¿½åŠ ä¸Šä¼ åˆ°ã€å‘è´§è¿½è¸ªã€", key="btn_upload_pallet"):
            try:
                ss = client.open(SHEET_SHIP_TRACKING); ws_track = ss.sheet1
            except SpreadsheetNotFound:
                st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_SHIP_TRACKING}ã€ã€‚è¯·å…ˆåœ¨ Google Drive ä¸­åˆ›å»ºï¼Œå¹¶è®¾ç½®ç¬¬ä¸€è¡Œè¡¨å¤´ã€‚")
                st.stop()

            exist = _safe_get_all_values(ws_track)
            if not exist:
                st.error("ç›®æ ‡è¡¨ä¸ºç©ºä¸”æ— è¡¨å¤´ã€‚è¯·å…ˆåœ¨ç¬¬ä¸€è¡Œå†™å¥½è¡¨å¤´ï¼ˆæ ‡é¢˜è¡Œï¼‰ã€‚")
                st.stop()

            header_raw = exist[0]
            header_norm = _norm_header(header_raw)
            header_norm_lower = [h.lower() for h in header_norm]
            need_ok = any(n in header_norm for n in ["æ‰˜ç›˜å·","æ‰˜ç›˜ç¼–å·"]) or \
                      any(n in header_norm_lower for n in ["palletid","palletno","palletç¼–å·"])
            if not need_ok:
                st.error("ã€å‘è´§è¿½è¸ªã€ç¼ºå°‘â€œæ‰˜ç›˜å·â€åˆ—ï¼ˆæˆ–ç­‰ä»·åˆ—å¦‚ PalletID/PalletNoï¼‰ã€‚è¯·å…ˆåœ¨ç›®æ ‡è¡¨å¢åŠ è¯¥åˆ—ã€‚")
                st.stop()

            tmp = upload_df.copy()
            if ("æ—¥æœŸ" in header_raw) and ("æ—¥æœŸ" not in tmp.columns):
                tmp["æ—¥æœŸ"] = datetime.today().strftime("%Y-%m-%d")

            for col in header_raw:
                if col not in tmp.columns:
                    tmp[col] = ""
            rows = tmp.reindex(columns=header_raw).fillna("").values.tolist()

            ws_track.append_rows(rows, value_input_option="USER_ENTERED")
            st.success(f"å·²ä¸Šä¼  {len(rows)} æ¡åˆ°ã€{SHEET_SHIP_TRACKING}ã€ã€‚å¡è½¦å•å·ï¼š{pallet_truck_no}")

            # === ä¸Šä¼ æˆåŠŸåï¼šä»…å±€éƒ¨åˆ·æ–°ï¼Œä¸æ¸…å…¨ç«™ç¼“å­˜ ===
            _bust("ship_tracking")
            _ = load_ship_tracking_raw(_bust=_get_bust("ship_tracking"))

            st.info("æ­£åœ¨æ›´æ–°ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ï¼ˆåªå«ã€å‘è´§è¿½è¸ªã€é‡Œçš„è¿å•ï¼›ä»…æ›´æ–°æŒ‡å®šåˆ—ï¼‰â€¦")
            try:
                df_delta = build_waybill_delta()
                if df_delta.empty:
                    st.warning("æ²¡æœ‰å¯æ›´æ–°çš„æ•°æ®ï¼ˆæ£€æŸ¥åˆ°ä»“/å‘è´§/è‡ªæè¡¨ï¼‰ã€‚")
                else:
                    ok = upsert_waybill_summary_partial(df_delta)
                    if ok:
                        _bust("wb_summary")
                        _ = load_waybill_summary_df(_bust=_get_bust("wb_summary"))
                        st.success(f"å·²æ›´æ–°/æ–°å¢ {len(df_delta)} æ¡åˆ°ã€{SHEET_WB_SUMMARY}ã€ã€‚")
                    else:
                        st.warning("æœªèƒ½å†™å…¥ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ï¼šè¯·å…ˆåˆ›å»ºè¯¥è¡¨å¹¶ç¡®ä¿é¦–è¡ŒåŒ…å«â€œè¿å•å·â€åˆ—ã€‚")
            except Exception as e:
                st.warning(f"æ›´æ–°ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€å¤±è´¥ï¼š{e}")

            st.session_state.sel_locked = False
            st.session_state.locked_df = pd.DataFrame()
            st.session_state.pop("pallet_select_editor", None)
            st.rerun()

with tab2:
    st.subheader("ğŸšš æŒ‰å¡è½¦å›å¡«åˆ°ä»“æ—¥æœŸï¼ˆå…ˆé€‰ä»“åº“ â†’ å†é€‰å¡è½¦ï¼‰")

    @st.cache_data(ttl=300)
    def load_waybill_summary_df(_bust=0):
        try:
            ws = client.open(SHEET_WB_SUMMARY).sheet1
        except SpreadsheetNotFound:
            st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_WB_SUMMARY}ã€ã€‚")
            return pd.DataFrame(), None, []
        vals = _safe_get_all_values(
            ws,
            value_render_option="UNFORMATTED_VALUE",
            date_time_render_option="SERIAL_NUMBER"
        )
        if not vals:
            st.warning("ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ä¸ºç©ºã€‚")
            return pd.DataFrame(), ws, []

        header_raw = vals[0]
        df = pd.DataFrame(vals[1:], columns=header_raw) if len(vals) > 1 else pd.DataFrame(columns=header_raw)

        def pick(colnames, cands):
            for c in cands:
                if c in colnames:
                    return c
            return None

        col_wb   = pick(df.columns, ["è¿å•å·","Waybill"])
        col_wh   = pick(df.columns, ["ä»“åº“ä»£ç ","ä»“åº“"])
        col_trk  = pick(df.columns, ["å‘èµ°å¡è½¦å·","å‘èµ°è½¦å·","å‘èµ°å¡è½¦","å¡è½¦å·","TruckNo","Truck"])
        col_ship = pick(df.columns, ["å‘èµ°æ—¥æœŸ","å‘è´§æ—¥æœŸ","å‡ºä»“æ—¥æœŸ"])
        col_eta  = pick(df.columns, ["åˆ°ä»“æ—¥æœŸ","åˆ°ä»“æ—¥","åˆ°ä»“(wh)"])

        if col_wb   is None: df["è¿å•å·"]   = ""; col_wb   = "è¿å•å·"
        if col_wh   is None: df["ä»“åº“ä»£ç "] = ""; col_wh   = "ä»“åº“ä»£ç "
        if col_trk  is None: df["å‘èµ°å¡è½¦å·"] = ""; col_trk  = "å‘èµ°å¡è½¦å·"
        if col_ship is None: df["å‘èµ°æ—¥æœŸ"]  = ""; col_ship = "å‘èµ°æ—¥æœŸ"
        if col_eta  is None: df["åˆ°ä»“æ—¥æœŸ"]  = ""; col_eta  = "åˆ°ä»“æ—¥æœŸ"

        df_work = df.rename(columns={
            col_wb: "è¿å•å·",
            col_wh: "ä»“åº“ä»£ç ",
            col_trk: "å‘èµ°å¡è½¦å·",
            col_ship: "å‘èµ°æ—¥æœŸ",
            col_eta: "åˆ°ä»“æ—¥æœŸ",
        }).copy()

        df_work["_rowno"] = np.arange(2, 2 + len(df_work))
        df_work["_å‘èµ°æ—¥æœŸ_dt"] = df_work["å‘èµ°æ—¥æœŸ"].apply(_parse_sheet_value_to_date)
        df_work["_åˆ°ä»“æ—¥æœŸ_dt"] = df_work["åˆ°ä»“æ—¥æœŸ"].apply(_parse_sheet_value_to_date)

        df_work["ä»“åº“ä»£ç "] = df_work["ä»“åº“ä»£ç "].astype(str).str.strip()
        df_work["å‘èµ°å¡è½¦å·"] = df_work["å‘èµ°å¡è½¦å·"].astype(str).str.strip()

        return df_work, ws, header_raw

    df_sum, ws_sum, header_raw = load_waybill_summary_df(_bust=_get_bust("wb_summary"))
    if ws_sum is None or df_sum.empty:
        st.stop()

    st.subheader("ç­›é€‰æ¡ä»¶")

    wh_all = sorted([w for w in df_sum["ä»“åº“ä»£ç "].astype(str).unique() if w.strip()])
    wh_pick = st.multiselect("ä»“åº“ä»£ç ï¼ˆå…ˆé€‰è¿™é‡Œï¼‰", options=wh_all, placeholder="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªä»“åº“â€¦")

    if wh_pick:
        df_wh = df_sum[df_sum["ä»“åº“ä»£ç "].isin(wh_pick)].copy()
    else:
        df_wh = df_sum.copy()

    truck_opts = sorted([t for t in df_wh["å‘èµ°å¡è½¦å·"].astype(str).unique() if t.strip()])
    if truck_opts:
        trucks_pick = st.multiselect(
            "å¡è½¦å•å·ï¼ˆä»æ‰€é€‰ä»“åº“æ´¾ç”Ÿï¼‰",
            options=truck_opts,
            placeholder="é€‰æ‹©è¦æ‰¹é‡å›å¡«çš„è½¦æ¬¡â€¦"
        )
    else:
        st.info("å½“å‰ä»“åº“ä¸‹æ²¡æœ‰å¯é€‰çš„å¡è½¦å•å·ã€‚")
        trucks_pick = []

    df_for_dates = df_wh.copy()
    if trucks_pick:
        df_for_dates = df_for_dates[df_for_dates["å‘èµ°å¡è½¦å·"].astype(str).isin(trucks_pick)]

    valid_ship_dates = df_for_dates.loc[df_for_dates["_å‘èµ°æ—¥æœŸ_dt"].notna(), "_å‘èµ°æ—¥æœŸ_dt"]
    if not valid_ship_dates.empty:
        dmin, dmax = valid_ship_dates.min(), valid_ship_dates.max()
        default_start = dmin
        default_end = dmax if dmax >= dmin else dmin
        r1, r2 = st.date_input(
            "æŒ‰å‘èµ°æ—¥æœŸç­›é€‰èŒƒå›´",
            value=(default_start, default_end),
            min_value=dmin, max_value=max(dmax, dmin)
        )
    else:
        r1 = r2 = None
        st.caption("æœªæ£€ç´¢åˆ°å¯ç”¨çš„ã€å‘èµ°æ—¥æœŸã€èŒƒå›´ï¼ˆæ‰€é€‰æ¡ä»¶å¯èƒ½æ²¡æœ‰æ—¥æœŸæ•°æ®ï¼‰ã€‚")

    only_blank = st.checkbox("ä»…å¡«ç©ºç™½åˆ°ä»“æ—¥æœŸ", value=True)

    filt = pd.Series(True, index=df_sum.index)
    if wh_pick:
        filt &= df_sum["ä»“åº“ä»£ç "].isin(wh_pick)
    if trucks_pick:
        filt &= df_sum["å‘èµ°å¡è½¦å·"].astype(str).isin(trucks_pick)
    if r1 and r2:
        filt &= df_sum["_å‘èµ°æ—¥æœŸ_dt"].between(r1, r2)
    if only_blank:
        filt &= df_sum["_åˆ°ä»“æ—¥æœŸ_dt"].isna()

    df_target = df_sum.loc[filt].copy()

    st.markdown(f"**åŒ¹é…åˆ° {len(df_target)} æ¡è¿å•**")
    st.dataframe(
        df_target[["è¿å•å·","ä»“åº“ä»£ç ","å‘èµ°å¡è½¦å·","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ"]]
            .sort_values(["ä»“åº“ä»£ç ","å‘èµ°å¡è½¦å·","è¿å•å·"]),
        use_container_width=True, height=360
    )

    st.divider()

    today = date.today()
    fill_date = st.date_input("å¡«å……åˆ°ä»“æ—¥æœŸï¼ˆæ‰¹é‡ï¼‰", value=today)

    def _get_google_credentials():
        if "gcp_service_account" in st.secrets:
            sa_info = st.secrets["gcp_service_account"]
            return Credentials.from_service_account_info(sa_info, scopes=SCOPES)
        else:
            return Credentials.from_service_account_file("service_accounts.json", scopes=SCOPES)

    def _write_arrival_date(rows_idx, date_to_fill: date):
        col_idx_1based = None
        for i, h in enumerate(header_raw):
            if h.replace(" ", "") in ["åˆ°ä»“æ—¥æœŸ", "åˆ°ä»“æ—¥", "åˆ°ä»“(wh)"]:
                col_idx_1based = i + 1
                break
        if col_idx_1based is None:
            st.error("ç›®æ ‡è¡¨ç¼ºå°‘ã€åˆ°ä»“æ—¥æœŸã€åˆ—ã€‚è¯·å…ˆåœ¨è¡¨å¤´æ–°å¢è¯¥åˆ—åé‡è¯•ã€‚")
            return False
        if not rows_idx:
            return True

        rows = sorted(int(r) for r in rows_idx)
        ranges = []
        s = p = rows[0]
        for r in rows[1:]:
            if r == p + 1:
                p = r
            else:
                ranges.append((s, p))
                s = p = r
        ranges.append((s, p))

        try:
            creds = _get_google_credentials()
            service = build("sheets", "v4", credentials=creds, cache_discovery=False)
            spreadsheet_id = ws_sum.spreadsheet.id
            sheet_title = ws_sum.title

            date_str = date_to_fill.strftime("%Y-%m-%d")

            batch_size = 200
            for i in range(0, len(ranges), batch_size):
                sub = ranges[i:i + batch_size]
                data = []
                for r1_, r2_ in sub:
                    a1_start = gspread.utils.rowcol_to_a1(r1_, col_idx_1based)
                    a1_end   = gspread.utils.rowcol_to_a1(r2_, col_idx_1based)
                    a1_range = f"{sheet_title}!{a1_start}:{a1_end}"
                    values = [[date_str] for _ in range(r2_ - r1_ + 1)]
                    data.append({"range": a1_range, "values": values})

                body = {"valueInputOption": "USER_ENTERED", "data": data}
                service.spreadsheets().values().batchUpdate(
                    spreadsheetId=spreadsheet_id,
                    body=body
                ).execute()

            return True
        except HttpError as e:
            st.error(f"å†™å…¥å¤±è´¥ï¼ˆHTTPï¼‰ï¼š{e}")
            return False
        except Exception as e:
            st.error(f"å†™å…¥å¤±è´¥ï¼š{e}")
            return False

    left, right = st.columns([1,1])
    with left:
        st.caption("æç¤ºï¼šå…ˆé€‰ä»“åº“ï¼Œå†é€‰å¡è½¦ï¼›å¯æŒ‰å‘èµ°æ—¥æœŸèŒƒå›´è¿‡æ»¤ï¼›å‹¾é€‰â€œä»…å¡«ç©ºç™½â€é¿å…è¦†ç›–å·²æœ‰å€¼ã€‚")
    with right:
        if st.button("ğŸ“ æ‰¹é‡å†™å…¥åˆ°ä»“æ—¥æœŸ", key="btn_fill_arrival_date"):
            if df_target.empty:
                st.warning("ç­›é€‰ç»“æœä¸ºç©ºï¼›è¯·è°ƒæ•´ä»“åº“/å¡è½¦/æ—¥æœŸæ¡ä»¶ã€‚")
            else:
                ok = _write_arrival_date(df_target["_rowno"].tolist(), fill_date)
                if ok:
                    st.success(f"å·²æ›´æ–° {len(df_target)} è¡Œçš„ã€åˆ°ä»“æ—¥æœŸã€ä¸º {fill_date.strftime('%Y-%m-%d')}ã€‚")
                    _bust("wb_summary")
                    st.rerun()
