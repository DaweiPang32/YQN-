# ship_app_tab2.py â€”â€” ä»…å¯ç”¨ æŒ‰æ‰˜ç›˜å‘è´§ï¼ˆTab2 çš„é€»è¾‘ï¼Œå»æ‰ Tab1ï¼‰
# åŠŸèƒ½ï¼š
# - æ‰˜ç›˜é‡é‡/ä½“ç§¯ï¼šé‡é‡åªæ¥è‡ªã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹å¹¶æŒ‰æ‰˜ç›˜æ±‚å’Œï¼›ä½“ç§¯ç”±é•¿å®½é«˜ï¼ˆinchï¼‰è®¡ç®—ä¸º CBMï¼ˆæ¯ä¸ªæ‰˜ç›˜åªè®¡ç®—ä¸€æ¬¡ï¼Œé¿å…é‡å¤ï¼‰
# - ETA/ATAï¼ˆåˆå¹¶åˆ—ï¼‰ã€ETD/ATDï¼ˆExcelåºåˆ— 45824 ç­‰ï¼‰â†’ æ—¥æœŸå­—ç¬¦ä¸²
# - å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´å¦‚â€œ19-21â€â†’ ä¸ä»Šå¤©çš„å¤©æ•°å·®ï¼šx-yï¼ˆé”šå®š ETA/ATA çš„æœˆä»½ï¼Œç¼ºå¤±ç”¨å½“æœˆï¼‰
# - å·²å‘æ‰˜ç›˜è¯»å–è‡ªã€å‘è´§è¿½è¸ªã€ï¼Œå†æ¬¡è¿›å…¥é¡µé¢è‡ªåŠ¨éšè—
# - ä¸Šä¼ åˆ°ã€å‘è´§è¿½è¸ªã€åï¼Œè‡ªåŠ¨ã€éƒ¨åˆ†æ›´æ–°ã€‘ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€
#   ä»…æ›´æ–°ä»¥ä¸‹åˆ—ï¼šå®¢æˆ·å•å·ã€å‘å‡º(ETD/ATD)ã€åˆ°æ¸¯(ETA/ATA)ã€åˆ°BCFæ—¥æœŸã€åˆ°BCFå¡è½¦å·ã€åˆ°BCFè´¹ç”¨ã€å‘èµ°æ—¥æœŸã€å‘èµ°å¡è½¦å·ã€å‘èµ°è´¹ç”¨
# - åªé’ˆå¯¹ã€å‘è´§è¿½è¸ªã€é‡Œå‡ºç°è¿‡çš„è¿å•å·è¿›è¡Œæ±‡æ€»/æ›´æ–°
# - å…¼å®¹ã€bolè‡ªææ˜ç»†ã€/ã€å‘è´§è¿½è¸ªã€å®é™…åˆ—åï¼ˆå¡è½¦å·/è´¹ç”¨/æ—¥æœŸ/å®¢æˆ·å•å·ç­‰ï¼‰
# - æ–°å¢ï¼šåœ¨æ‰˜ç›˜å±•ç¤ºä¸­æ˜¾ç¤ºã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹æäº¤æ—¶å†™å…¥çš„ã€æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ / æ‰˜ç›˜åˆ›å»ºæ—¶é—´ã€‘

import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from gspread.exceptions import SpreadsheetNotFound
from datetime import datetime, timedelta, date
import calendar
import re

SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

def get_gspread_client():
    # 1) Cloudï¼šä¼˜å…ˆä» st.secrets è¯»å–ï¼ˆStreamlit Cloud é…ç½®çš„æœºå¯†ï¼‰
    if "gcp_service_account" in st.secrets:
        sa_info = st.secrets["gcp_service_account"]  # è¿™æ˜¯ä¸€ä¸ª dictï¼ˆæˆ‘ä»¬ç¨ååœ¨ Cloud é‡Œé…ç½®ï¼‰
        creds = Credentials.from_service_account_info(sa_info, scopes=SCOPES)
        return gspread.authorize(creds)
    # 2) æœ¬åœ°ï¼šå…¼å®¹ä½ åŸæ¥çš„ JSON æ–‡ä»¶
    else:
        creds = Credentials.from_service_account_file("service_accounts.json", scopes=SCOPES)
        return gspread.authorize(creds)

client = get_gspread_client()

# ========= è¡¨åé…ç½® =========
SHEET_ARRIVALS_NAME   = "åˆ°ä»“æ•°æ®è¡¨"       # ETD/ATDã€ETA/ATAï¼ˆåˆå¹¶ï¼‰ã€å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´ã€é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰
SHEET_PALLET_DETAIL   = "æ‰˜ç›˜æ˜ç»†è¡¨"       # æ‰˜ç›˜æ•°æ®ï¼ˆé‡é‡/ä½“ç§¯æ¥è‡ªæ­¤è¡¨ï¼›ä½“ç§¯ç”± L/W/H(inch) è®¡ç®—ä¸º CBMï¼‰
SHEET_SHIP_TRACKING   = "å‘è´§è¿½è¸ª"     # æ‰˜ç›˜ç»´åº¦å‡ºä»“è®°å½•ï¼ˆåˆ†æ‘Šåˆ°æ‰˜ç›˜ï¼‰
SHEET_BOL_DETAIL      = "bolè‡ªææ˜ç»†"      # åˆ°BCF æ˜ç»†ï¼ˆåˆ†æ‘Šåˆ°è¿å•ï¼‰
SHEET_WB_SUMMARY      = "è¿å•å…¨é“¾è·¯æ±‡æ€»"    # ä»…éƒ¨åˆ†æ›´æ–°

# ========= åŸºç¡€å·¥å…· =========
def _norm_header(cols):
    return [c.replace("\u00A0"," ").replace("\n","").strip().replace(" ","") for c in cols]

def _to_num(x):
    try: return float(str(x).strip())
    except: return None

def _to_num_safe(x):
    try:
        s = str(x).strip().replace(",","")
        s = re.sub(r"[^\d\.\-]", "", s)
        return float(s)
    except:
        return None

def _is_blank(v):
    try:
        if v is None: return True
        if pd.isna(v): return True
        if isinstance(v, str) and v.strip()=="": return True
        return False
    except Exception:
        try: return bool(pd.isna(v))
        except Exception: return False
def _coerce_excel_serial_sum(v):
    """
    å°†å„ç§å½¢æ€çš„è¾“å…¥åˆå¹¶ä¸º Excel/GS åºåˆ—å¤©æ•°ï¼ˆå¯å«å°æ•°çš„å¤©æ•°ï¼‰ï¼š
    - æ•°å­—ï¼šç›´æ¥è¿”å›
    - å­—ç¬¦ä¸²ï¼šæå–å…¶ä¸­çš„æ‰€æœ‰æ•°å­—ï¼ˆå«å°æ•°ï¼‰ï¼Œç´¯åŠ ï¼ˆé€‚é… '45905 0.6855' è¿™ç±»ï¼‰
    - åˆ—è¡¨/å…ƒç»„ï¼šæŠŠå…¶ä¸­èƒ½è½¬æ•°å­—çš„é¡¹ç´¯åŠ 
    è§£æå¤±è´¥è¿”å› None
    """
    # å•ä¸ªæ•°å­—
    try:
        if isinstance(v, (int, float)) and not pd.isna(v):
            return float(v)
    except Exception:
        pass

    # å­—ç¬¦ä¸²é‡ŒæŠ½å–æ‰€æœ‰æ•°å­—ç‰‡æ®µå¹¶ç›¸åŠ 
    if isinstance(v, str):
        nums = re.findall(r'[-+]?\d+(?:\.\d+)?', v)
        total = 0.0
        ok = False
        for n in nums:
            try:
                total += float(n); ok = True
            except Exception:
                pass
        if ok:
            return total

    # å¯è¿­ä»£ï¼ˆå¦‚ list/tupleï¼‰é€é¡¹ç›¸åŠ 
    if isinstance(v, (list, tuple)):
        total = 0.0
        ok = False
        for x in v:
            try:
                if x is None or (isinstance(x, float) and pd.isna(x)):
                    continue
                total += float(x); ok = True
            except Exception:
                pass
        if ok:
            return total

    return None

def _norm_waybill_str(v):
    if _is_blank(v): return ""
    s = str(v).strip()
    if s.endswith(".0"): s = s[:-2]
    try:
        f = float(s)
        if abs(f - round(f)) < 1e-9: s = str(int(round(f)))
    except: pass
    return s

# Excel/GS åºåˆ—çš„èµ·ç‚¹ï¼ˆè‹¥æ–‡ä»¶é¡¶éƒ¨å·²æœ‰ _BASEï¼Œå¯ä¿ç•™ä¸€å¤„å³å¯ï¼‰
_BASE = datetime(1899, 12, 30)

def _coerce_excel_serial_sum(v):
    """
    å°† v åˆå¹¶ä¸º Excel/GS åºåˆ—å¤©æ•°ï¼ˆå¯å«å°æ•°ï¼‰ã€‚
    å…¼å®¹ï¼š
    - '45905 0.6855' / '45905\t0,6855' / '45905\u00A00.6855'
    - æ··åˆåˆ†éš”ç¬¦ã€ä¸­æ–‡æ ‡ç‚¹ã€ä¸å¯è§ç©ºç™½
    - é€—å·å°æ•°ï¼ˆ0,6855 -> 0.6855ï¼‰
    - åˆ—è¡¨/å…ƒç»„ä¸­çš„å¤šç‰‡æ®µ
    è§£æå¤±è´¥è¿”å› None
    """
    # å•ä¸ªæ•°å­—
    try:
        if isinstance(v, (int, float)) and not pd.isna(v):
            return float(v)
    except Exception:
        pass

    # å­—ç¬¦ä¸²ï¼šæŠ½å–å…¨éƒ¨æ•°å­—ç‰‡æ®µå¹¶ç´¯åŠ 
    if isinstance(v, str):
        s = v.strip()
        s = re.sub(r'[\u00A0\u2000-\u200B]', ' ', s)  # å„ç±»ä¸å¯è§ç©ºç™½ -> ç©ºæ ¼
        s = s.replace(',', '.')                       # é€—å·å°æ•° -> ç‚¹
        nums = re.findall(r'[-+]?\d+(?:\.\d+)?', s)
        total, ok = 0.0, False
        for n in nums:
            try:
                total += float(n); ok = True
            except Exception:
                pass
        if ok:
            return total

    # å¯è¿­ä»£ï¼ˆlist/tupleï¼‰ï¼šé€é¡¹ç›¸åŠ 
    if isinstance(v, (list, tuple)):
        total, ok = 0.0, False
        for x in v:
            if x is None or (isinstance(x, float) and pd.isna(x)):
                continue
            try:
                xs = str(x).strip().replace(',', '.')
                total += float(xs); ok = True
            except Exception:
                pass
        if ok:
            return total

    return None


def _parse_sheet_value_to_date(v):
    """
    æ›´å¼ºå¥çš„â€œå€¼ -> æ—¥æœŸ(date)â€è§£æï¼š
    1) å…ˆæŠŠ v åˆå¹¶æˆ Excel/GS å¤©æ•°ï¼ˆå«å°æ•°ï¼‰ï¼ŒæˆåŠŸåˆ™æŒ‰åºåˆ—è½¬æ¢ï¼ˆä¸¢å¼ƒæ—¶é—´éƒ¨åˆ†ï¼‰
    2) ä¸è¡Œå†å°è¯•æ•°å€¼èŒƒå›´/æ—¶é—´æˆ³
    3) æœ€åç”¨ pandas å…œåº•
    """
    # â‘  åˆå¹¶â€œæ—¥æœŸ+æ—¶é—´ç‰‡æ®µâ€
    serial = _coerce_excel_serial_sum(v)
    if serial is not None:
        try:
            dt = _BASE + timedelta(days=float(serial))
            return dt.date()
        except Exception:
            pass

    # â‘¡ é€€è·¯ï¼šåŸæ•°å€¼è·¯å¾„
    if _is_blank(v):
        return None
    n = _to_num(v)
    if n is not None:
        if 30000 <= n <= 80000:
            return (_BASE + timedelta(days=n)).date()
        if 80000 < n < 200000:
            return (_BASE + timedelta(days=n/2.0)).date()
        if 1e9 <= n < 2e10:           # ç§’æ—¶é—´æˆ³
            try: return datetime.utcfromtimestamp(n).date()
            except: pass
        if 1e12 <= n < 2e13:          # æ¯«ç§’æ—¶é—´æˆ³
            try: return datetime.utcfromtimestamp(n/1000.0).date()
            except: pass
        try: return (_BASE + timedelta(days=n)).date()
        except: pass

    # â‘¢ pandas å…œåº•
    try:
        dt = pd.to_datetime(v, errors="coerce")
        if pd.isna(dt): return None
        return dt.date()
    except Exception:
        return None



def _fmt_date(d: date, out_fmt="%Y-%m-%d"):
    return d.strftime(out_fmt) if isinstance(d, date) else ""

def _parse_time_window_days(win: str):
    if not isinstance(win, str): return (None, None)
    s = win.strip()
    if "-" not in s: return (None, None)
    a, b = s.split("-", 1)
    try:
        sa, sb = int(a), int(b)
        if 1 <= sa <= 31 and 1 <= sb <= 31 and sa <= sb:
            return (sa, sb)
    except: pass
    return (None, None)

def _clamp_dom(year, month, dom):
    last = calendar.monthrange(year, month)[1]
    dom = max(1, min(last, dom))
    return date(year, month, dom)

def _promise_diff_days_str(win: str, anchor: date | None):
    sa, sb = _parse_time_window_days(win)
    if sa is None: return ""
    today = date.today()
    if anchor is None: anchor = today
    y, m = anchor.year, anchor.month
    start_d = _clamp_dom(y, m, sa)
    end_d   = _clamp_dom(y, m, sb)
    x = (start_d - today).days
    y2 = (end_d   - today).days
    return f"{x}-{y2}"
def _excel_serial_to_dt(v):
    """
    å°†ä»»æ„å½¢æ€çš„ Excel/GS åºåˆ—ï¼ˆå«å°æ•°ï¼‰æˆ–å¸¦æœ‰æ•°å­—çš„å­—ç¬¦ä¸²è½¬ä¸º datetimeï¼ˆå«æ—¥æœŸä¸æ—¶é—´ï¼‰ã€‚
    - æ”¯æŒ '45905 0.6855'ã€'45905,0.6855'ã€åˆ—è¡¨ [45905, 0.6855] ç­‰
    - è¿”å› datetime æˆ– None
    """
    serial = _coerce_excel_serial_sum(v)
    if serial is None:
        # å†è¯•ï¼šç›´æ¥è§£ææ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¦‚ '14:25'ï¼‰
        try:
            ts = pd.to_datetime(str(v), errors="coerce")
            if pd.isna(ts):
                return None
            # è‹¥åªæœ‰æ—¶é—´è€Œæ— æ—¥æœŸï¼Œåˆ™ç”¨ä»Šå¤©çš„æ—¥æœŸ
            if ts.year < 1900:
                base = datetime.combine(date.today(), ts.time())
                return base
            return ts.to_pydatetime()
        except Exception:
            return None
    try:
        return _BASE + timedelta(days=float(serial))
    except Exception:
        return None

def _fmt_time_from_any(v, out_fmt="%H:%M"):
    """
    å°†å„ç§å½¢æ€ï¼ˆåºåˆ—/å­—ç¬¦ä¸²/åˆ—è¡¨ï¼‰è§£æä¸ºæ—¶é—´å­—ç¬¦ä¸² HH:MMã€‚
    - è‹¥ v æ˜¯ä»…æ—¶é—´å°æ•°ï¼ˆå¦‚ 0.6855ï¼‰ä¹Ÿå¯
    - è‹¥ v åŒ…å«æ—¥æœŸ+æ—¶é—´ï¼ˆå¦‚ 45905.6855 / '45905 0.6855'ï¼‰ä¹Ÿå¯
    """
    dt = _excel_serial_to_dt(v)
    return dt.strftime(out_fmt) if isinstance(dt, datetime) else ""

def _split_dt_to_date_time_str(date_raw, time_raw):
    """
    æ™ºèƒ½ä»â€œæ—¥æœŸåˆ—/æ—¶é—´åˆ—â€æå–æœ€ç»ˆçš„æ—¥æœŸå­—ç¬¦ä¸²ä¸æ—¶é—´å­—ç¬¦ä¸²ã€‚
    ä¼˜å…ˆï¼š
      1) ä» date_raw ä¸­è§£æåˆ°æ—¥æœŸï¼›è‹¥å…¶ä¸­å¸¦æœ‰æ—¶é—´ä¹Ÿç”¨äº time å…œåº•
      2) ä» time_raw ä¸­è§£ææ—¶é—´ï¼›è‹¥ time_raw ä¸ºç©ºåˆ™å°è¯•ä» date_raw çš„å°æ•°éƒ¨åˆ†å–æ—¶é—´
    """
    d_dt = _excel_serial_to_dt(date_raw)
    t_dt = _excel_serial_to_dt(time_raw)

    # æ—¥æœŸ
    if isinstance(d_dt, datetime):
        date_str = d_dt.date().strftime("%Y-%m-%d")
    elif isinstance(t_dt, datetime):
        # åªæœ‰æ—¶é—´ï¼Œç»™ä»Šå¤©çš„æ—¥æœŸ
        date_str = date.today().strftime("%Y-%m-%d")
    else:
        date_str = ""

    # æ—¶é—´
    time_str = ""
    if isinstance(t_dt, datetime):
        time_str = t_dt.strftime("%H:%M")
    elif isinstance(d_dt, datetime):
        # date_raw é‡Œå¯èƒ½ä¹Ÿå¸¦å°æ•° -> æœ‰æ—¶é—´
        time_str = d_dt.strftime("%H:%M")
    return date_str, time_str

def _split_waybill_list(s):
    if _is_blank(s): return []
    parts = re.split(r"[,\ï¼Œ;\ï¼›ã€\|\/\s]+", str(s))
    return [_norm_waybill_str(p) for p in parts if _norm_waybill_str(p)]

def _first_nonblank_str(s):
    for x in s:
        if not _is_blank(x):
            return str(x).strip()
    return ""

# ========= æ•°æ®è¯»å– =========
@st.cache_data(ttl=60)
def load_arrivals_df():
    ws = client.open(SHEET_ARRIVALS_NAME).sheet1
    data = ws.get_all_values(
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not data: return pd.DataFrame()
    header = _norm_header(data[0])
    df = pd.DataFrame(data[1:], columns=header)

    # å…œåº•å¿…éœ€åˆ—
    for need in ["è¿å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡"]:
        if need not in df.columns: df[need] = pd.NA

    # â€”â€” è¯†åˆ«â€œä½“ç§¯â€åˆ—ï¼ˆCBMï¼‰
    vol_col = next((c for c in ["ä½“ç§¯","CBM","ä½“ç§¯m3","ä½“ç§¯(m3)","ä½“ç§¯ï¼ˆm3ï¼‰"] if c in df.columns), None)
    if vol_col is None:
        df["ä½“ç§¯"] = pd.NA
    else:
        df["ä½“ç§¯"] = pd.to_numeric(df[vol_col], errors="coerce")

    # ETA/ATA åˆå¹¶åˆ—è¯†åˆ«
    etaata_col = None
    for cand in ["ETA/ATA","ETAATA"]:
        if cand in df.columns:
            etaata_col = cand; break

    if "ETD/ATD" not in df.columns: df["ETD/ATD"] = pd.NA
    if "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´" not in df.columns: df["å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´"] = pd.NA

    eta_wh_col = None
    for cand in ["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰","é¢„è®¡åˆ°ä»“æ—¶é—´(æ—¥)","é¢„è®¡åˆ°ä»“æ—¶é—´æ—¥"]:
        if cand in df.columns:
            eta_wh_col = cand; break
    if eta_wh_col is None:
        df["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"] = pd.NA
        eta_wh_col = "é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"

    # è§„èŒƒåŒ–
    df["è¿å•å·"] = df["è¿å•å·"].apply(_norm_waybill_str)
    df["ä»“åº“ä»£ç "] = df["ä»“åº“ä»£ç "].astype(str).str.strip()
    df["æ”¶è´¹é‡"] = pd.to_numeric(df["æ”¶è´¹é‡"], errors="coerce")

    # è§£ææ—¥æœŸåˆ— â€”â€” ç»Ÿä¸€â€œå¼ºåˆ¶è¦†ç›–ä¸ºæ—¥æœŸå­—ç¬¦ä¸²â€ï¼Œå¤±è´¥åˆ™ç©ºï¼Œä¸ä¿ç•™åŸä¸²
    if etaata_col is not None:
        df["_ETAATA_date"] = df[etaata_col].apply(_parse_sheet_value_to_date)
        df["ETA/ATA"] = df["_ETAATA_date"].apply(_fmt_date).replace("", pd.NA)
    else:
        df["_ETAATA_date"] = pd.NA
        df["ETA/ATA"] = pd.NA

    df["_ETD_ATD_date"] = df["ETD/ATD"].apply(_parse_sheet_value_to_date)
    df["ETD/ATD"] = df["_ETD_ATD_date"].apply(_fmt_date).replace("", pd.NA)

    df["_ETA_WH_date"] = df[eta_wh_col].apply(_parse_sheet_value_to_date)
    df["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"] = df["_ETA_WH_date"].apply(_fmt_date).replace("", pd.NA)

    # å»é‡ï¼ˆä¿ç•™æœ€åä¸€æ¡ï¼‰
    df = df.drop_duplicates(subset=["è¿å•å·"], keep="last")

    keep = ["ä»“åº“ä»£ç ","è¿å•å·","æ”¶è´¹é‡","ä½“ç§¯",
            "ETA/ATA","ETD/ATD","å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰",
            "_ETAATA_date"]
    return df[keep]


@st.cache_data(ttl=60)
def load_pallet_detail_df():
    """
    æ‰˜ç›˜ç»´åº¦ï¼šä»ã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹èšåˆï¼Œå¹¶ä¸ã€Šåˆ°ä»“æ•°æ®è¡¨ã€‹åŒ¹é…æ—¶é—´/æ‰¿è¯ºå­—æ®µ
    - æ‰˜ç›˜é‡é‡ï¼šä»…æ¥è‡ªæ‰˜ç›˜æ˜ç»†ï¼ŒæŒ‰æ‰˜ç›˜æ±‚å’Œ
    - æ‰˜ç›˜ä½“ç§¯ï¼ˆCBMï¼‰ï¼šç”± L/W/H(inch) è®¡ç®—ï¼ˆæ¯ä¸ªæ‰˜ç›˜ä»…è®¡ç®—ä¸€æ¬¡ä½“ç§¯ï¼Œå–è¯¥æ‰˜ç›˜ç»„å†…ç¬¬ä¸€ç»„æœ‰æ•ˆ L/W/Hï¼‰
    - åŒæ—¶è¾“å‡ºæ¯æ‰˜ç›˜çš„â€œé•¿(in)/å®½(in)/é«˜(in)â€ï¼ˆå„å–é¦–ä¸ªæœ‰æ•ˆå€¼ï¼Œä»…ç”¨äºæ˜¾ç¤ºï¼‰
    - ETA/ATA ä½¿ç”¨â€œåˆå¹¶åˆ—â€ï¼ˆæ¥è‡ªåˆ°ä»“è¡¨ï¼‰ï¼Œå±•ç¤ºä¸º 'ETA/ATA yyyy-mm-dd'
    - æ–°å¢ï¼šèšåˆã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹ä¸­æäº¤æ—¶å†™å…¥çš„â€œæ‰˜ç›˜åˆ›å»ºæ—¥æœŸ/æ‰˜ç›˜åˆ›å»ºæ—¶é—´â€ï¼ˆè§£æä¸º YYYY-MM-DD / HH:MMï¼‰
    """
    # === å†…éƒ¨ä»…ä¾›æœ¬å‡½æ•°ä½¿ç”¨çš„å°å·¥å…·ï¼ˆä¾èµ–å…¨å±€ _BASE / _coerce_excel_serial_sumï¼‰===
    def _excel_serial_to_dt(v):
        """å°† Excel/GS åºåˆ—ï¼ˆå«å°æ•°ï¼‰æˆ–å¸¦æ•°å­—çš„å­—ç¬¦ä¸²è½¬ä¸º datetimeï¼›å¤±è´¥è¿”å› Noneã€‚"""
        serial = _coerce_excel_serial_sum(v)
        if serial is None:
            # å…œåº•ï¼šå°è¯•ç›´æ¥è§£æå­—ç¬¦ä¸²æ—¶é—´ï¼ˆå¦‚ '14:25'ï¼‰
            try:
                ts = pd.to_datetime(str(v), errors="coerce")
                if pd.isna(ts):
                    return None
                # åªæœ‰æ—¶é—´è€Œæ— æ—¥æœŸæ—¶ï¼ˆå¹´ä»½å¼‚å¸¸ï¼‰ï¼Œç»™ä»Šå¤©æ—¥æœŸ
                if ts.year < 1900:
                    return datetime.combine(date.today(), ts.time())
                return ts.to_pydatetime()
            except Exception:
                return None
        try:
            return _BASE + timedelta(days=float(serial))
        except Exception:
            return None

    def _split_dt_to_date_time_str(date_raw, time_raw):
        """
        æ™ºèƒ½ä»â€œæ—¥æœŸåˆ—/æ—¶é—´åˆ—â€æå–æœ€ç»ˆçš„æ—¥æœŸå­—ç¬¦ä¸²ä¸æ—¶é—´å­—ç¬¦ä¸²ï¼ˆ24h HH:MMï¼‰ã€‚
        ä¼˜å…ˆï¼š
          1) ä» date_raw ä¸­è§£æåˆ°æ—¥æœŸï¼›è‹¥å…¶ä¸­å¸¦å°æ•°æ—¶é—´ä¹Ÿå¯ç”¨äº time
          2) ä» time_raw ä¸­è§£ææ—¶é—´ï¼›è‹¥ç©ºåˆ™å›é€€åˆ° date_raw çš„æ—¶é—´éƒ¨åˆ†
        """
        d_dt = _excel_serial_to_dt(date_raw)
        t_dt = _excel_serial_to_dt(time_raw)

        # æ—¥æœŸ
        if isinstance(d_dt, datetime):
            date_str = d_dt.date().strftime("%Y-%m-%d")
        elif isinstance(t_dt, datetime):
            date_str = date.today().strftime("%Y-%m-%d")
        else:
            date_str = ""

        # æ—¶é—´
        if isinstance(t_dt, datetime):
            time_str = t_dt.strftime("%H:%M")
        elif isinstance(d_dt, datetime):
            time_str = d_dt.strftime("%H:%M")
        else:
            time_str = ""

        return date_str, time_str
    # === å°å·¥å…·ç»“æŸ ===

    ws = client.open(SHEET_PALLET_DETAIL).sheet1
    vals = ws.get_all_values(
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not vals:
        return pd.DataFrame()

    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)

    # å…œåº•å…³é”®åˆ—ï¼šæ‰˜ç›˜å·/ä»“åº“ä»£ç /è¿å•å·
    if "æ‰˜ç›˜å·" not in df.columns:
        for cand in ["æ‰˜ç›˜ID","æ‰˜ç›˜ç¼–å·","PalletID","PalletNo","palletid","palletno"]:
            if cand in df.columns:
                df = df.rename(columns={cand: "æ‰˜ç›˜å·"})
                break
    if "æ‰˜ç›˜å·" not in df.columns:
        df["æ‰˜ç›˜å·"] = pd.NA

    if "ä»“åº“ä»£ç " not in df.columns:
        df["ä»“åº“ä»£ç "] = pd.NA

    if "è¿å•å·" not in df.columns:
        for cand in ["Waybill","waybill","è¿å•ç¼–å·"]:
            if cand in df.columns:
                df = df.rename(columns={cand: "è¿å•å·"})
                break
    if "è¿å•å·" not in df.columns:
        df["è¿å•å·"] = pd.NA

    # è§„èŒƒåŒ–åŸºç¡€å­—æ®µ
    df["æ‰˜ç›˜å·"] = df["æ‰˜ç›˜å·"].astype(str).str.strip()
    df["ä»“åº“ä»£ç "] = df["ä»“åº“ä»£ç "].astype(str).str.strip()
    df["è¿å•å·"] = df["è¿å•å·"].apply(_norm_waybill_str)

    # è¯†åˆ«é‡é‡åˆ—ï¼ˆæ¥è‡ªæ‰˜ç›˜æ˜ç»†ï¼›åªç”¨æ‰˜ç›˜è¡¨ï¼Œä¸ä»åˆ°ä»“è¡¨å¸¦ï¼‰
    weight_col = None
    for cand in ["æ‰˜ç›˜é‡é‡","æ‰˜ç›˜é‡","æ”¶è´¹é‡","æ‰˜ç›˜æ”¶è´¹é‡","è®¡è´¹é‡","è®¡è´¹é‡é‡","é‡é‡"]:
        if cand in df.columns:
            weight_col = cand
            break
    if weight_col is None:
        df["æ‰˜ç›˜é‡é‡"] = pd.NA
        weight_col = "æ‰˜ç›˜é‡é‡"
    df[weight_col] = pd.to_numeric(df[weight_col], errors="coerce")

    # è¯†åˆ« L/W/Hï¼ˆinchï¼‰
    len_col = next((c for c in ["æ‰˜ç›˜é•¿","é•¿","é•¿åº¦","Length","length","L"] if c in df.columns), None)
    wid_col = next((c for c in ["æ‰˜ç›˜å®½","å®½","å®½åº¦","Width","width","W"] if c in df.columns), None)
    hei_col = next((c for c in ["æ‰˜ç›˜é«˜","é«˜","é«˜åº¦","Height","height","H"] if c in df.columns), None)

    INCH_TO_M = 0.0254

    def _cbm_row(r):
        if not all([len_col, wid_col, hei_col]):
            return None
        try:
            L = float(pd.to_numeric(r.get(len_col), errors="coerce"))
            W = float(pd.to_numeric(r.get(wid_col), errors="coerce"))
            H = float(pd.to_numeric(r.get(hei_col), errors="coerce"))
            if L > 0 and W > 0 and H > 0:
                return (L * W * H) * (INCH_TO_M ** 3)
        except Exception:
            pass
        return None

    df["_cbm_row"] = df.apply(_cbm_row, axis=1)

    def _first_valid_num(s):
        s_num = pd.to_numeric(s, errors="coerce").dropna()
        return float(s_num.iloc[0]) if len(s_num) > 0 else None

    def _wb_list(s):
        vals = [x for x in s if isinstance(x, str) and x.strip()]
        return vals

    # è¯†åˆ«â€œæ‰˜ç›˜åˆ›å»ºæ—¥æœŸ/æ—¶é—´â€åˆ—ï¼ˆæ”¶è´§ App æäº¤æ—¶å†™å…¥ï¼‰
    create_date_col = next((c for c in ["æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ","åˆ›å»ºæ—¥æœŸ","PalletCreateDate","CreateDate"] if c in df.columns), None)
    create_time_col = next((c for c in ["æ‰˜ç›˜åˆ›å»ºæ—¶é—´","åˆ›å»ºæ—¶é—´","PalletCreateTime","CreateTime"] if c in df.columns), None)
    if create_date_col is None:
        df["æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ"] = ""
        create_date_col = "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ"
    if create_time_col is None:
        df["æ‰˜ç›˜åˆ›å»ºæ—¶é—´"] = ""
        create_time_col = "æ‰˜ç›˜åˆ›å»ºæ—¶é—´"

    # === èšåˆåˆ°æ‰˜ç›˜ ===
    agg_dict = {
        "æ‰˜ç›˜é‡é‡": (weight_col, lambda s: pd.to_numeric(s, errors="coerce").dropna().sum()),
        "æ‰˜ç›˜ä½“ç§¯": ("_cbm_row", _first_valid_num),  # æ¯æ‰˜ç›˜ä»…å–ç¬¬ä¸€æ¡æœ‰æ•ˆä½“ç§¯
        "è¿å•æ¸…å•_list": ("è¿å•å·", _wb_list),
        # åˆ›å»ºæ—¥æœŸ/æ—¶é—´å–é¦–ä¸ªéç©ºåŸå§‹å€¼ï¼ˆç¨åç»Ÿä¸€è§£æï¼‰
        "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ_raw": (create_date_col, _first_nonblank_str),
        "æ‰˜ç›˜åˆ›å»ºæ—¶é—´_raw": (create_time_col, _first_nonblank_str),
    }
    if len_col:
        agg_dict["æ‰˜ç›˜é•¿in"] = (len_col, _first_valid_num)
    if wid_col:
        agg_dict["æ‰˜ç›˜å®½in"] = (wid_col, _first_valid_num)
    if hei_col:
        agg_dict["æ‰˜ç›˜é«˜in"] = (hei_col, _first_valid_num)

    base = (
        df.groupby(["æ‰˜ç›˜å·", "ä»“åº“ä»£ç "], as_index=False, dropna=False)
          .agg(**agg_dict)
    )

    # ä¸åˆ°ä»“æ•°æ®åˆå¹¶ï¼ˆä¸ºå±•ç¤º ETA/ATAã€ETD/ATDã€æ‰¿è¯ºæ—¶æ®µï¼‰
    arrivals = load_arrivals_df()  # éœ€è¦ï¼šETA/ATA, ETD/ATD, å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´, _ETAATA_date
    df_join = df.merge(
        arrivals[["è¿å•å·", "ETA/ATA", "ETD/ATD", "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´", "_ETAATA_date"]],
        on="è¿å•å·", how="left"
    )

    # å®¢æˆ·å•å·æ˜ å°„ï¼ˆä¼˜å…ˆæ¥è‡ªã€bolè‡ªææ˜ç»†ã€ï¼‰
    bol_cust_df = load_bol_waybill_costs()
    cust_map = {}
    if not bol_cust_df.empty and "è¿å•å·" in bol_cust_df.columns and "å®¢æˆ·å•å·" in bol_cust_df.columns:
        for _, rr in bol_cust_df.iterrows():
            wb = _norm_waybill_str(rr.get("è¿å•å·", ""))
            cust = str(rr.get("å®¢æˆ·å•å·", "")).strip()
            if wb and cust:
                cust_map[wb] = cust

    # === é€æ‰˜ç›˜ç»„è£…å±•ç¤ºé¡¹ ===
    pallets = []
    for _, brow in base.iterrows():
        pid, wh = brow["æ‰˜ç›˜å·"], brow["ä»“åº“ä»£ç "]
        if _is_blank(pid):
            continue

        p_wt = brow.get("æ‰˜ç›˜é‡é‡", None)
        p_vol = brow.get("æ‰˜ç›˜ä½“ç§¯", None)

        # è¿å•æ¸…å•ï¼ˆå¸¦å®¢æˆ·å•å·ï¼‰
        waybills = brow.get("è¿å•æ¸…å•_list", []) or []
        waybills_disp = []
        for wb in waybills:
            wb_norm = _norm_waybill_str(wb)
            cust = cust_map.get(wb_norm, "")
            waybills_disp.append(f"{wb}({cust})" if cust else f"{wb}")

        # è§£æåˆ›å»ºæ—¥æœŸ/æ—¶é—´ä¸ºå¯è¯»å­—ç¬¦ä¸²
        create_date_str, create_time_str = _split_dt_to_date_time_str(
            brow.get("æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ_raw", ""),
            brow.get("æ‰˜ç›˜åˆ›å»ºæ—¶é—´_raw", "")
        )

        # æ±‡æ€»å„è¿å•çš„ ETA/ATAã€ETD/ATDã€æ‰¿è¯ºæ—¶æ®µ&å·®å€¼
        sub = df_join[(df_join["æ‰˜ç›˜å·"] == pid) & (df_join["ä»“åº“ä»£ç "] == wh)]
        lines_etaata, lines_etdatd, promised = [], [], []
        diffs_days = []
        for _, r in sub.iterrows():
            wb = r.get("è¿å•å·", "")
            etaata_s = r.get("ETA/ATA", pd.NA)
            etdatd_s = r.get("ETD/ATD", "")
            promise = r.get("å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´", "")
            anchor = r.get("_ETAATA_date", None)

            lines_etaata.append(f"{wb}: ETA/ATA {etaata_s if not _is_blank(etaata_s) else '-'}")
            lines_etdatd.append(f"{wb}: {'' if _is_blank(etdatd_s) else str(etdatd_s)}")

            if not _is_blank(promise):
                diffs_days.append(_promise_diff_days_str(str(promise).strip(), anchor or date.today()))
                promised.append(str(promise).strip())

        readable_etaata = " ; ".join(lines_etaata) if lines_etaata else ""
        readable_etdatd = " ; ".join(lines_etdatd) if lines_etdatd else ""
        promised_set = list(dict.fromkeys([p for p in promised if p]))
        promised_str = " , ".join(promised_set)

        diff_days_str = ""
        if diffs_days:
            def keyfn(s):
                try:
                    a, _ = s.split("-", 1)
                    return int(a)
                except Exception:
                    return 10**9
            diff_days_str = sorted(diffs_days, key=keyfn)[0]

        # L/W/Hï¼ˆä»…æ˜¾ç¤ºï¼‰
        L_in = brow.get("æ‰˜ç›˜é•¿in", None)
        W_in = brow.get("æ‰˜ç›˜å®½in", None)
        H_in = brow.get("æ‰˜ç›˜é«˜in", None)

        pallets.append({
            "æ‰˜ç›˜å·": pid,
            "ä»“åº“ä»£ç ": wh,
            "æ‰˜ç›˜é‡é‡": float(p_wt) if pd.notna(p_wt) else None,
            "æ‰˜ç›˜ä½“ç§¯": float(p_vol) if p_vol is not None else None,  # mÂ³
            "é•¿(in)": round(float(L_in), 2) if pd.notna(L_in) else None,
            "å®½(in)": round(float(W_in), 2) if pd.notna(W_in) else None,
            "é«˜(in)": round(float(H_in), 2) if pd.notna(H_in) else None,
            # âœ… è§£æåçš„åˆ›å»ºæ—¶é—´ï¼ˆå¯è¯»ï¼‰
            "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ": create_date_str,
            "æ‰˜ç›˜åˆ›å»ºæ—¶é—´": create_time_str,
            "è¿å•æ•°é‡": len(waybills),
            "è¿å•æ¸…å•": ", ".join(waybills_disp) if waybills_disp else "",
            "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´": promised_str,
            "é€ä»“æ—¶æ®µå·®å€¼(å¤©)": diff_days_str,
            "ETA/ATA(æŒ‰è¿å•)": readable_etaata,
            "ETD/ATD(æŒ‰è¿å•)": readable_etdatd,
        })

    out = pd.DataFrame(pallets)
    if out.empty:
        return out

    # è¿‡æ»¤ç©ºæ‰˜ç›˜å·
    out = out[out["æ‰˜ç›˜å·"].astype(str).str.strip() != ""].copy()

    # æ•°å€¼ä¿ç•™ä¸¤ä½ï¼ˆä»…æ˜¾ç¤ºç”¨ï¼‰
    for c in ["æ‰˜ç›˜ä½“ç§¯","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)"]:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce")
    out["æ‰˜ç›˜ä½“ç§¯"] = out["æ‰˜ç›˜ä½“ç§¯"].round(2)
    out["é•¿(in)"] = out["é•¿(in)"].round(2)
    out["å®½(in)"] = out["å®½(in)"].round(2)
    out["é«˜(in)"] = out["é«˜(in)"].round(2)

    return out


@st.cache_data(ttl=60)
def load_shipped_pallet_ids():
    try:
        ws = client.open(SHEET_SHIP_TRACKING).sheet1
    except SpreadsheetNotFound:
        return set()
    vals = ws.get_all_values()
    if not vals: return set()
    raw_header = vals[0]
    norm_header = _norm_header(raw_header)
    norm_header_lower = [h.lower() for h in norm_header]
    candidates = ["æ‰˜ç›˜å·", "æ‰˜ç›˜ç¼–å·", "æ‰˜ç›˜id", "palletid", "palletno", "palletç¼–å·"]
    col_idx = None
    for name in candidates:
        n = name.replace(" ","")
        if n in norm_header: col_idx = norm_header.index(n); break
        if n.lower() in norm_header_lower: col_idx = norm_header_lower.index(n.lower()); break
    if col_idx is None: return set()
    shipped = set()
    for r in vals[1:]:
        if len(r)>col_idx:
            pid = str(r[col_idx]).strip()
            if pid: shipped.add(pid)
    return shipped

@st.cache_data(ttl=60)
def load_bol_waybill_costs():
    try:
        ws = client.open(SHEET_BOL_DETAIL).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame()
    vals = ws.get_all_values(
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not vals:
        return pd.DataFrame()
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header) if len(vals)>1 else pd.DataFrame(columns=header)

    col_wb    = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    col_truck = next((c for c in ["å¡è½¦å•å·","å¡è½¦å·","TruckNo","truckno","Truck","truck"] if c in df.columns), None)
    col_cost  = next((c for c in ["åˆ†æ‘Šè´¹ç”¨","è´¹ç”¨","Amount","amount","cost"] if c in df.columns), None)
    col_date  = next((c for c in ["ETA(åˆ°BCF)","ETAåˆ°BCF","åˆ°BCFETA","æ—¥æœŸ","Date","date"] if c in df.columns), None)
    col_cust  = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)

    if col_wb is None or col_cost is None:
        return pd.DataFrame()

    df[col_wb] = df[col_wb].apply(_norm_waybill_str)
    df[col_cost] = df[col_cost].apply(_to_num_safe)
    if col_truck: df[col_truck] = df[col_truck].astype(str).str.strip()
    if col_cust:  df[col_cust]  = df[col_cust].astype(str).str.strip()
    if col_date:
        df["_date"] = df[col_date].apply(_parse_sheet_value_to_date)
        df[col_date] = df["_date"].apply(_fmt_date).replace("", pd.NA)

    if df.empty:
        return pd.DataFrame()

    agg_dict = {col_cost: "sum"}
    if col_truck:
        agg_dict[col_truck] = lambda s: ", ".join(sorted(set([x.strip() for x in s if not _is_blank(x)])))
    if col_date:
        agg_dict[col_date] = "min"
    if col_cust:
        def _first_nonblank(s):
            for x in s:
                if not _is_blank(x): return x
            return ""
        agg_dict[col_cust] = _first_nonblank

    g = df.groupby(col_wb, dropna=False).agg(agg_dict).reset_index()

    rename_map = {col_wb:"è¿å•å·"}
    if col_truck: rename_map[col_truck] = "åˆ°BCFå¡è½¦å·"
    if col_cost:  rename_map[col_cost]  = "åˆ°BCFè´¹ç”¨"
    if col_date:  rename_map[col_date]  = "åˆ°BCFæ—¥æœŸ"
    if col_cust:  rename_map[col_cust]  = "å®¢æˆ·å•å·"
    g = g.rename(columns=rename_map)
    for c in ["è¿å•å·","å®¢æˆ·å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]:
        if c not in g.columns: g[c] = pd.NA
    g["åˆ°BCFè´¹ç”¨"] = pd.to_numeric(g["åˆ°BCFè´¹ç”¨"], errors="coerce").round(2)
    return g[["è¿å•å·","å®¢æˆ·å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]]

@st.cache_data(ttl=60)
def load_ship_tracking_raw():
    try:
        ws = client.open(SHEET_SHIP_TRACKING).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame()
    vals = ws.get_all_values()
    if not vals: return pd.DataFrame()
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header) if len(vals)>1 else pd.DataFrame(columns=header)

    if "æ‰˜ç›˜å·" not in df.columns:
        for c in ["æ‰˜ç›˜ç¼–å·","PalletID","PalletNo","palletid","palletno"]:
            if c in df.columns: df = df.rename(columns={c:"æ‰˜ç›˜å·"}); break
    if "è¿å•æ¸…å•" not in df.columns:
        for c in ["è¿å•å·æ¸…å•","è¿å•åˆ—è¡¨","Waybills","waybills"]:
            if c in df.columns: df = df.rename(columns={c:"è¿å•æ¸…å•"}); break
    if "å¡è½¦å•å·" not in df.columns:
        for c in ["TruckNo","truckno","Truck","truck","å¡è½¦å·"]:
            if c in df.columns: df = df.rename(columns={c:"å¡è½¦å•å·"}); break
    if "åˆ†æ‘Šè´¹ç”¨" not in df.columns:
        for c in ["è´¹ç”¨","Amount","amount","cost"]:
            if c in df.columns: df = df.rename(columns={c:"åˆ†æ‘Šè´¹ç”¨"}); break
    if "æ—¥æœŸ" not in df.columns:
        for c in ["Date","date"]:
            if c in df.columns: df = df.rename(columns={c:"æ—¥æœŸ"}); break

    df["æ‰˜ç›˜å·"]   = df.get("æ‰˜ç›˜å·","").astype(str).str.strip()
    df["å¡è½¦å•å·"] = df.get("å¡è½¦å•å·","").astype(str).str.strip()
    df["åˆ†æ‘Šè´¹ç”¨"] = df.get("åˆ†æ‘Šè´¹ç”¨","").apply(_to_num_safe)
    df["æ—¥æœŸ_raw"] = df.get("æ—¥æœŸ","")
    df["_date"]    = df["æ—¥æœŸ_raw"].apply(_parse_sheet_value_to_date)
    df["æ—¥æœŸ"]     = df["_date"].apply(_fmt_date).replace("", pd.NA)
    df["è¿å•æ¸…å•"] = df.get("è¿å•æ¸…å•","")
    return df[["æ‰˜ç›˜å·","è¿å•æ¸…å•","å¡è½¦å•å·","åˆ†æ‘Šè´¹ç”¨","æ—¥æœŸ"]]

@st.cache_data(ttl=60)
def load_customer_refs_from_arrivals():
    try:
        ws = client.open(SHEET_ARRIVALS_NAME).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    vals = ws.get_all_values()
    if not vals:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)
    cust_col = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)
    wb_col   = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    if not cust_col or not wb_col:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    out = df[[wb_col, cust_col]].copy()
    out[wb_col] = out[wb_col].apply(_norm_waybill_str)
    out[cust_col] = out[cust_col].astype(str).str.strip()
    out = out.rename(columns={wb_col:"è¿å•å·", cust_col:"å®¢æˆ·å•å·"})
    out = out[out["è¿å•å·"]!=""].drop_duplicates(subset=["è¿å•å·"])
    return out[["è¿å•å·","å®¢æˆ·å•å·"]]

@st.cache_data(ttl=60)
def load_customer_refs_from_pallet():
    try:
        ws = client.open(SHEET_PALLET_DETAIL).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    vals = ws.get_all_values()
    if not vals:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)
    cust_col = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)
    wb_col   = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    if not cust_col or not wb_col:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    out = df[[wb_col, cust_col]].copy()
    out[wb_col] = out[wb_col].apply(_norm_waybill_str)
    out[cust_col] = out[cust_col].astype(str).str.strip()
    out = out.rename(columns={wb_col:"è¿å•å·", cust_col:"å®¢æˆ·å•å·"})
    out = out[out["è¿å•å·"]!=""].drop_duplicates(subset=["è¿å•å·"])
    return out[["è¿å•å·","å®¢æˆ·å•å·"]]

# ===================== è¿å•å¢é‡æ„å»º =====================
def _extract_pure_waybills(mixed: str) -> list[str]:
    """
    ä»ã€Šå‘è´§è¿½è¸ªã€‹çš„â€œè¿å•æ¸…å•â€å­—æ®µä¸­æå–çº¯è¿å•å·åˆ—è¡¨ã€‚
    å…¼å®¹ï¼š
      - åˆå¹¶æ ¼å¼ï¼šUSSH202507241130(IP25072400102 IP25072400118 ...)
      - ä¸­/è‹±æ–‡æ‹¬å·ï¼š() / ï¼ˆï¼‰
      - æ‹¬å·å†…å¤šè¡Œã€å¤šç©ºæ ¼ã€å¤šåˆ†éš”ç¬¦
      - æ··åˆåˆ†éš”ç¬¦ï¼šé€—å·/åˆ†å·/æ–œæ /ç«–çº¿/ç©ºç™½/ä¸­æ–‡æ ‡ç‚¹
    é¢å¤–é˜²å‘†ï¼š
      - ä¸¢å¼ƒä»¥ 'IP' å¼€å¤´çš„ç‰‡æ®µï¼ˆå®¢æˆ·POï¼‰
      - ä¸¢å¼ƒä¸å«å­—æ¯æˆ–æ•°å­—/é•¿åº¦å¤ªçŸ­çš„ç‰‡æ®µ
    """
    if _is_blank(mixed):
        return []
    s = str(mixed).strip()
    s_no_paren = re.sub(r"[\(\ï¼ˆ][\s\S]*?[\)\ï¼‰]", "", s, flags=re.DOTALL).strip()
    if not s_no_paren:
        return []
    parts = re.split(r"[,\ï¼Œ;\ï¼›ã€\|\/\s]+", s_no_paren)
    out = []
    for p in parts:
        if not p:
            continue
        token = _norm_waybill_str(p)
        if not token:
            continue
        if token.upper().startswith("IP"):
            continue
        if not (re.search(r"[A-Za-z]", token) and re.search(r"\d", token) and len(token) >= 8):
            continue
        out.append(token)
    return out

def build_waybill_delta():
    """
    èšåˆåˆ°â€œè¿å•ç²’åº¦â€çš„å¢é‡æ•°æ®ï¼Œä¾›éƒ¨åˆ†æ›´æ–°ã€Šè¿å•å…¨é“¾è·¯æ±‡æ€»ã€‹ï¼š
      - ã€æ”¶è´¹é‡ã€ã€ä½“ç§¯ã€ã€ä»“åº“ä»£ç ã€ï¼šç›´æ¥æ¥è‡ªã€Šåˆ°ä»“æ•°æ®è¡¨ã€‹
      - ã€åˆ°ä»“æ—¥æœŸã€ï¼šæ¥è‡ªã€Šåˆ°ä»“æ•°æ®è¡¨ã€‹â€œé¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰â€
      - ã€å‘èµ°è´¹ç”¨/è½¦å·/æ—¥æœŸã€ï¼šä»ç”±ã€Šå‘è´§è¿½è¸ªã€‹æŒ‰â€œæ”¶è´¹é‡â€æƒé‡ï¼ˆç¼ºå¤±åˆ™å‡åˆ†ï¼‰åˆ†æ‘Š
      - ã€åˆ°BCF ä¸‰ä»¶å¥—ã€ï¼šæ¥è‡ªã€bolè‡ªææ˜ç»†ã€
    """
    arrivals = load_arrivals_df()
    bol      = load_bol_waybill_costs()
    track    = load_ship_tracking_raw()

    wb_from_track = set()
    for _, r in track.iterrows():
        for wb in _extract_pure_waybills(r.get("è¿å•æ¸…å•", "")):
            if wb: wb_from_track.add(wb)

    if not wb_from_track:
        return pd.DataFrame(columns=[
            "è¿å•å·","å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
            "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
            "åˆ°BCFæ—¥æœŸ","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ",
            "åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
            "å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
        ])

    arrivals = arrivals[arrivals["è¿å•å·"].isin(wb_from_track)].copy()
    if not bol.empty:
        bol = bol[bol["è¿å•å·"].isin(wb_from_track)].copy()

    weight_map = dict(zip(
        arrivals["è¿å•å·"],
        pd.to_numeric(arrivals["æ”¶è´¹é‡"], errors="coerce")
    ))

    wb2_cost, wb2_trucks, wb2_date = {}, {}, {}
    for _, r in track.iterrows():
        waybills = _extract_pure_waybills(r.get("è¿å•æ¸…å•", ""))
        waybills = [wb for wb in waybills if wb in wb_from_track]
        if not waybills:
            continue
        pallet_cost = _to_num_safe(r.get("åˆ†æ‘Šè´¹ç”¨"))
        truck_no    = r.get("å¡è½¦å•å·", "")
        dt_str      = r.get("æ—¥æœŸ", None)
        dt_obj      = _parse_sheet_value_to_date(dt_str) if not _is_blank(dt_str) else None

        weights = [weight_map.get(wb, None) for wb in waybills]
        valid   = [w for w in weights if w and w > 0]
        if valid and sum(valid) > 0:
            total_w = sum(valid)
            shares  = [(w/total_w if (w and w > 0) else 0.0) for w in weights]
        else:
            shares  = [1.0/len(waybills)] * len(waybills)

        if pallet_cost is not None:
            for wb, s in zip(waybills, shares):
                wb2_cost[wb] = wb2_cost.get(wb, 0.0) + pallet_cost * s
        if truck_no:
            for wb in waybills:
                wb2_trucks.setdefault(wb, set()).add(truck_no)
        if dt_obj:
            for wb in waybills:
                if (wb not in wb2_date) or (dt_obj < wb2_date[wb]):
                    wb2_date[wb] = dt_obj

    out = pd.DataFrame({"è¿å•å·": sorted(wb_from_track)})

    if not arrivals.empty:
        arr2 = arrivals[["è¿å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯","ETD/ATD","ETA/ATA","é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"]].copy()
        arr2 = arr2.rename(columns={
            "ETD/ATD": "å‘å‡º(ETD/ATD)",
            "ETA/ATA": "åˆ°æ¸¯(ETA/ATA)",
            "é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰": "åˆ°ä»“æ—¥æœŸ"
        })
        out = out.merge(arr2, on="è¿å•å·", how="left")
    else:
        out["ä»“åº“ä»£ç "] = pd.NA
        out["æ”¶è´¹é‡"] = pd.NA
        out["ä½“ç§¯"]   = pd.NA
        out["å‘å‡º(ETD/ATD)"] = pd.NA
        out["åˆ°æ¸¯(ETA/ATA)"] = pd.NA
        out["åˆ°ä»“æ—¥æœŸ"]       = pd.NA

    # å®¢æˆ·å•å·åˆå¹¶
    cust_bol = bol[["è¿å•å·","å®¢æˆ·å•å·"]] if (not bol.empty and "å®¢æˆ·å•å·" in bol.columns) \
               else pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    cust_pal = load_customer_refs_from_pallet()
    cust_arr = load_customer_refs_from_arrivals()
    for d in (cust_pal, cust_arr):
        if not d.empty:
            d.drop_duplicates(subset=["è¿å•å·"], inplace=True)
            d["è¿å•å·"] = d["è¿å•å·"].map(_norm_waybill_str)
    cust_all = pd.concat([cust_bol.assign(_pri=1), cust_pal.assign(_pri=2), cust_arr.assign(_pri=3)], ignore_index=True)
    if not cust_all.empty:
        cust_all = cust_all[cust_all["è¿å•å·"].isin(wb_from_track)]
        cust_all = cust_all[~cust_all["å®¢æˆ·å•å·"].isna() & (cust_all["å®¢æˆ·å•å·"].astype(str)!="")]
        cust_all = (cust_all.sort_values(["è¿å•å·","_pri"])
                            .drop_duplicates(subset=["è¿å•å·"], keep="first")[["è¿å•å·","å®¢æˆ·å•å·"]])
        out = out.merge(cust_all, on="è¿å•å·", how="left")
    else:
        out["å®¢æˆ·å•å·"] = pd.NA

    if not bol.empty:
        out = out.merge(bol[["è¿å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]], on="è¿å•å·", how="left")
    else:
        for c in ["åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]:
            out[c] = pd.NA

    out["å‘èµ°è´¹ç”¨"]   = out["è¿å•å·"].map(lambda wb: round(wb2_cost.get(wb, 0.0), 2) if wb in wb2_cost else pd.NA)
    out["å‘èµ°å¡è½¦å·"] = out["è¿å•å·"].map(lambda wb: ", ".join(sorted(wb2_trucks.get(wb, []))) if wb in wb2_trucks else pd.NA)
    out["å‘èµ°æ—¥æœŸ"]   = out["è¿å•å·"].map(lambda wb: _fmt_date(wb2_date.get(wb)) if wb in wb2_date else pd.NA)

    out["æ”¶è´¹é‡"]   = pd.to_numeric(out["æ”¶è´¹é‡"], errors="coerce")
    out["ä½“ç§¯"]     = pd.to_numeric(out["ä½“ç§¯"], errors="coerce").round(2)
    out["åˆ°BCFè´¹ç”¨"] = pd.to_numeric(out["åˆ°BCFè´¹ç”¨"], errors="coerce").round(2)
    out["å‘èµ°è´¹ç”¨"]  = pd.to_numeric(out["å‘èµ°è´¹ç”¨"], errors="coerce").round(2)

    final_cols = [
        "è¿å•å·","å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
        "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
        "åˆ°BCFæ—¥æœŸ","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ",
        "åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
        "å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
    ]
    for c in final_cols:
        if c not in out.columns:
            out[c] = pd.NA
    return out[final_cols]

def upsert_waybill_summary_partial(df_delta: pd.DataFrame):
    target_cols = [
        "å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
        "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
        "åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
        "å‘èµ°æ—¥æœŸ","å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
    ]
    try:
        ws = client.open(SHEET_WB_SUMMARY).sheet1
    except SpreadsheetNotFound:
        st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_WB_SUMMARY}ã€ã€‚è¯·å…ˆåœ¨ Drive ä¸­åˆ›å»ºï¼Œå¹¶åœ¨ç¬¬ä¸€è¡Œå†™å…¥è¡¨å¤´ï¼ˆè‡³å°‘åŒ…å«ï¼šè¿å•å·ï¼‰ã€‚")
        return False

    vals = ws.get_all_values()
    if not vals:
        st.error("ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ä¸ºç©ºä¸”æ— è¡¨å¤´ã€‚è¯·å…ˆåœ¨ç¬¬ä¸€è¡Œå†™å¥½è¡¨å¤´ï¼ˆè‡³å°‘åŒ…å«ï¼šè¿å•å·ï¼‰ã€‚")
        return False

    header_raw = list(vals[0])
    if "è¿å•å·" not in header_raw:
        st.error("ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ç¼ºå°‘â€œè¿å•å·â€è¡¨å¤´ï¼Œæ— æ³•æ›´æ–°ã€‚")
        return False

    header_new = header_raw[:]
    for c in target_cols:
        if c not in header_new:
            header_new.append(c)

    exist = pd.DataFrame(vals[1:], columns=header_raw) if len(vals) > 1 else pd.DataFrame(columns=header_raw)
    for c in header_new:
        if c not in exist.columns:
            exist[c] = ""

    exist["è¿å•å·"] = exist["è¿å•å·"].map(_norm_waybill_str)
    df_delta = df_delta.copy()
    df_delta["è¿å•å·"] = df_delta["è¿å•å·"].map(_norm_waybill_str)

    exist_idx = exist.set_index("è¿å•å·", drop=False)
    delta_idx = df_delta.set_index("è¿å•å·", drop=False)

    common = delta_idx.index.intersection(exist_idx.index)
    if len(common) > 0:
        for col in target_cols:
            if col in header_new and col in delta_idx.columns:
                exist_idx.loc[common, col] = delta_idx.loc[common, col].values

    new_keys = list(delta_idx.index.difference(exist_idx.index))
    if new_keys:
        cols_without_wb = [c for c in header_new if c != "è¿å•å·"]
        new_rows = pd.DataFrame(index=new_keys, columns=cols_without_wb).fillna("")
        new_rows.index.name = "è¿å•å·"
        new_rows = new_rows.reset_index()
        base_delta = df_delta.set_index("è¿å•å·")
        for col in [c for c in target_cols if c in base_delta.columns]:
            new_rows.loc[:, col] = base_delta.reindex(new_rows["è¿å•å·"])[col].values
        exist = pd.concat([exist_idx.reset_index(drop=True), new_rows.reindex(columns=header_new)], ignore_index=True)
    else:
        exist = exist_idx.reset_index(drop=True)

    ws.clear()
    ws.append_row(header_new, value_input_option="USER_ENTERED")
    rows = exist.reindex(columns=header_new).fillna("").values.tolist()
    if rows:
        ws.append_rows(rows, value_input_option="USER_ENTERED")
    return True

# ========= UIï¼šä»…å¯ç”¨â€œæŒ‰æ‰˜ç›˜å‘è´§â€ =========
st.set_page_config(page_title="BCF å‘è´§è°ƒåº¦ï¼ˆä»…æ‰˜ç›˜ï¼‰", layout="wide")
st.title("ğŸšš BCF å‘è´§è°ƒåº¦ï¼ˆä»…æ‰˜ç›˜ï¼‰")

# ======= ä¸Šä¼ æŒ‰é’®æ”¾å¤§ + é«˜äº®æ ·å¼ï¼ˆå…¨å±€ï¼‰=======
st.markdown("""
    <style>
    /* é’ˆå¯¹ä¸Šä¼ åŒºçš„ SUBMIT æŒ‰é’®æ”¾å¤§ + é«˜äº® */
    div.stButton > button[kind="secondary"] {
        font-size: 28px !important;
        font-weight: 900 !important;
        padding: 0.8em 1.6em !important;
        background-color: #ff9800 !important;
        color: white !important;
        border-radius: 10px !important;
        border: 3px solid #e65100 !important;
    }
    </style>
""", unsafe_allow_html=True)

# åˆ·æ–°
c1,_ = st.columns([1,6])
with c1:
    if st.button("ğŸ”„ åˆ·æ–°æ‰˜ç›˜æ•°æ®ç¼“å­˜", key="btn_refresh_pallet"):
        st.cache_data.clear()
        st.rerun()

pallet_df = load_pallet_detail_df()
if pallet_df.empty:
    st.warning("æœªä»ã€æ‰˜ç›˜æ˜ç»†è¡¨ã€è¯»å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥è¡¨å/æƒé™/è¡¨å¤´ã€‚")
    st.stop()

# æ’é™¤å·²å‘è´§æ‰˜ç›˜
shipped_pallets = load_shipped_pallet_ids()
if shipped_pallets:
    pallet_df = pallet_df[~pallet_df["æ‰˜ç›˜å·"].isin(shipped_pallets)]

if pallet_df.empty:
    st.info("å½“å‰å¯å‘è´§çš„æ‰˜ç›˜ä¸ºç©ºï¼ˆå¯èƒ½éƒ½å·²è®°å½•åœ¨ã€å‘è´§è¿½è¸ªã€ï¼‰ã€‚")
    st.stop()

# ä»“åº“ç­›é€‰
wh_opts = ["ï¼ˆå…¨éƒ¨ï¼‰"] + sorted([w for w in pallet_df["ä»“åº“ä»£ç "].dropna().unique() if str(w).strip()])
wh_pick = st.selectbox("é€‰æ‹©ä»“åº“ä»£ç ï¼ˆå¯é€‰ï¼‰", options=wh_opts, key="wh_pallet")
if wh_pick != "ï¼ˆå…¨éƒ¨ï¼‰":
    pallet_df = pallet_df[pallet_df["ä»“åº“ä»£ç "]==wh_pick]

# ----------------------- è¡¨æ ¼ä¸å‹¾é€‰ï¼ˆé˜²æŠ–ç‰ˆï¼‰ -----------------------
show_cols = [
    "æ‰˜ç›˜å·","ä»“åº“ä»£ç ","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)","æ‰˜ç›˜ä½“ç§¯",
    # æ–°å¢å±•ç¤ºåˆ—
    "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ","æ‰˜ç›˜åˆ›å»ºæ—¶é—´",
    "è¿å•æ•°é‡","è¿å•æ¸…å•",
    "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é€ä»“æ—¶æ®µå·®å€¼(å¤©)",
    "ETA/ATA(æŒ‰è¿å•)","ETD/ATD(æŒ‰è¿å•)"
]
for c in show_cols:
    if c not in pallet_df.columns:
        pallet_df[c] = ""

disp_df = pallet_df.copy().reset_index(drop=True)
for c in ["æ‰˜ç›˜ä½“ç§¯","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)"]:
    disp_df[c] = pd.to_numeric(disp_df.get(c, pd.Series()), errors="coerce")

disp_df["æ‰˜ç›˜ä½“ç§¯"] = disp_df["æ‰˜ç›˜ä½“ç§¯"].round(2)
disp_df["é•¿(in)"] = disp_df["é•¿(in)"].round(2)
disp_df["å®½(in)"] = disp_df["å®½(in)"].round(2)
disp_df["é«˜(in)"] = disp_df["é«˜(in)"].round(2)

# å‹¾é€‰åˆ—ç½®é¡¶
if "é€‰æ‹©" not in disp_df.columns:
    disp_df["é€‰æ‹©"] = False
cols_order = ["é€‰æ‹©"] + show_cols

# åˆå§‹åŒ–ä¼šè¯æ€
if "sel_locked" not in st.session_state:
    st.session_state.sel_locked = False
if "locked_df" not in st.session_state:
    st.session_state.locked_df = pd.DataFrame()

# ========== é€‰æ‹©é˜¶æ®µï¼ˆä¸è§¦å‘å…¨é¡µé¢‘ç¹é‡ç®—ï¼‰==========
if not st.session_state.sel_locked:
    with st.form("pick_pallets_form", clear_on_submit=False):
        edited_pal = st.data_editor(
            disp_df[cols_order],
            hide_index=True,
            use_container_width=True,
            height=500,
            column_config={"é€‰æ‹©": st.column_config.CheckboxColumn("é€‰æ‹©")},
            disabled=[c for c in show_cols],  # ä»…â€œé€‰æ‹©â€å¯ç¼–è¾‘
            key="pallet_select_editor"
        )
        # åªæœ‰æäº¤æ—¶æ‰æŠŠå‹¾é€‰ç»“æœå†™å…¥ session_state
        submitted = st.form_submit_button("ğŸ”’ é”å®šé€‰æ‹©å¹¶è¿›å…¥è®¡ç®—")
    if submitted:
        selected_pal = edited_pal[edited_pal["é€‰æ‹©"]==True].copy()
        if len(selected_pal) == 0:
            st.warning("è¯·è‡³å°‘å‹¾é€‰ä¸€ä¸ªæ‰˜ç›˜å†ç‚¹å‡»ã€é”å®šé€‰æ‹©å¹¶è¿›å…¥è®¡ç®—ã€ã€‚")
            st.stop()
        # é”å®šé€‰æ‹© + ä¿å­˜ä¸€æ¬¡å…¨è¡¨å¿«ç…§
        st.session_state.locked_df = selected_pal.reset_index(drop=True)
        st.session_state.all_snapshot_df = disp_df[cols_order].copy()
        st.session_state.sel_locked = True
        st.rerun()

# ========== è®¡ç®—é˜¶æ®µï¼ˆåŸºäºå·²é”å®šçš„é€‰æ‹©ï¼ŒåŒæ—¶æ˜¾ç¤ºæœªé”å®šçš„æ‰˜ç›˜ï¼‰==========
if st.session_state.sel_locked:
    st.success("âœ… å·²é”å®šæ‰˜ç›˜é€‰æ‹©")
    # æä¾›â€œé‡æ–°é€‰æ‹©â€
    if st.button("ğŸ”“ é‡æ–°é€‰æ‹©"):
        st.session_state.sel_locked = False
        st.session_state.locked_df = pd.DataFrame()
        st.rerun()

    # å·²é”å®šæ‰˜ç›˜
    selected_pal = st.session_state.locked_df.copy()
    # å…¶ä½™æœªé”å®šæ‰˜ç›˜ï¼ˆåªè¯»å±•ç¤ºï¼‰
    locked_ids = set(selected_pal["æ‰˜ç›˜å·"].astype(str))
    others_df = disp_df[~disp_df["æ‰˜ç›˜å·"].astype(str).isin(locked_ids)].copy()
    if "é€‰æ‹©" in others_df.columns:
        others_df["é€‰æ‹©"] = False

    left, right = st.columns([2, 2], gap="large")

    with left:
        st.markdown("**ğŸ“¦ å·²é”å®šæ‰˜ç›˜ï¼ˆç”¨äºè®¡ç®—ï¼‰**")
        st.dataframe(
            selected_pal[cols_order],
            use_container_width=True,
            height=320
        )
        st.caption(f"å·²é”å®šæ•°é‡ï¼š{len(selected_pal)}")

    with right:
        st.markdown("**ğŸ—‚ å…¶ä»–æ‰˜ç›˜ï¼ˆæœªé”å®šï¼Œä»…æŸ¥çœ‹ï¼‰**")
        st.dataframe(
            others_df[cols_order],
            use_container_width=True,
            height=320
        )
        st.caption(f"æœªé”å®šæ•°é‡ï¼š{len(others_df)}")

    # é€‰ä¸­æ•°é‡ & ä½“ç§¯åˆè®¡ï¼ˆåªç®—å·²é”å®šï¼‰
    sel_count = int(len(selected_pal))
    sel_vol_sum = pd.to_numeric(selected_pal.get("æ‰˜ç›˜ä½“ç§¯", pd.Series()), errors="coerce").sum()
    m1, m2 = st.columns(2)
    with m1: st.metric("å·²é€‰æ‹©æ‰˜ç›˜æ•°", sel_count)
    with m2: st.metric("é€‰ä¸­ä½“ç§¯åˆè®¡ï¼ˆCBMï¼‰", round(float(sel_vol_sum or 0.0), 2))

    if sel_count == 0:
        st.info("å½“å‰æ²¡æœ‰é”å®šçš„æ‰˜ç›˜ã€‚ç‚¹å‡»ã€é‡æ–°é€‰æ‹©ã€è¿”å›ã€‚")
        st.stop()

    # è½¦æ¬¡ä¿¡æ¯ï¼ˆåˆ†æ‘ŠæŒ‰â€œæ‰˜ç›˜é‡é‡â€ï¼‰
    st.subheader("ğŸ§¾ è½¦æ¬¡ä¿¡æ¯ï¼ˆæ‰˜ç›˜ç»´åº¦åˆ†æ‘Šï¼‰")
    cc1, cc2 = st.columns([2,2])
    with cc1:
        pallet_truck_no = st.text_input("å¡è½¦å•å·ï¼ˆå¿…å¡«ï¼‰", key="pallet_truck_no")
    with cc2:
        pallet_total_cost = st.number_input("æœ¬è½¦æ€»è´¹ç”¨ï¼ˆå¿…å¡«ï¼‰", min_value=0.0, step=1.0, format="%.2f", key="pallet_total_cost")

    if not pallet_truck_no or pallet_total_cost <= 0:
        st.info("è¯·å¡«å†™å¡è½¦å•å·ä¸æœ¬è½¦æ€»è´¹ç”¨ã€‚")
        st.stop()

    # åˆ†æ‘Šè®¡ç®—ï¼ˆæŒ‰æ‰˜ç›˜é‡é‡ï¼‰
    selected_pal["æ‰˜ç›˜é‡é‡"] = pd.to_numeric(selected_pal["æ‰˜ç›˜é‡é‡"], errors="coerce")
    weights = selected_pal["æ‰˜ç›˜é‡é‡"]
    if weights.isna().any() or (weights.dropna() <= 0).any():
        st.error("æ‰€é€‰æ‰˜ç›˜å­˜åœ¨ç¼ºå¤±æˆ–éæ­£çš„ã€æ‰˜ç›˜é‡é‡ã€ï¼Œæ— æ³•åˆ†æ‘Šã€‚è¯·å…ˆåœ¨ã€æ‰˜ç›˜æ˜ç»†è¡¨ã€ä¿®æ­£ã€‚")
        st.stop()

    wt_sum = float(weights.sum())
    if wt_sum <= 0:
        st.error("æ€»æ‰˜ç›˜é‡é‡ä¸º 0ï¼Œæ— æ³•åˆ†æ‘Šã€‚")
        st.stop()

    selected_pal["åˆ†æ‘Šæ¯”ä¾‹"] = weights / wt_sum
    selected_pal["åˆ†æ‘Šè´¹ç”¨_raw"] = selected_pal["åˆ†æ‘Šæ¯”ä¾‹"] * float(pallet_total_cost)
    selected_pal["åˆ†æ‘Šè´¹ç”¨"] = selected_pal["åˆ†æ‘Šè´¹ç”¨_raw"].round(2)
    diff_cost = round(float(pallet_total_cost) - selected_pal["åˆ†æ‘Šè´¹ç”¨"].sum(), 2)
    if abs(diff_cost) >= 0.01:
        selected_pal.loc[selected_pal.index[-1], "åˆ†æ‘Šè´¹ç”¨"] += diff_cost

    upload_df = selected_pal.copy()
    upload_df["å¡è½¦å•å·"] = pallet_truck_no
    upload_df["æ€»è´¹ç”¨"] = round(float(pallet_total_cost), 2)
    upload_df["åˆ†æ‘Šæ¯”ä¾‹"] = (upload_df["åˆ†æ‘Šæ¯”ä¾‹"]*100).round(2).astype(str) + "%"
    upload_df["åˆ†æ‘Šè´¹ç”¨"] = upload_df["åˆ†æ‘Šè´¹ç”¨"].map(lambda x: f"{x:.2f}")
    upload_df["æ€»è´¹ç”¨"] = upload_df["æ€»è´¹ç”¨"].map(lambda x: f"{x:.2f}")
    upload_df["æ‰˜ç›˜ä½“ç§¯"] = pd.to_numeric(upload_df.get("æ‰˜ç›˜ä½“ç§¯", pd.Series()), errors="coerce").round(2)

    preview_cols_pal = [
        "å¡è½¦å•å·","ä»“åº“ä»£ç ","æ‰˜ç›˜å·","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)","æ‰˜ç›˜ä½“ç§¯",
        # åŒæ­¥åœ¨é¢„è§ˆä¹Ÿçœ‹å¾—åˆ°åˆ›å»ºæ—¶é—´ï¼ˆåªè¯»å±•ç¤ºï¼Œä¸å†™å‘è´§è¿½è¸ªï¼‰
        "æ‰˜ç›˜åˆ›å»ºæ—¥æœŸ","æ‰˜ç›˜åˆ›å»ºæ—¶é—´",
        "è¿å•æ•°é‡","è¿å•æ¸…å•",
        "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é€ä»“æ—¶æ®µå·®å€¼(å¤©)",
        "ETA/ATA(æŒ‰è¿å•)","ETD/ATD(æŒ‰è¿å•)",
        "åˆ†æ‘Šæ¯”ä¾‹","åˆ†æ‘Šè´¹ç”¨","æ€»è´¹ç”¨"
    ]
    for c in preview_cols_pal:
        if c not in upload_df.columns:
            upload_df[c] = ""

    st.subheader("âœ… ä¸Šä¼ é¢„è§ˆï¼ˆæ‰˜ç›˜ â†’ å‘è´§è¿½è¸ªï¼‰")
    st.dataframe(upload_df[preview_cols_pal], use_container_width=True, height=360)

    st.markdown("""
    **åˆ†æ‘Šæ¯”ä¾‹è®¡ç®—å…¬å¼ï¼š** æ¯ä¸ªæ‰˜ç›˜çš„åˆ†æ‘Šæ¯”ä¾‹ = è¯¥æ‰˜ç›˜é‡é‡ Ã· æ‰€æœ‰é€‰ä¸­æ‰˜ç›˜é‡é‡æ€»å’Œ  
    **åˆ†æ‘Šè´¹ç”¨è®¡ç®—å…¬å¼ï¼š** æ¯ä¸ªæ‰˜ç›˜çš„åˆ†æ‘Šè´¹ç”¨ = åˆ†æ‘Šæ¯”ä¾‹ Ã— æœ¬è½¦æ€»è´¹ç”¨  
    ï¼ˆæœ€åä¸€æ‰˜ç›˜è‡ªåŠ¨è°ƒæ•´å‡ åˆ†é’±å·®é¢ï¼Œç¡®ä¿æ€»é¢=æœ¬è½¦æ€»è´¹ç”¨ï¼‰
    """)

    # ä¸Šä¼ æŒ‰é’®
    if st.button("ğŸ“¤ è¿½åŠ ä¸Šä¼ åˆ°ã€å‘è´§è¿½è¸ªã€", key="btn_upload_pallet"):
        try:
            ss = client.open(SHEET_SHIP_TRACKING); ws_track = ss.sheet1
        except SpreadsheetNotFound:
            st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_SHIP_TRACKING}ã€ã€‚è¯·å…ˆåœ¨ Google Drive ä¸­åˆ›å»ºï¼Œå¹¶è®¾ç½®ç¬¬ä¸€è¡Œè¡¨å¤´ã€‚")
            st.stop()

        exist = ws_track.get_all_values()
        if not exist:
            st.error("ç›®æ ‡è¡¨ä¸ºç©ºä¸”æ— è¡¨å¤´ã€‚è¯·å…ˆåœ¨ç¬¬ä¸€è¡Œå†™å¥½è¡¨å¤´ï¼ˆæ ‡é¢˜è¡Œï¼‰ã€‚")
            st.stop()

        header_raw = exist[0]
        header_norm = _norm_header(header_raw)
        header_norm_lower = [h.lower() for h in header_norm]
        need_ok = any(n in header_norm for n in ["æ‰˜ç›˜å·","æ‰˜ç›˜ç¼–å·"]) or \
                  any(n in header_norm_lower for n in ["palletid","palletno","palletç¼–å·"])
        if not need_ok:
            st.error("ã€å‘è´§è¿½è¸ªã€ç¼ºå°‘â€œæ‰˜ç›˜å·â€åˆ—ï¼ˆæˆ–ç­‰ä»·åˆ—å¦‚ PalletID/PalletNoï¼‰ã€‚è¯·å…ˆåœ¨ç›®æ ‡è¡¨å¢åŠ è¯¥åˆ—ã€‚")
            st.stop()

        tmp = upload_df.copy()
        if ("æ—¥æœŸ" in header_raw) and ("æ—¥æœŸ" not in tmp.columns):
            tmp["æ—¥æœŸ"] = datetime.today().strftime("%Y-%m-%d")

        for col in header_raw:
            if col not in tmp.columns:
                tmp[col] = ""
        rows = tmp.reindex(columns=header_raw).fillna("").values.tolist()
        ws_track.append_rows(rows, value_input_option="USER_ENTERED")

        st.success(f"å·²ä¸Šä¼  {len(rows)} æ¡åˆ°ã€{SHEET_SHIP_TRACKING}ã€ã€‚å¡è½¦å•å·ï¼š{pallet_truck_no}")

        # æ›´æ–°ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€
        try:
            st.info("æ­£åœ¨æ›´æ–°ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ï¼ˆåªå«ã€å‘è´§è¿½è¸ªã€é‡Œçš„è¿å•ï¼›ä»…æ›´æ–°æŒ‡å®šåˆ—ï¼‰â€¦")
            df_delta = build_waybill_delta()
            if df_delta.empty:
                st.warning("æ²¡æœ‰å¯æ›´æ–°çš„æ•°æ®ï¼ˆæ£€æŸ¥åˆ°ä»“/å‘è´§/è‡ªæè¡¨ï¼‰ã€‚")
            else:
                ok = upsert_waybill_summary_partial(df_delta)
                if ok:
                    st.success(f"å·²æ›´æ–°/æ–°å¢ {len(df_delta)} æ¡åˆ°ã€{SHEET_WB_SUMMARY}ã€ã€‚")
                else:
                    st.warning("æœªèƒ½å†™å…¥ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ï¼šè¯·å…ˆåˆ›å»ºè¯¥è¡¨å¹¶ç¡®ä¿é¦–è¡ŒåŒ…å«â€œè¿å•å·â€åˆ—ã€‚")
        except Exception as e:
            st.warning(f"æ›´æ–°ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€å¤±è´¥ï¼š{e}")

        # ä¸Šä¼ æˆåŠŸåæ¸…ç¼“å­˜/è§£é”
        st.cache_data.clear()
        st.session_state.sel_locked = False
        st.session_state.locked_df = pd.DataFrame()
        st.session_state.pop("pallet_select_editor", None)
        st.rerun()
# ----------------------- é€‰æ‹©ä¸è®¡ç®—ç‰‡æ®µç»“æŸ -----------------------
