# ship_app_tab2.py â€”â€” ä»…å¯ç”¨ æŒ‰æ‰˜ç›˜å‘è´§ï¼ˆTab2 çš„é€»è¾‘ï¼Œå»æ‰ Tab1ï¼‰
# åŠŸèƒ½ï¼š
# - æ‰˜ç›˜é‡é‡/ä½“ç§¯ï¼šé‡é‡åªæ¥è‡ªã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹å¹¶æŒ‰æ‰˜ç›˜æ±‚å’Œï¼›ä½“ç§¯ç”±é•¿å®½é«˜ï¼ˆinchï¼‰è®¡ç®—ä¸º CBMï¼ˆæ¯ä¸ªæ‰˜ç›˜åªè®¡ç®—ä¸€æ¬¡ï¼Œé¿å…é‡å¤ï¼‰
# - ETA/ATAï¼ˆåˆå¹¶åˆ—ï¼‰ã€ETD/ATDï¼ˆExcelåºåˆ— 45824 ç­‰ï¼‰â†’ æ—¥æœŸå­—ç¬¦ä¸²
# - å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´å¦‚â€œ19-21â€â†’ ä¸ä»Šå¤©çš„å¤©æ•°å·®ï¼šx-yï¼ˆé”šå®š ETA/ATA çš„æœˆä»½ï¼Œç¼ºå¤±ç”¨å½“æœˆï¼‰
# - å·²å‘æ‰˜ç›˜è¯»å–è‡ªã€å‘è´§è¿½è¸ªã€ï¼Œå†æ¬¡è¿›å…¥é¡µé¢è‡ªåŠ¨éšè—
# - ä¸Šä¼ åˆ°ã€å‘è´§è¿½è¸ªã€åï¼Œè‡ªåŠ¨ã€éƒ¨åˆ†æ›´æ–°ã€‘ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€
#   ä»…æ›´æ–°ä»¥ä¸‹åˆ—ï¼šå®¢æˆ·å•å·ã€å‘å‡º(ETD/ATD)ã€åˆ°æ¸¯(ETA/ATA)ã€åˆ°BCFæ—¥æœŸã€åˆ°BCFå¡è½¦å·ã€åˆ°BCFè´¹ç”¨ã€å‘èµ°æ—¥æœŸã€å‘èµ°å¡è½¦å·ã€å‘èµ°è´¹ç”¨
# - åªé’ˆå¯¹ã€å‘è´§è¿½è¸ªã€é‡Œå‡ºç°è¿‡çš„è¿å•å·è¿›è¡Œæ±‡æ€»/æ›´æ–°
# - å…¼å®¹ã€bolè‡ªææ˜ç»†ã€/ã€å‘è´§è¿½è¸ªã€å®é™…åˆ—åï¼ˆå¡è½¦å·/è´¹ç”¨/æ—¥æœŸ/å®¢æˆ·å•å·ç­‰ï¼‰

import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from gspread.exceptions import SpreadsheetNotFound
from datetime import datetime, timedelta, date
import calendar
import re

SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

def get_gspread_client():
    # 1) Cloudï¼šä¼˜å…ˆä» st.secrets è¯»å–ï¼ˆStreamlit Cloud é…ç½®çš„æœºå¯†ï¼‰
    if "gcp_service_account" in st.secrets:
        sa_info = st.secrets["gcp_service_account"]  # è¿™æ˜¯ä¸€ä¸ª dictï¼ˆæˆ‘ä»¬ç¨ååœ¨ Cloud é‡Œé…ç½®ï¼‰
        creds = Credentials.from_service_account_info(sa_info, scopes=SCOPES)
        return gspread.authorize(creds)
    # 2) æœ¬åœ°ï¼šå…¼å®¹ä½ åŸæ¥çš„ JSON æ–‡ä»¶
    else:
        creds = Credentials.from_service_account_file("service_accounts.json", scopes=SCOPES)
        return gspread.authorize(creds)

client = get_gspread_client()


# ========= è¡¨åé…ç½® =========
SHEET_ARRIVALS_NAME   = "åˆ°ä»“æ•°æ®è¡¨"       # ETD/ATDã€ETA/ATAï¼ˆåˆå¹¶ï¼‰ã€å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´ã€é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰
SHEET_PALLET_DETAIL   = "æ‰˜ç›˜æ˜ç»†è¡¨"       # æ‰˜ç›˜æ•°æ®ï¼ˆé‡é‡/ä½“ç§¯æ¥è‡ªæ­¤è¡¨ï¼›ä½“ç§¯ç”± L/W/H(inch) è®¡ç®—ä¸º CBMï¼‰
SHEET_SHIP_TRACKING   = "å‘è´§è¿½è¸ªtest"          # æ‰˜ç›˜ç»´åº¦å‡ºä»“è®°å½•ï¼ˆåˆ†æ‘Šåˆ°æ‰˜ç›˜ï¼‰
SHEET_BOL_DETAIL      = "bolè‡ªææ˜ç»†"      # åˆ°BCF æ˜ç»†ï¼ˆåˆ†æ‘Šåˆ°è¿å•ï¼‰
SHEET_WB_SUMMARY      = "è¿å•å…¨é“¾è·¯æ±‡æ€»"    # ä»…éƒ¨åˆ†æ›´æ–°ï¼šå®¢æˆ·å•å·/ETD/ETA/åˆ°BCF/å‘èµ°ç›¸å…³åˆ—

# ========= åŸºç¡€å·¥å…· =========
# === fast sheet open + retry helpers (ADD) ===
import time
from gspread.exceptions import APIError

def get_ws(sheet_title: str, secret_key_name: str | None = None):
    """
    ä¼˜å…ˆç”¨ secrets é‡Œçš„ xxx_key æ‰“å¼€ï¼ˆopen_by_key å¿« & ç¨³å®šï¼‰
    å›é€€åˆ°æŒ‰æ ‡é¢˜æ‰“å¼€ï¼ˆä»…å½“æ²¡é… key æ—¶ï¼‰ã€‚
    """
    key = ""
    try:
        key = st.secrets.get(secret_key_name, "").strip()
    except Exception:
        key = ""
    if key:
        ss = client.open_by_key(key)
    else:
        ss = client.open(sheet_title)
    return ss.sheet1

# ======== REPLACE: _retryï¼ˆæ›´ç¨³å¥ï¼‰ ========
from gspread.exceptions import APIError
import time

def _retry(fn, *args, _retries=6, _base=0.6, _factor=1.8, _max_sleep=6.0, **kwargs):
    """
    å¸¦æŒ‡æ•°é€€é¿çš„å®‰å…¨è°ƒç”¨ï¼š
    - å¯¹ 429/5xx é‡è¯•
    - å¯¹â€œæœªçŸ¥/è¢«è„±æ•â€çš„ APIError ä¹Ÿå°è¯•é‡è¯•å‡ æ¬¡
    - æœ€åä¸€æ¬¡ä»å¤±è´¥åˆ™è¿”å› Noneï¼ˆç”±ä¸Šå±‚å†³å®šæ˜¯å¦ç»§ç»­/æå‰ç»“æŸï¼‰
    """
    last_exc = None
    for i in range(_retries):
        try:
            return fn(*args, **kwargs)
        except APIError as e:
            last_exc = e
            # ä¸€äº›å¹³å°ä¼šæŠŠ status code è„±æ•ï¼Œè¿™é‡Œå°½é‡è·å–ï¼›æ‹¿ä¸åˆ°ä¹Ÿå½“ä½œâ€œå¯é‡è¯•â€
            code = None
            try:
                if getattr(e, "response", None) is not None:
                    code = getattr(e.response, "status_code", None)
            except Exception:
                code = None

            if code in (429, 500, 502, 503, 504) or code is None:
                time.sleep(min(_base * (_factor ** i), _max_sleep))
                continue
            # å…¶å®ƒæ˜ç¡®çš„ 4xxï¼ˆå¦‚ 403/404ï¼‰ç›´æ¥æŠ›å‡º
            raise
        except Exception as e:
            # é APIError çš„å…¶ä»–ä¸´æ—¶é”™è¯¯ï¼Œä¹Ÿè½»å¾®é‡è¯•ä¸€ä¸‹
            last_exc = e
            time.sleep(min(_base * (_factor ** i), _max_sleep))
            continue
    # è¶…è¿‡é‡è¯•æ¬¡æ•°ä»å¤±è´¥ï¼šä¸å†æŠ›å‡ºï¼Œäº¤ç”±ä¸Šå±‚æ ¹æ® None åšæå‰åœæ­¢æˆ–æç¤º
    return None


def _norm_header(cols):
    return [c.replace("\u00A0"," ").replace("\n","").strip().replace(" ","") for c in cols]

def _to_num(x):
    try: return float(str(x).strip())
    except: return None

def _to_num_safe(x):
    try:
        s = str(x).strip().replace(",","")
        s = re.sub(r"[^\d\.\-]", "", s)
        return float(s)
    except:
        return None

def _is_blank(v):
    try:
        if v is None: return True
        if pd.isna(v): return True
        if isinstance(v, str) and v.strip()=="": return True
        return False
    except Exception:
        try: return bool(pd.isna(v))
        except Exception: return False

def _norm_waybill_str(v):
    if _is_blank(v): return ""
    s = str(v).strip()
    if s.endswith(".0"): s = s[:-2]
    try:
        f = float(s)
        if abs(f - round(f)) < 1e-9: s = str(int(round(f)))
    except: pass
    return s

_BASE = datetime(1899, 12, 30)  # Excel/GS èµ·ç‚¹
def _parse_sheet_value_to_date(v):
    if _is_blank(v): return None
    n = _to_num(v)
    if n is not None:
        if 30000 <= n <= 80000:
            return (_BASE + timedelta(days=n)).date()
        if 80000 < n < 200000:
            return (_BASE + timedelta(days=n/2.0)).date()
        if 1e9 <= n < 2e10:
            try: return datetime.utcfromtimestamp(n).date()
            except: pass
        if 1e12 <= n < 2e13:
            try: return datetime.utcfromtimestamp(n/1000.0).date()
            except: pass
        try: return (_BASE + timedelta(days=n)).date()
        except: pass
    try:
        dt = pd.to_datetime(v, errors="coerce")
        if pd.isna(dt): return None
        return dt.date()
    except Exception:
        return None

def _fmt_date(d: date, out_fmt="%Y-%m-%d"):
    return d.strftime(out_fmt) if isinstance(d, date) else ""

def _parse_time_window_days(win: str):
    if not isinstance(win, str): return (None, None)
    s = win.strip()
    if "-" not in s: return (None, None)
    a, b = s.split("-", 1)
    try:
        sa, sb = int(a), int(b)
        if 1 <= sa <= 31 and 1 <= sb <= 31 and sa <= sb:
            return (sa, sb)
    except: pass
    return (None, None)

def _clamp_dom(year, month, dom):
    last = calendar.monthrange(year, month)[1]
    dom = max(1, min(last, dom))
    return date(year, month, dom)

def _promise_diff_days_str(win: str, anchor: date | None):
    sa, sb = _parse_time_window_days(win)
    if sa is None: return ""
    today = date.today()
    if anchor is None: anchor = today
    y, m = anchor.year, anchor.month
    start_d = _clamp_dom(y, m, sa)
    end_d   = _clamp_dom(y, m, sb)
    x = (start_d - today).days
    y2 = (end_d   - today).days
    return f"{x}-{y2}"

def _split_waybill_list(s):
    if _is_blank(s): return []
    parts = re.split(r"[,\ï¼Œ;\ï¼›ã€\|\/\s]+", str(s))
    return [_norm_waybill_str(p) for p in parts if _norm_waybill_str(p)]

# ========= æ•°æ®è¯»å– =========
@st.cache_data(ttl=60)
def load_arrivals_df():
    ws = client.open(SHEET_ARRIVALS_NAME).sheet1
    data = ws.get_all_values(
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not data: return pd.DataFrame()
    header = _norm_header(data[0])
    df = pd.DataFrame(data[1:], columns=header)

    # å…œåº•å¿…éœ€åˆ—
    for need in ["è¿å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡"]:
        if need not in df.columns: df[need] = pd.NA

    # â€”â€” è¯†åˆ«â€œä½“ç§¯â€åˆ—ï¼ˆCBMï¼‰ï¼Œå¸¸è§å‘½åï¼šä½“ç§¯/CBM/ä½“ç§¯m3/ä½“ç§¯(m3)/ä½“ç§¯ï¼ˆm3ï¼‰
    vol_col = next((c for c in ["ä½“ç§¯","CBM","ä½“ç§¯m3","ä½“ç§¯(m3)","ä½“ç§¯ï¼ˆm3ï¼‰"] if c in df.columns), None)
    if vol_col is None:
        df["ä½“ç§¯"] = pd.NA
    else:
        df["ä½“ç§¯"] = pd.to_numeric(df[vol_col], errors="coerce")

    # ETA/ATA åˆå¹¶åˆ—è¯†åˆ«
    etaata_col = None
    for cand in ["ETA/ATA","ETAATA"]:
        if cand in df.columns:
            etaata_col = cand; break

    if "ETD/ATD" not in df.columns: df["ETD/ATD"] = pd.NA
    if "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´" not in df.columns: df["å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´"] = pd.NA

    eta_wh_col = None
    for cand in ["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰","é¢„è®¡åˆ°ä»“æ—¶é—´(æ—¥)","é¢„è®¡åˆ°ä»“æ—¶é—´æ—¥"]:
        if cand in df.columns:
            eta_wh_col = cand; break
    if eta_wh_col is None:
        df["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"] = pd.NA
        eta_wh_col = "é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"

    # è§„èŒƒåŒ–
    df["è¿å•å·"] = df["è¿å•å·"].apply(_norm_waybill_str)
    df["ä»“åº“ä»£ç "] = df["ä»“åº“ä»£ç "].astype(str).str.strip()
    df["æ”¶è´¹é‡"] = pd.to_numeric(df["æ”¶è´¹é‡"], errors="coerce")

    # è§£ææ—¥æœŸåˆ—
    if etaata_col is not None:
        df["_ETAATA_date"] = df[etaata_col].apply(_parse_sheet_value_to_date)
        df["ETA/ATA"] = df["_ETAATA_date"].apply(_fmt_date).replace("", pd.NA)
    else:
        df["_ETAATA_date"] = pd.NA
        df["ETA/ATA"] = pd.NA

    df["_ETD_ATD_date"] = df["ETD/ATD"].apply(_parse_sheet_value_to_date)
    df["ETD/ATD"] = df["_ETD_ATD_date"].apply(_fmt_date).where(
        df["_ETD_ATD_date"].notna(), df["ETD/ATD"]
    )

    df["_ETA_WH_date"] = df[eta_wh_col].apply(_parse_sheet_value_to_date)
    df["é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"] = df["_ETA_WH_date"].apply(_fmt_date).replace("", pd.NA)

    # å»é‡ï¼ˆä¿ç•™æœ€åä¸€æ¡ï¼‰
    df = df.drop_duplicates(subset=["è¿å•å·"], keep="last")

    keep = ["ä»“åº“ä»£ç ","è¿å•å·","æ”¶è´¹é‡","ä½“ç§¯",
            "ETA/ATA","ETD/ATD","å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰",
            "_ETAATA_date"]
    return df[keep]


# ======== REPLACE: load_pallet_detail_dfï¼ˆåˆ†å—+å®¹é”™ï¼Œä¸å¡ä½ï¼‰ ========
@st.cache_data(ttl=60)
def load_pallet_detail_df():
    """
    åˆ†å—è¯»å–ã€Šæ‰˜ç›˜æ˜ç»†è¡¨ã€‹â†’ æ±‡æ€»åˆ°æ‰˜ç›˜ç»´åº¦ï¼š
    - ä»…å–å¿…è¦åˆ—ï¼ˆæ‰˜ç›˜å·/ä»“åº“ä»£ç /è¿å•å· + å¯èƒ½çš„é‡é‡/é•¿å®½é«˜ï¼‰
    - 2000 è¡Œä¸€å—ï¼Œè¿ç»­ç©ºè¡Œé˜ˆå€¼æ—©åœ
    - æ‰€æœ‰ gspread è°ƒç”¨å‡èµ° _retryï¼Œå¤±è´¥åˆ™ä¼˜é›…é™çº§è€ŒéæŠ›å¼‚å¸¸
    """
    # 1) æ‰“å¼€ sheet
    try:
        try:
            ws = get_ws(SHEET_PALLET_DETAIL, "pallet_detail_key")
        except NameError:
            ws = client.open(SHEET_PALLET_DETAIL).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame()

    # 2) è¯»è¡¨å¤´
    header_row = _retry(ws.get_values, "1:1")
    if not header_row:
        # è¿”å›ç©º DFï¼ˆä¸ç»™é¡µé¢å¡æ­»ï¼‰
        return pd.DataFrame()
    raw_header = header_row[0] if header_row else []
    def _norm_cols(cols):
        return [c.replace("\u00A0"," ").replace("\n","").strip().replace(" ","") for c in cols]
    header = _norm_cols(raw_header)
    if not header:
        return pd.DataFrame()

    # åˆ«åæ˜ å°„
    alias = {
        "æ‰˜ç›˜å·":   ["æ‰˜ç›˜å·","æ‰˜ç›˜ID","æ‰˜ç›˜ç¼–å·","PalletID","PalletNo","palletid","palletno"],
        "ä»“åº“ä»£ç ": ["ä»“åº“ä»£ç ","ä»“åº“","WH","Warehouse","warehouse"],
        "è¿å•å·":   ["è¿å•å·","Waybill","waybill","è¿å•ç¼–å·"],
        "æ‰˜ç›˜é‡é‡": ["æ‰˜ç›˜é‡é‡","æ‰˜ç›˜é‡","æ”¶è´¹é‡","æ‰˜ç›˜æ”¶è´¹é‡","è®¡è´¹é‡","è®¡è´¹é‡é‡","é‡é‡"],
        "æ‰˜ç›˜é•¿":   ["æ‰˜ç›˜é•¿","é•¿","é•¿åº¦","Length","length","L"],
        "æ‰˜ç›˜å®½":   ["æ‰˜ç›˜å®½","å®½","å®½åº¦","Width","width","W"],
        "æ‰˜ç›˜é«˜":   ["æ‰˜ç›˜é«˜","é«˜","é«˜åº¦","Height","height","H"],
    }

    col_map = {}
    for key, names in alias.items():
        for nm in names:
            nm_norm = nm.replace(" ","")
            if nm_norm in header:
                col_map[key] = header.index(nm_norm) + 1  # 1-based
                break

    # å¿…éœ€åˆ—æ£€æŸ¥
    for must in ["æ‰˜ç›˜å·","ä»“åº“ä»£ç ","è¿å•å·"]:
        if must not in col_map:
            if must in header:
                col_map[must] = header.index(must) + 1
            else:
                # ç¼ºå…³é”®åˆ—ï¼Œç›´æ¥è¿”å›ç©º
                return pd.DataFrame()

    # 3) åªè¯»å–å¿…è¦åˆ—åŒºé—´
    def _col_letter(n: int) -> str:
        s = ""
        while n:
            n, r = divmod(n-1, 26)
            s = chr(r + 65) + s
        return s
    def _get_range(r1, c1, r2, c2):
        return f"{_col_letter(c1)}{r1}:{_col_letter(c2)}{r2}"

    need_cols = [col_map[k] for k in col_map.keys()]
    c1, c2 = min(need_cols), max(need_cols)

    CHUNK = 2000
    START_ROW = 2
    MAX_ROWS = 200000
    EMPTY_LIMIT = 200

    rows = []
    empty_streak = 0
    cur = START_ROW
    last_row = min(START_ROW + MAX_ROWS - 1, START_ROW + MAX_ROWS - 1)

    while cur <= last_row:
        end = min(cur + CHUNK - 1, last_row)
        rng = _get_range(cur, c1, end, c2)
        chunk = _retry(ws.get_values, rng, major_dimension="ROWS")

        # è‹¥è¿™å—ç›´æ¥å¤±è´¥ï¼ˆ_retry è¿”å› Noneï¼‰ï¼Œä¸è¦æŠ›å¼‚å¸¸ï¼Œæ ‡è®°ä¸ºç©ºç»§ç»­ä¸‹å»
        if chunk is None:
            # å½“æˆç©ºå—å¤„ç†ï¼›ç´¯è®¡ç©ºè¡Œæ•°
            empty_streak += (end - cur + 1)
            if empty_streak >= EMPTY_LIMIT:
                break
            cur = end + 1
            continue

        if not chunk:
            empty_streak += (end - cur + 1)
            if empty_streak >= EMPTY_LIMIT:
                break
            cur = end + 1
            continue

        for row in chunk:
            if len(row) < (c2 - c1 + 1):
                row = row + [""] * ((c2 - c1 + 1) - len(row))
            if all((str(x).strip() == "") for x in row):
                empty_streak += 1
                if empty_streak >= EMPTY_LIMIT:
                    break
                continue
            else:
                empty_streak = 0
            rows.append(row)

        if empty_streak >= EMPTY_LIMIT:
            break
        cur = end + 1

    if not rows:
        return pd.DataFrame()

    # 4) ç»„è£… DFï¼ˆåªå«å¿…è¦åˆ—ï¼‰
    idx_to_name = { (idx - c1): std for std, idx in col_map.items() }
    data = []
    for r in rows:
        rec = {}
        for i, v in enumerate(r):
            if i in idx_to_name:
                rec[idx_to_name[i]] = v
        data.append(rec)
    df = pd.DataFrame(data)

    # 5) è§„èŒƒåŒ–
    def _norm_waybill_str(v):
        if v is None or (isinstance(v,str) and v.strip()==""):
            return ""
        s = str(v).strip()
        if s.endswith(".0"):
            s = s[:-2]
        try:
            f = float(s)
            if abs(f - round(f)) < 1e-9:
                s = str(int(round(f)))
        except:
            pass
        return s

    for k in ["æ‰˜ç›˜å·","ä»“åº“ä»£ç ","è¿å•å·"]:
        if k not in df.columns: df[k] = pd.NA
    df["æ‰˜ç›˜å·"] = df["æ‰˜ç›˜å·"].astype(str).str.strip()
    df["ä»“åº“ä»£ç "] = df["ä»“åº“ä»£ç "].astype(str).str.strip()
    df["è¿å•å·"] = df["è¿å•å·"].apply(_norm_waybill_str)

    for nm in ["æ‰˜ç›˜é‡é‡","æ‰˜ç›˜é•¿","æ‰˜ç›˜å®½","æ‰˜ç›˜é«˜"]:
        if nm in df.columns:
            df[nm] = pd.to_numeric(df[nm], errors="coerce")

    INCH_TO_M = 0.0254
    def _cbm_row(r):
        try:
            L = float(r.get("æ‰˜ç›˜é•¿", float("nan")))
            W = float(r.get("æ‰˜ç›˜å®½", float("nan")))
            H = float(r.get("æ‰˜ç›˜é«˜", float("nan")))
            if L > 0 and W > 0 and H > 0:
                return (L * W * H) * (INCH_TO_M ** 3)
        except Exception:
            pass
        return None
    df["_cbm_row"] = df.apply(_cbm_row, axis=1)

    def _first_valid_num(s):
        s_num = pd.to_numeric(s, errors="coerce").dropna()
        return float(s_num.iloc[0]) if len(s_num) > 0 else None
    def _wb_list(s):
        vals = [x for x in s if isinstance(x, str) and x.strip()]
        return vals

    agg_dict = {
        "æ‰˜ç›˜é‡é‡": ("æ‰˜ç›˜é‡é‡", lambda s: pd.to_numeric(s, errors="coerce").dropna().sum()),
        "æ‰˜ç›˜ä½“ç§¯": ("_cbm_row", _first_valid_num),
        "è¿å•æ¸…å•_list": ("è¿å•å·", _wb_list),
    }
    if "æ‰˜ç›˜é•¿" in df.columns: agg_dict["æ‰˜ç›˜é•¿in"] = ("æ‰˜ç›˜é•¿", _first_valid_num)
    if "æ‰˜ç›˜å®½" in df.columns: agg_dict["æ‰˜ç›˜å®½in"] = ("æ‰˜ç›˜å®½", _first_valid_num)
    if "æ‰˜ç›˜é«˜" in df.columns: agg_dict["æ‰˜ç›˜é«˜in"] = ("æ‰˜ç›˜é«˜", _first_valid_num)

    base = (
        df.groupby(["æ‰˜ç›˜å·", "ä»“åº“ä»£ç "], as_index=False, dropna=False)
          .agg(**agg_dict)
    )

    # åˆå¹¶åˆ°ä»“çš„æ—¶é—´/æ‰¿è¯ºä¿¡æ¯
    arrivals = load_arrivals_df()
    df_join = df.merge(
        arrivals[["è¿å•å·", "ETA/ATA", "ETD/ATD", "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´", "_ETAATA_date"]],
        on="è¿å•å·", how="left"
    )

    # å®¢æˆ·å•å·ï¼ˆè‡ªææ˜ç»†ï¼‰
    bol_cust_df = load_bol_waybill_costs()
    cust_map = {}
    if not bol_cust_df.empty and "è¿å•å·" in bol_cust_df.columns and "å®¢æˆ·å•å·" in bol_cust_df.columns:
        for _, rr in bol_cust_df.iterrows():
            wb = _norm_waybill_str(rr.get("è¿å•å·", ""))
            cust = str(rr.get("å®¢æˆ·å•å·", "")).strip()
            if wb and cust:
                cust_map[wb] = cust

    pallets = []
    for _, brow in base.iterrows():
        pid, wh = brow["æ‰˜ç›˜å·"], brow["ä»“åº“ä»£ç "]
        p_wt = brow.get("æ‰˜ç›˜é‡é‡", None)
        p_vol = brow.get("æ‰˜ç›˜ä½“ç§¯", None)
        waybills = brow.get("è¿å•æ¸…å•_list", []) or []

        waybills_disp = []
        for wb in waybills:
            wb_norm = _norm_waybill_str(wb)
            cust = cust_map.get(wb_norm, "")
            waybills_disp.append(f"{wb}({cust})" if cust else f"{wb}")

        sub = df_join[(df_join["æ‰˜ç›˜å·"] == pid) & (df_join["ä»“åº“ä»£ç "] == wh)]

        lines_etaata, lines_etdatd, promised = [], [], []
        diffs_days = []
        for _, r in sub.iterrows():
            wb = r.get("è¿å•å·", "")
            etaata_s = r.get("ETA/ATA", pd.NA)
            etdatd_s = r.get("ETD/ATD", "")
            promise = r.get("å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´", "")
            anchor = r.get("_ETAATA_date", None)
            lines_etaata.append(f"{wb}: ETA/ATA {etaata_s if str(etaata_s).strip() else '-'}")
            lines_etdatd.append(f"{wb}: {'' if str(etdatd_s).strip()=='' else str(etdatd_s)}")
            if str(promise).strip():
                diffs_days.append(_promise_diff_days_str(str(promise).strip(), anchor or date.today()))
                promised.append(str(promise).strip())

        readable_etaata = " ; ".join(lines_etaata) if lines_etaata else ""
        readable_etdatd = " ; ".join(lines_etdatd) if lines_etdatd else ""
        promised_str = " , ".join(list(dict.fromkeys([p for p in promised if p])))

        def _keyfn(s):
            try:
                a, _ = s.split("-", 1); return int(a)
            except Exception:
                return 10**9
        diff_days_str = sorted(diffs_days, key=_keyfn)[0] if diffs_days else ""

        pallets.append({
            "æ‰˜ç›˜å·": pid,
            "ä»“åº“ä»£ç ": wh,
            "æ‰˜ç›˜é‡é‡": float(p_wt) if pd.notna(p_wt) else None,
            "æ‰˜ç›˜ä½“ç§¯": float(p_vol) if p_vol is not None else None,
            "é•¿(in)": round(float(brow.get("æ‰˜ç›˜é•¿in", None)), 2) if pd.notna(brow.get("æ‰˜ç›˜é•¿in", None)) else None,
            "å®½(in)": round(float(brow.get("æ‰˜ç›˜å®½in", None)), 2) if pd.notna(brow.get("æ‰˜ç›˜å®½in", None)) else None,
            "é«˜(in)": round(float(brow.get("æ‰˜ç›˜é«˜in", None)), 2) if pd.notna(brow.get("æ‰˜ç›˜é«˜in", None)) else None,
            "è¿å•æ•°é‡": len(waybills),
            "è¿å•æ¸…å•": ", ".join(waybills_disp) if waybills_disp else "",
            "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´": promised_str,
            "é€ä»“æ—¶æ®µå·®å€¼(å¤©)": diff_days_str,
            "ETA/ATA(æŒ‰è¿å•)": readable_etaata,
            "ETD/ATD(æŒ‰è¿å•)": readable_etdatd,
        })

    out = pd.DataFrame(pallets)
    if out.empty:
        return out
    return out[out["æ‰˜ç›˜å·"].astype(str).str.strip() != ""]



@st.cache_data(ttl=60)
def load_shipped_pallet_ids():
    try:
        ws = client.open(SHEET_SHIP_TRACKING).sheet1
    except SpreadsheetNotFound:
        return set()
    vals = ws.get_all_values()
    if not vals: return set()
    raw_header = vals[0]
    norm_header = _norm_header(raw_header)
    norm_header_lower = [h.lower() for h in norm_header]
    candidates = ["æ‰˜ç›˜å·", "æ‰˜ç›˜ç¼–å·", "æ‰˜ç›˜id", "palletid", "palletno", "palletç¼–å·"]
    col_idx = None
    for name in candidates:
        n = name.replace(" ","")
        if n in norm_header: col_idx = norm_header.index(n); break
        if n.lower() in norm_header_lower: col_idx = norm_header_lower.index(n.lower()); break
    if col_idx is None: return set()
    shipped = set()
    for r in vals[1:]:
        if len(r)>col_idx:
            pid = str(r[col_idx]).strip()
            if pid: shipped.add(pid)
    return shipped

@st.cache_data(ttl=60)
def load_bol_waybill_costs():
    try:
        ws = client.open(SHEET_BOL_DETAIL).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame()
    vals = ws.get_all_values(
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not vals:
        return pd.DataFrame()
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header) if len(vals)>1 else pd.DataFrame(columns=header)

    col_wb    = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    col_truck = next((c for c in ["å¡è½¦å•å·","å¡è½¦å·","TruckNo","truckno","Truck","truck"] if c in df.columns), None)
    col_cost  = next((c for c in ["åˆ†æ‘Šè´¹ç”¨","è´¹ç”¨","Amount","amount","cost"] if c in df.columns), None)
    col_date  = next((c for c in ["ETA(åˆ°BCF)","ETAåˆ°BCF","åˆ°BCFETA","æ—¥æœŸ","Date","date"] if c in df.columns), None)
    col_cust  = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)

    if col_wb is None or col_cost is None:
        return pd.DataFrame()

    df[col_wb] = df[col_wb].apply(_norm_waybill_str)
    df[col_cost] = df[col_cost].apply(_to_num_safe)
    if col_truck: df[col_truck] = df[col_truck].astype(str).str.strip()
    if col_cust:  df[col_cust]  = df[col_cust].astype(str).str.strip()
    if col_date:
        df["_date"] = df[col_date].apply(_parse_sheet_value_to_date)
        df[col_date] = df["_date"].apply(_fmt_date).replace("", pd.NA)

    if df.empty:
        return pd.DataFrame()

    agg_dict = {col_cost: "sum"}
    if col_truck:
        agg_dict[col_truck] = lambda s: ", ".join(sorted(set([x.strip() for x in s if not _is_blank(x)])))
    if col_date:
        agg_dict[col_date] = "min"
    if col_cust:
        def _first_nonblank(s):
            for x in s:
                if not _is_blank(x): return x
            return ""
        agg_dict[col_cust] = _first_nonblank

    g = df.groupby(col_wb, dropna=False).agg(agg_dict).reset_index()

    rename_map = {col_wb:"è¿å•å·"}
    if col_truck: rename_map[col_truck] = "åˆ°BCFå¡è½¦å·"
    if col_cost:  rename_map[col_cost]  = "åˆ°BCFè´¹ç”¨"
    if col_date:  rename_map[col_date]  = "åˆ°BCFæ—¥æœŸ"
    if col_cust:  rename_map[col_cust]  = "å®¢æˆ·å•å·"
    g = g.rename(columns=rename_map)
    for c in ["è¿å•å·","å®¢æˆ·å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]:
        if c not in g.columns: g[c] = pd.NA
    g["åˆ°BCFè´¹ç”¨"] = pd.to_numeric(g["åˆ°BCFè´¹ç”¨"], errors="coerce").round(2)
    return g[["è¿å•å·","å®¢æˆ·å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]]

@st.cache_data(ttl=60)
def load_ship_tracking_raw():
    try:
        ws = client.open(SHEET_SHIP_TRACKING).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame()
    vals = ws.get_all_values()
    if not vals: return pd.DataFrame()
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header) if len(vals)>1 else pd.DataFrame(columns=header)

    if "æ‰˜ç›˜å·" not in df.columns:
        for c in ["æ‰˜ç›˜ç¼–å·","PalletID","PalletNo","palletid","palletno"]:
            if c in df.columns: df = df.rename(columns={c:"æ‰˜ç›˜å·"}); break
    if "è¿å•æ¸…å•" not in df.columns:
        for c in ["è¿å•å·æ¸…å•","è¿å•åˆ—è¡¨","Waybills","waybills"]:
            if c in df.columns: df = df.rename(columns={c:"è¿å•æ¸…å•"}); break
    if "å¡è½¦å•å·" not in df.columns:
        for c in ["TruckNo","truckno","Truck","truck","å¡è½¦å·"]:
            if c in df.columns: df = df.rename(columns={c:"å¡è½¦å•å·"}); break
    if "åˆ†æ‘Šè´¹ç”¨" not in df.columns:
        for c in ["è´¹ç”¨","Amount","amount","cost"]:
            if c in df.columns: df = df.rename(columns={c:"åˆ†æ‘Šè´¹ç”¨"}); break
    if "æ—¥æœŸ" not in df.columns:
        for c in ["Date","date"]:
            if c in df.columns: df = df.rename(columns={c:"æ—¥æœŸ"}); break

    df["æ‰˜ç›˜å·"]   = df.get("æ‰˜ç›˜å·","").astype(str).str.strip()
    df["å¡è½¦å•å·"] = df.get("å¡è½¦å•å·","").astype(str).str.strip()
    df["åˆ†æ‘Šè´¹ç”¨"] = df.get("åˆ†æ‘Šè´¹ç”¨","").apply(_to_num_safe)
    df["æ—¥æœŸ_raw"] = df.get("æ—¥æœŸ","")
    df["_date"]    = df["æ—¥æœŸ_raw"].apply(_parse_sheet_value_to_date)
    df["æ—¥æœŸ"]     = df["_date"].apply(_fmt_date).replace("", pd.NA)
    df["è¿å•æ¸…å•"] = df.get("è¿å•æ¸…å•","")
    return df[["æ‰˜ç›˜å·","è¿å•æ¸…å•","å¡è½¦å•å·","åˆ†æ‘Šè´¹ç”¨","æ—¥æœŸ"]]

@st.cache_data(ttl=60)
def load_customer_refs_from_arrivals():
    try:
        ws = client.open(SHEET_ARRIVALS_NAME).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    vals = ws.get_all_values()
    if not vals:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)
    cust_col = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)
    wb_col   = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    if not cust_col or not wb_col:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    out = df[[wb_col, cust_col]].copy()
    out[wb_col] = out[wb_col].apply(_norm_waybill_str)
    out[cust_col] = out[cust_col].astype(str).str.strip()
    out = out.rename(columns={wb_col:"è¿å•å·", cust_col:"å®¢æˆ·å•å·"})
    out = out[out["è¿å•å·"]!=""].drop_duplicates(subset=["è¿å•å·"])
    return out[["è¿å•å·","å®¢æˆ·å•å·"]]

@st.cache_data(ttl=60)
def load_customer_refs_from_pallet():
    try:
        ws = client.open(SHEET_PALLET_DETAIL).sheet1
    except SpreadsheetNotFound:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    vals = ws.get_all_values()
    if not vals:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    header = _norm_header(vals[0])
    df = pd.DataFrame(vals[1:], columns=header)
    cust_col = next((c for c in ["å®¢æˆ·å•å·","å®¢æˆ·PO","å®¢æˆ·POå·","å®¢æˆ·å‚è€ƒå·","CustomerPO","CustomerRef","Reference"] if c in df.columns), None)
    wb_col   = next((c for c in ["è¿å•å·","Waybill","waybill"] if c in df.columns), None)
    if not cust_col or not wb_col:
        return pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    out = df[[wb_col, cust_col]].copy()
    out[wb_col] = out[wb_col].apply(_norm_waybill_str)
    out[cust_col] = out[cust_col].astype(str).str.strip()
    out = out.rename(columns={wb_col:"è¿å•å·", cust_col:"å®¢æˆ·å•å·"})
    out = out[out["è¿å•å·"]!=""].drop_duplicates(subset=["è¿å•å·"])
    return out[["è¿å•å·","å®¢æˆ·å•å·"]]

# ===================== REPLACEMENT START =====================
def _extract_pure_waybills(mixed: str) -> list[str]:
    """
    ä»ã€Šå‘è´§è¿½è¸ªã€‹çš„â€œè¿å•æ¸…å•â€å­—æ®µä¸­æå–çº¯è¿å•å·åˆ—è¡¨ã€‚
    å…¼å®¹ï¼š
      - åˆå¹¶æ ¼å¼ï¼šUSSH202507241130(IP25072400102 IP25072400118 ...)
      - ä¸­/è‹±æ–‡æ‹¬å·ï¼š() / ï¼ˆï¼‰
      - æ‹¬å·å†…å¤šè¡Œã€å¤šç©ºæ ¼ã€å¤šåˆ†éš”ç¬¦
      - æ··åˆåˆ†éš”ç¬¦ï¼šé€—å·/åˆ†å·/æ–œæ /ç«–çº¿/ç©ºç™½/ä¸­æ–‡æ ‡ç‚¹
    é¢å¤–é˜²å‘†ï¼š
      - ä¸¢å¼ƒä»¥ 'IP' å¼€å¤´çš„ç‰‡æ®µï¼ˆå®¢æˆ·POï¼‰
      - ä¸¢å¼ƒçº¯æ•°å­—/çº¯å­—æ¯æˆ–é•¿åº¦å¤ªçŸ­çš„ç‰‡æ®µ
    """
    if _is_blank(mixed):
        return []

    s = str(mixed).strip()

    # 1) å…ˆæ•´ä½“å‰¥ç¦»æ‹¬å·å†…å†…å®¹ï¼ˆè·¨è¡Œéè´ªå©ªï¼‰ï¼Œé¿å…æ‹¬å·é‡Œçš„ IP... è¢«å½“æˆç‹¬ç«‹ token
    #    æ”¯æŒä¸­/è‹±æ–‡æ‹¬å·ï¼›DOTALL å…è®¸åŒ¹é…æ¢è¡Œ
    s_no_paren = re.sub(r"[\(\ï¼ˆ][\s\S]*?[\)\ï¼‰]", "", s, flags=re.DOTALL).strip()

    if not s_no_paren:
        return []

    # 2) å†è¿›è¡Œåˆ†å‰²
    parts = re.split(r"[,\ï¼Œ;\ï¼›ã€\|\/\s]+", s_no_paren)

    # 3) é€ä¸ªè§„èŒƒåŒ– & è¿‡æ»¤
    out = []
    for p in parts:
        if not p:
            continue
        token = _norm_waybill_str(p)

        if not token:
            continue
        # ä¸¢å¼ƒä»¥ 'IP' å¼€å¤´ï¼ˆå…¸å‹å®¢æˆ·POï¼‰
        if token.upper().startswith("IP"):
            continue
        # ä¸¢å¼ƒæ˜æ˜¾ä¸åƒè¿å•å·çš„ç‰‡æ®µï¼ˆå¯æŒ‰éœ€æ”¾å®½/æ”¶ç´§ï¼‰
        # è§„åˆ™ï¼šå¿…é¡»åŒ…å«å­—æ¯+æ•°å­—çš„ç»„åˆï¼Œä¸”é•¿åº¦â‰¥8
        if not (re.search(r"[A-Za-z]", token) and re.search(r"\d", token) and len(token) >= 8):
            continue

        out.append(token)

    return out



def build_waybill_delta():
    """
    èšåˆåˆ°â€œè¿å•ç²’åº¦â€çš„å¢é‡æ•°æ®ï¼Œä¾›éƒ¨åˆ†æ›´æ–°ã€Šè¿å•å…¨é“¾è·¯æ±‡æ€»ã€‹ï¼š
      - ã€æ”¶è´¹é‡ã€ã€ä½“ç§¯ã€ã€ä»“åº“ä»£ç ã€ï¼šç›´æ¥æ¥è‡ªã€Šåˆ°ä»“æ•°æ®è¡¨ã€‹
      - ã€åˆ°ä»“æ—¥æœŸã€ï¼šæ¥è‡ªã€Šåˆ°ä»“æ•°æ®è¡¨ã€‹â€œé¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰â€
      - ã€å‘èµ°è´¹ç”¨/è½¦å·/æ—¥æœŸã€ï¼šä»ç”±ã€Šå‘è´§è¿½è¸ªã€‹æŒ‰â€œæ”¶è´¹é‡â€æƒé‡ï¼ˆç¼ºå¤±åˆ™å‡åˆ†ï¼‰åˆ†æ‘Š
      - ã€åˆ°BCF ä¸‰ä»¶å¥—ã€ï¼šæ¥è‡ªã€bolè‡ªææ˜ç»†ã€
    """
    arrivals = load_arrivals_df()
    bol      = load_bol_waybill_costs()
    track    = load_ship_tracking_raw()

    wb_from_track = set()
    for _, r in track.iterrows():
        for wb in _extract_pure_waybills(r.get("è¿å•æ¸…å•", "")):
            if wb: wb_from_track.add(wb)

    if not wb_from_track:
        return pd.DataFrame(columns=[
            "è¿å•å·","å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
            "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
            "åˆ°BCFæ—¥æœŸ","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ",
            "åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
            "å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
        ])

    arrivals = arrivals[arrivals["è¿å•å·"].isin(wb_from_track)].copy()
    if not bol.empty:
        bol = bol[bol["è¿å•å·"].isin(wb_from_track)].copy()

    weight_map = dict(zip(
        arrivals["è¿å•å·"],
        pd.to_numeric(arrivals["æ”¶è´¹é‡"], errors="coerce")
    ))

    wb2_cost, wb2_trucks, wb2_date = {}, {}, {}
    for _, r in track.iterrows():
        waybills = _extract_pure_waybills(r.get("è¿å•æ¸…å•", ""))
        waybills = [wb for wb in waybills if wb in wb_from_track]
        if not waybills:
            continue
        pallet_cost = _to_num_safe(r.get("åˆ†æ‘Šè´¹ç”¨"))
        truck_no    = r.get("å¡è½¦å•å·", "")
        dt_str      = r.get("æ—¥æœŸ", None)
        dt_obj      = _parse_sheet_value_to_date(dt_str) if not _is_blank(dt_str) else None

        weights = [weight_map.get(wb, None) for wb in waybills]
        valid   = [w for w in weights if w and w > 0]
        if valid and sum(valid) > 0:
            total_w = sum(valid)
            shares  = [(w/total_w if (w and w > 0) else 0.0) for w in weights]
        else:
            shares  = [1.0/len(waybills)] * len(waybills)

        if pallet_cost is not None:
            for wb, s in zip(waybills, shares):
                wb2_cost[wb] = wb2_cost.get(wb, 0.0) + pallet_cost * s
        if truck_no:
            for wb in waybills:
                wb2_trucks.setdefault(wb, set()).add(truck_no)
        if dt_obj:
            for wb in waybills:
                if (wb not in wb2_date) or (dt_obj < wb2_date[wb]):
                    wb2_date[wb] = dt_obj

    out = pd.DataFrame({"è¿å•å·": sorted(wb_from_track)})

    if not arrivals.empty:
        arr2 = arrivals[["è¿å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯","ETD/ATD","ETA/ATA","é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰"]].copy()
        arr2 = arr2.rename(columns={
            "ETD/ATD": "å‘å‡º(ETD/ATD)",
            "ETA/ATA": "åˆ°æ¸¯(ETA/ATA)",
            "é¢„è®¡åˆ°ä»“æ—¶é—´ï¼ˆæ—¥ï¼‰": "åˆ°ä»“æ—¥æœŸ"
        })
        out = out.merge(arr2, on="è¿å•å·", how="left")
    else:
        out["ä»“åº“ä»£ç "] = pd.NA
        out["æ”¶è´¹é‡"] = pd.NA
        out["ä½“ç§¯"]   = pd.NA
        out["å‘å‡º(ETD/ATD)"] = pd.NA
        out["åˆ°æ¸¯(ETA/ATA)"] = pd.NA
        out["åˆ°ä»“æ—¥æœŸ"]       = pd.NA

    # å®¢æˆ·å•å·åˆå¹¶é€»è¾‘ï¼ˆç•¥ï¼ŒåŒä¹‹å‰ï¼‰
    cust_bol = bol[["è¿å•å·","å®¢æˆ·å•å·"]] if (not bol.empty and "å®¢æˆ·å•å·" in bol.columns) \
               else pd.DataFrame(columns=["è¿å•å·","å®¢æˆ·å•å·"])
    cust_pal = load_customer_refs_from_pallet()
    cust_arr = load_customer_refs_from_arrivals()
    for d in (cust_pal, cust_arr):
        if not d.empty:
            d.drop_duplicates(subset=["è¿å•å·"], inplace=True)
            d["è¿å•å·"] = d["è¿å•å·"].map(_norm_waybill_str)
    cust_all = pd.concat([cust_bol.assign(_pri=1), cust_pal.assign(_pri=2), cust_arr.assign(_pri=3)], ignore_index=True)
    if not cust_all.empty:
        cust_all = cust_all[cust_all["è¿å•å·"].isin(wb_from_track)]
        cust_all = cust_all[~cust_all["å®¢æˆ·å•å·"].isna() & (cust_all["å®¢æˆ·å•å·"].astype(str)!="")]
        cust_all = (cust_all.sort_values(["è¿å•å·","_pri"])
                            .drop_duplicates(subset=["è¿å•å·"], keep="first")[["è¿å•å·","å®¢æˆ·å•å·"]])
        out = out.merge(cust_all, on="è¿å•å·", how="left")
    else:
        out["å®¢æˆ·å•å·"] = pd.NA

    if not bol.empty:
        out = out.merge(bol[["è¿å•å·","åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]], on="è¿å•å·", how="left")
    else:
        for c in ["åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨"]:
            out[c] = pd.NA

    out["å‘èµ°è´¹ç”¨"]   = out["è¿å•å·"].map(lambda wb: round(wb2_cost.get(wb, 0.0), 2) if wb in wb2_cost else pd.NA)
    out["å‘èµ°å¡è½¦å·"] = out["è¿å•å·"].map(lambda wb: ", ".join(sorted(wb2_trucks.get(wb, []))) if wb in wb2_trucks else pd.NA)
    out["å‘èµ°æ—¥æœŸ"]   = out["è¿å•å·"].map(lambda wb: _fmt_date(wb2_date.get(wb)) if wb in wb2_date else pd.NA)

    out["æ”¶è´¹é‡"]   = pd.to_numeric(out["æ”¶è´¹é‡"], errors="coerce")
    out["ä½“ç§¯"]     = pd.to_numeric(out["ä½“ç§¯"], errors="coerce").round(2)
    out["åˆ°BCFè´¹ç”¨"] = pd.to_numeric(out["åˆ°BCFè´¹ç”¨"], errors="coerce").round(2)
    out["å‘èµ°è´¹ç”¨"]  = pd.to_numeric(out["å‘èµ°è´¹ç”¨"], errors="coerce").round(2)

    final_cols = [
        "è¿å•å·","å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
        "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
        "åˆ°BCFæ—¥æœŸ","å‘èµ°æ—¥æœŸ","åˆ°ä»“æ—¥æœŸ",
        "åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
        "å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
    ]
    for c in final_cols:
        if c not in out.columns:
            out[c] = pd.NA
    return out[final_cols]

# ===================== REPLACEMENT END =====================


def upsert_waybill_summary_partial(df_delta: pd.DataFrame):
    target_cols = [
    "å®¢æˆ·å•å·","ä»“åº“ä»£ç ","æ”¶è´¹é‡","ä½“ç§¯",
    "å‘å‡º(ETD/ATD)","åˆ°æ¸¯(ETA/ATA)",
    "åˆ°BCFæ—¥æœŸ","åˆ°BCFå¡è½¦å·","åˆ°BCFè´¹ç”¨",
    "å‘èµ°æ—¥æœŸ","å‘èµ°å¡è½¦å·","å‘èµ°è´¹ç”¨"
]


    try:
        ws = client.open(SHEET_WB_SUMMARY).sheet1
    except SpreadsheetNotFound:
        st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_WB_SUMMARY}ã€ã€‚è¯·å…ˆåœ¨ Drive ä¸­åˆ›å»ºï¼Œå¹¶åœ¨ç¬¬ä¸€è¡Œå†™å…¥è¡¨å¤´ï¼ˆè‡³å°‘åŒ…å«ï¼šè¿å•å·ï¼‰ã€‚")
        return False

    vals = ws.get_all_values()
    if not vals:
        st.error("ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ä¸ºç©ºä¸”æ— è¡¨å¤´ã€‚è¯·å…ˆåœ¨ç¬¬ä¸€è¡Œå†™å¥½è¡¨å¤´ï¼ˆè‡³å°‘åŒ…å«ï¼šè¿å•å·ï¼‰ã€‚")
        return False

    header_raw = list(vals[0])
    if "è¿å•å·" not in header_raw:
        st.error("ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ç¼ºå°‘â€œè¿å•å·â€è¡¨å¤´ï¼Œæ— æ³•æ›´æ–°ã€‚")
        return False

    header_new = header_raw[:]
    for c in target_cols:
        if c not in header_new:
            header_new.append(c)

    exist = pd.DataFrame(vals[1:], columns=header_raw) if len(vals) > 1 else pd.DataFrame(columns=header_raw)
    for c in header_new:
        if c not in exist.columns:
            exist[c] = ""

    exist["è¿å•å·"] = exist["è¿å•å·"].map(_norm_waybill_str)
    df_delta = df_delta.copy()
    df_delta["è¿å•å·"] = df_delta["è¿å•å·"].map(_norm_waybill_str)

    exist_idx = exist.set_index("è¿å•å·", drop=False)
    delta_idx = df_delta.set_index("è¿å•å·", drop=False)

    common = delta_idx.index.intersection(exist_idx.index)
    if len(common) > 0:
        for col in target_cols:
            if col in header_new and col in delta_idx.columns:
                exist_idx.loc[common, col] = delta_idx.loc[common, col].values

    new_keys = list(delta_idx.index.difference(exist_idx.index))
    if new_keys:
        cols_without_wb = [c for c in header_new if c != "è¿å•å·"]
        new_rows = pd.DataFrame(index=new_keys, columns=cols_without_wb).fillna("")
        new_rows.index.name = "è¿å•å·"
        new_rows = new_rows.reset_index()

        base_delta = df_delta.set_index("è¿å•å·")
        for col in [c for c in target_cols if c in base_delta.columns]:
            new_rows.loc[:, col] = base_delta.reindex(new_rows["è¿å•å·"])[col].values

        exist = pd.concat([exist_idx.reset_index(drop=True), new_rows.reindex(columns=header_new)], ignore_index=True)
    else:
        exist = exist_idx.reset_index(drop=True)

    ws.clear()
    ws.append_row(header_new, value_input_option="USER_ENTERED")
    rows = exist.reindex(columns=header_new).fillna("").values.tolist()
    if rows:
        ws.append_rows(rows, value_input_option="USER_ENTERED")
    return True

# ========= UIï¼šä»…å¯ç”¨â€œæŒ‰æ‰˜ç›˜å‘è´§â€ =========
st.set_page_config(page_title="BCF å‘è´§è°ƒåº¦ï¼ˆä»…æ‰˜ç›˜ï¼‰", layout="wide")
st.title("ğŸšš BCF å‘è´§è°ƒåº¦ï¼ˆä»…æ‰˜ç›˜ï¼‰")

# ======= ä¸Šä¼ æŒ‰é’®æ”¾å¤§ + é«˜äº®æ ·å¼ï¼ˆå…¨å±€ï¼‰=======
st.markdown("""
    <style>
    /* é’ˆå¯¹ä¸Šä¼ åŒºçš„ SUBMIT æŒ‰é’®æ”¾å¤§ + é«˜äº® */
    div.stButton > button[kind="secondary"] {
        font-size: 28px !important;
        font-weight: 900 !important;
        padding: 0.8em 1.6em !important;
        background-color: #ff9800 !important;
        color: white !important;
        border-radius: 10px !important;
        border: 3px solid #e65100 !important;
    }
    </style>
""", unsafe_allow_html=True)

# åˆ·æ–°
c1,_ = st.columns([1,6])
with c1:
    if st.button("ğŸ”„ åˆ·æ–°æ‰˜ç›˜æ•°æ®ç¼“å­˜", key="btn_refresh_pallet"):
        st.cache_data.clear()
        st.rerun()

pallet_df = load_pallet_detail_df()
if pallet_df.empty:
    st.warning("æœªä»ã€æ‰˜ç›˜æ˜ç»†è¡¨ã€è¯»å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥è¡¨å/æƒé™/è¡¨å¤´ã€‚")
    st.stop()

# æ’é™¤å·²å‘è´§æ‰˜ç›˜
shipped_pallets = load_shipped_pallet_ids()
if shipped_pallets:
    pallet_df = pallet_df[~pallet_df["æ‰˜ç›˜å·"].isin(shipped_pallets)]

if pallet_df.empty:
    st.info("å½“å‰å¯å‘è´§çš„æ‰˜ç›˜ä¸ºç©ºï¼ˆå¯èƒ½éƒ½å·²è®°å½•åœ¨ã€å‘è´§è¿½è¸ªã€ï¼‰ã€‚")
    st.stop()

# ä»“åº“ç­›é€‰
wh_opts = ["ï¼ˆå…¨éƒ¨ï¼‰"] + sorted([w for w in pallet_df["ä»“åº“ä»£ç "].dropna().unique() if str(w).strip()])
wh_pick = st.selectbox("é€‰æ‹©ä»“åº“ä»£ç ï¼ˆå¯é€‰ï¼‰", options=wh_opts, key="wh_pallet")
if wh_pick != "ï¼ˆå…¨éƒ¨ï¼‰":
    pallet_df = pallet_df[pallet_df["ä»“åº“ä»£ç "]==wh_pick]

# è¡¨æ ¼ä¸å‹¾é€‰
# ----------------------- è¡¨æ ¼ä¸å‹¾é€‰ï¼ˆé˜²æŠ–ç‰ˆï¼‰ -----------------------
show_cols = [
    "æ‰˜ç›˜å·","ä»“åº“ä»£ç ","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)","æ‰˜ç›˜ä½“ç§¯",
    "è¿å•æ•°é‡","è¿å•æ¸…å•",
    "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é€ä»“æ—¶æ®µå·®å€¼(å¤©)",
    "ETA/ATA(æŒ‰è¿å•)","ETD/ATD(æŒ‰è¿å•)"
]
for c in show_cols:
    if c not in pallet_df.columns:
        pallet_df[c] = ""

disp_df = pallet_df.copy().reset_index(drop=True)
for c in ["æ‰˜ç›˜ä½“ç§¯","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)"]:
    disp_df[c] = pd.to_numeric(disp_df.get(c, pd.Series()), errors="coerce")

disp_df["æ‰˜ç›˜ä½“ç§¯"] = disp_df["æ‰˜ç›˜ä½“ç§¯"].round(2)
disp_df["é•¿(in)"] = disp_df["é•¿(in)"].round(2)
disp_df["å®½(in)"] = disp_df["å®½(in)"].round(2)
disp_df["é«˜(in)"] = disp_df["é«˜(in)"].round(2)

# å‹¾é€‰åˆ—ç½®é¡¶
if "é€‰æ‹©" not in disp_df.columns:
    disp_df["é€‰æ‹©"] = False
cols_order = ["é€‰æ‹©"] + show_cols

# åˆå§‹åŒ–ä¼šè¯æ€
if "sel_locked" not in st.session_state:
    st.session_state.sel_locked = False
if "locked_df" not in st.session_state:
    st.session_state.locked_df = pd.DataFrame()

# ========== é€‰æ‹©é˜¶æ®µï¼ˆä¸è§¦å‘å…¨é¡µé¢‘ç¹é‡ç®—ï¼‰==========
if not st.session_state.sel_locked:
    with st.form("pick_pallets_form", clear_on_submit=False):
        edited_pal = st.data_editor(
            disp_df[cols_order],
            hide_index=True,
            use_container_width=True,
            height=500,
            column_config={"é€‰æ‹©": st.column_config.CheckboxColumn("é€‰æ‹©")},
            disabled=[c for c in show_cols],  # ä»…â€œé€‰æ‹©â€å¯ç¼–è¾‘
            key="pallet_select_editor"
        )
        # åªæœ‰æäº¤æ—¶æ‰æŠŠå‹¾é€‰ç»“æœå†™å…¥ session_state
        submitted = st.form_submit_button("ğŸ”’ é”å®šé€‰æ‹©å¹¶è¿›å…¥è®¡ç®—")
    if submitted:
        selected_pal = edited_pal[edited_pal["é€‰æ‹©"]==True].copy()
        if len(selected_pal) == 0:
            st.warning("è¯·è‡³å°‘å‹¾é€‰ä¸€ä¸ªæ‰˜ç›˜å†ç‚¹å‡»ã€é”å®šé€‰æ‹©å¹¶è¿›å…¥è®¡ç®—ã€ã€‚")
            st.stop()
        # é”å®šé€‰æ‹© + ä¿å­˜ä¸€æ¬¡å…¨è¡¨å¿«ç…§ï¼ˆå«â€œé€‰æ‹©â€åˆ—ç½®é¡¶çš„è§†å›¾ï¼‰
        st.session_state.locked_df = selected_pal.reset_index(drop=True)
        st.session_state.all_snapshot_df = disp_df[cols_order].copy()  # â† æ–°å¢ï¼šç”¨é”å®šç¬é—´çš„å…¨é‡æ•°æ®åšå¿«ç…§
        st.session_state.sel_locked = True
        st.rerun()


# ========== è®¡ç®—é˜¶æ®µï¼ˆåŸºäºå·²é”å®šçš„é€‰æ‹©ï¼ŒåŒæ—¶æ˜¾ç¤ºæœªé”å®šçš„æ‰˜ç›˜ï¼‰==========
if st.session_state.sel_locked:
    st.success("âœ… å·²é”å®šæ‰˜ç›˜é€‰æ‹©")
    # æä¾›â€œé‡æ–°é€‰æ‹©â€
    if st.button("ğŸ”“ é‡æ–°é€‰æ‹©"):
        st.session_state.sel_locked = False
        st.session_state.locked_df = pd.DataFrame()
        st.rerun()

    # å·²é”å®šæ‰˜ç›˜
    selected_pal = st.session_state.locked_df.copy()
    # å…¶ä½™æœªé”å®šæ‰˜ç›˜ï¼ˆåªè¯»å±•ç¤ºï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œä¾èµ–ä¸Šæ–‡çš„ disp_df å’Œ cols_orderï¼ˆ["é€‰æ‹©"] + show_colsï¼‰
    locked_ids = set(selected_pal["æ‰˜ç›˜å·"].astype(str))
    others_df = disp_df[~disp_df["æ‰˜ç›˜å·"].astype(str).isin(locked_ids)].copy()
    # åªè¯»è¡¨é‡ŒæŠŠâ€œé€‰æ‹©â€åˆ—å›ºå®šä¸º Falseï¼ˆé¿å…è¯¯å¯¼ï¼‰
    if "é€‰æ‹©" in others_df.columns:
        others_df["é€‰æ‹©"] = False

    # ä¸¤å—å¹¶æ’å±•ç¤ºï¼šå·¦=å·²é”å®šï¼Œå³=æœªé”å®šï¼ˆåªè¯»ï¼‰
    left, right = st.columns([2, 2], gap="large")

    with left:
        st.markdown("**ğŸ“¦ å·²é”å®šæ‰˜ç›˜ï¼ˆç”¨äºè®¡ç®—ï¼‰**")
        st.dataframe(
            selected_pal[cols_order],
            use_container_width=True,
            height=320
        )
        st.caption(f"å·²é”å®šæ•°é‡ï¼š{len(selected_pal)}")

    with right:
        st.markdown("**ğŸ—‚ å…¶ä»–æ‰˜ç›˜ï¼ˆæœªé”å®šï¼Œä»…æŸ¥çœ‹ï¼‰**")
        st.dataframe(
            others_df[cols_order],
            use_container_width=True,
            height=320
        )
        st.caption(f"æœªé”å®šæ•°é‡ï¼š{len(others_df)}")

    # é€‰ä¸­æ•°é‡ & ä½“ç§¯åˆè®¡ï¼ˆåªç®—å·²é”å®šï¼‰
    sel_count = int(len(selected_pal))
    sel_vol_sum = pd.to_numeric(selected_pal.get("æ‰˜ç›˜ä½“ç§¯", pd.Series()), errors="coerce").sum()
    m1, m2 = st.columns(2)
    with m1: st.metric("å·²é€‰æ‹©æ‰˜ç›˜æ•°", sel_count)
    with m2: st.metric("é€‰ä¸­ä½“ç§¯åˆè®¡ï¼ˆCBMï¼‰", round(float(sel_vol_sum or 0.0), 2))

    if sel_count == 0:
        st.info("å½“å‰æ²¡æœ‰é”å®šçš„æ‰˜ç›˜ã€‚ç‚¹å‡»ã€é‡æ–°é€‰æ‹©ã€è¿”å›ã€‚")
        st.stop()

    # è½¦æ¬¡ä¿¡æ¯ï¼ˆåˆ†æ‘ŠæŒ‰â€œæ‰˜ç›˜é‡é‡â€ï¼‰â€”â€”ä»¥ä¸‹ä¿æŒä½ åŸé€»è¾‘
    st.subheader("ğŸ§¾ è½¦æ¬¡ä¿¡æ¯ï¼ˆæ‰˜ç›˜ç»´åº¦åˆ†æ‘Šï¼‰")
    cc1, cc2 = st.columns([2,2])
    with cc1:
        pallet_truck_no = st.text_input("å¡è½¦å•å·ï¼ˆå¿…å¡«ï¼‰", key="pallet_truck_no")
    with cc2:
        pallet_total_cost = st.number_input("æœ¬è½¦æ€»è´¹ç”¨ï¼ˆå¿…å¡«ï¼‰", min_value=0.0, step=1.0, format="%.2f", key="pallet_total_cost")

    if not pallet_truck_no or pallet_total_cost <= 0:
        st.info("è¯·å¡«å†™å¡è½¦å•å·ä¸æœ¬è½¦æ€»è´¹ç”¨ã€‚")
        st.stop()

    # åˆ†æ‘Šè®¡ç®—ï¼ˆæŒ‰æ‰˜ç›˜é‡é‡ï¼‰
    selected_pal["æ‰˜ç›˜é‡é‡"] = pd.to_numeric(selected_pal["æ‰˜ç›˜é‡é‡"], errors="coerce")
    weights = selected_pal["æ‰˜ç›˜é‡é‡"]
    if weights.isna().any() or (weights.dropna() <= 0).any():
        st.error("æ‰€é€‰æ‰˜ç›˜å­˜åœ¨ç¼ºå¤±æˆ–éæ­£çš„ã€æ‰˜ç›˜é‡é‡ã€ï¼Œæ— æ³•åˆ†æ‘Šã€‚è¯·å…ˆåœ¨ã€æ‰˜ç›˜æ˜ç»†è¡¨ã€ä¿®æ­£ã€‚")
        st.stop()

    wt_sum = float(weights.sum())
    if wt_sum <= 0:
        st.error("æ€»æ‰˜ç›˜é‡é‡ä¸º 0ï¼Œæ— æ³•åˆ†æ‘Šã€‚")
        st.stop()

    selected_pal["åˆ†æ‘Šæ¯”ä¾‹"] = weights / wt_sum
    selected_pal["åˆ†æ‘Šè´¹ç”¨_raw"] = selected_pal["åˆ†æ‘Šæ¯”ä¾‹"] * float(pallet_total_cost)
    selected_pal["åˆ†æ‘Šè´¹ç”¨"] = selected_pal["åˆ†æ‘Šè´¹ç”¨_raw"].round(2)
    diff_cost = round(float(pallet_total_cost) - selected_pal["åˆ†æ‘Šè´¹ç”¨"].sum(), 2)
    if abs(diff_cost) >= 0.01:
        selected_pal.loc[selected_pal.index[-1], "åˆ†æ‘Šè´¹ç”¨"] += diff_cost

    upload_df = selected_pal.copy()
    upload_df["å¡è½¦å•å·"] = pallet_truck_no
    upload_df["æ€»è´¹ç”¨"] = round(float(pallet_total_cost), 2)
    upload_df["åˆ†æ‘Šæ¯”ä¾‹"] = (upload_df["åˆ†æ‘Šæ¯”ä¾‹"]*100).round(2).astype(str) + "%"
    upload_df["åˆ†æ‘Šè´¹ç”¨"] = upload_df["åˆ†æ‘Šè´¹ç”¨"].map(lambda x: f"{x:.2f}")
    upload_df["æ€»è´¹ç”¨"] = upload_df["æ€»è´¹ç”¨"].map(lambda x: f"{x:.2f}")
    upload_df["æ‰˜ç›˜ä½“ç§¯"] = pd.to_numeric(upload_df.get("æ‰˜ç›˜ä½“ç§¯", pd.Series()), errors="coerce").round(2)

    preview_cols_pal = [
        "å¡è½¦å•å·","ä»“åº“ä»£ç ","æ‰˜ç›˜å·","æ‰˜ç›˜é‡é‡","é•¿(in)","å®½(in)","é«˜(in)","æ‰˜ç›˜ä½“ç§¯",
        "è¿å•æ•°é‡","è¿å•æ¸…å•",
        "å¯¹å®¢æ‰¿è¯ºé€ä»“æ—¶é—´","é€ä»“æ—¶æ®µå·®å€¼(å¤©)",
        "ETA/ATA(æŒ‰è¿å•)","ETD/ATD(æŒ‰è¿å•)",
        "åˆ†æ‘Šæ¯”ä¾‹","åˆ†æ‘Šè´¹ç”¨","æ€»è´¹ç”¨"
    ]
    for c in preview_cols_pal:
        if c not in upload_df.columns:
            upload_df[c] = ""

    st.subheader("âœ… ä¸Šä¼ é¢„è§ˆï¼ˆæ‰˜ç›˜ â†’ å‘è´§è¿½è¸ªï¼‰")
    st.dataframe(upload_df[preview_cols_pal], use_container_width=True, height=360)

    st.markdown("""
    **åˆ†æ‘Šæ¯”ä¾‹è®¡ç®—å…¬å¼ï¼š** æ¯ä¸ªæ‰˜ç›˜çš„åˆ†æ‘Šæ¯”ä¾‹ = è¯¥æ‰˜ç›˜é‡é‡ Ã· æ‰€æœ‰é€‰ä¸­æ‰˜ç›˜é‡é‡æ€»å’Œ  
    **åˆ†æ‘Šè´¹ç”¨è®¡ç®—å…¬å¼ï¼š** æ¯ä¸ªæ‰˜ç›˜çš„åˆ†æ‘Šè´¹ç”¨ = åˆ†æ‘Šæ¯”ä¾‹ Ã— æœ¬è½¦æ€»è´¹ç”¨  
    ï¼ˆæœ€åä¸€æ‰˜ç›˜è‡ªåŠ¨è°ƒæ•´å‡ åˆ†é’±å·®é¢ï¼Œç¡®ä¿æ€»é¢=æœ¬è½¦æ€»è´¹ç”¨ï¼‰
    """)


    # ä¸Šä¼ æŒ‰é’®ï¼ˆåŸé€»è¾‘ä¿æŒï¼‰
    if st.button("ğŸ“¤ è¿½åŠ ä¸Šä¼ åˆ°ã€å‘è´§è¿½è¸ªã€", key="btn_upload_pallet"):
        try:
            ss = client.open(SHEET_SHIP_TRACKING); ws_track = ss.sheet1
        except SpreadsheetNotFound:
            st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_SHIP_TRACKING}ã€ã€‚è¯·å…ˆåœ¨ Google Drive ä¸­åˆ›å»ºï¼Œå¹¶è®¾ç½®ç¬¬ä¸€è¡Œè¡¨å¤´ã€‚")
            st.stop()

        exist = ws_track.get_all_values()
        if not exist:
            st.error("ç›®æ ‡è¡¨ä¸ºç©ºä¸”æ— è¡¨å¤´ã€‚è¯·å…ˆåœ¨ç¬¬ä¸€è¡Œå†™å¥½è¡¨å¤´ï¼ˆæ ‡é¢˜è¡Œï¼‰ã€‚")
            st.stop()

        header_raw = exist[0]
        header_norm = _norm_header(header_raw)
        header_norm_lower = [h.lower() for h in header_norm]
        need_ok = any(n in header_norm for n in ["æ‰˜ç›˜å·","æ‰˜ç›˜ç¼–å·"]) or \
                any(n in header_norm_lower for n in ["palletid","palletno","palletç¼–å·"])
        if not need_ok:
            st.error("ã€å‘è´§è¿½è¸ªã€ç¼ºå°‘â€œæ‰˜ç›˜å·â€åˆ—ï¼ˆæˆ–ç­‰ä»·åˆ—å¦‚ PalletID/PalletNoï¼‰ã€‚è¯·å…ˆåœ¨ç›®æ ‡è¡¨å¢åŠ è¯¥åˆ—ã€‚")
            st.stop()

        tmp = upload_df.copy()
        if ("æ—¥æœŸ" in header_raw) and ("æ—¥æœŸ" not in tmp.columns):
            tmp["æ—¥æœŸ"] = datetime.today().strftime("%Y-%m-%d")

        for col in header_raw:
            if col not in tmp.columns:
                tmp[col] = ""
        rows = tmp.reindex(columns=header_raw).fillna("").values.tolist()

        ws_track.append_rows(rows, value_input_option="USER_ENTERED")

        st.success(f"å·²ä¸Šä¼  {len(rows)} æ¡åˆ°ã€{SHEET_SHIP_TRACKING}ã€ã€‚å¡è½¦å•å·ï¼š{pallet_truck_no}")

        try:
            st.info("æ­£åœ¨æ›´æ–°ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ï¼ˆåªå«ã€å‘è´§è¿½è¸ªã€é‡Œçš„è¿å•ï¼›ä»…æ›´æ–°æŒ‡å®šåˆ—ï¼‰â€¦")
            df_delta = build_waybill_delta()
            if df_delta.empty:
                st.warning("æ²¡æœ‰å¯æ›´æ–°çš„æ•°æ®ï¼ˆæ£€æŸ¥åˆ°ä»“/å‘è´§/è‡ªæè¡¨ï¼‰ã€‚")
            else:
                ok = upsert_waybill_summary_partial(df_delta)
                if ok:
                    st.success(f"å·²æ›´æ–°/æ–°å¢ {len(df_delta)} æ¡åˆ°ã€{SHEET_WB_SUMMARY}ã€ã€‚")
                else:
                    st.warning("æœªèƒ½å†™å…¥ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€ï¼šè¯·å…ˆåˆ›å»ºè¯¥è¡¨å¹¶ç¡®ä¿é¦–è¡ŒåŒ…å«â€œè¿å•å·â€åˆ—ã€‚")
        except Exception as e:
            st.warning(f"æ›´æ–°ã€è¿å•å…¨é“¾è·¯æ±‡æ€»ã€å¤±è´¥ï¼š{e}")

        # ä»…åœ¨ä¸Šä¼ æˆåŠŸåæ¸…ç¼“å­˜/è§£é”ï¼Œé¿å…æ“ä½œä¸­æ–­å¯¼è‡´çš„åˆ·æ–°
        st.cache_data.clear()
        st.session_state.sel_locked = False
        st.session_state.locked_df = pd.DataFrame()
        st.session_state.pop("pallet_select_editor", None)
        st.rerun()
# ----------------------- é€‰æ‹©ä¸è®¡ç®—ç‰‡æ®µç»“æŸ -----------------------

