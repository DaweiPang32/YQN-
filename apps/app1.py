# ship_app.py  â€”â€” å‘è´§è°ƒåº¦ï¼ˆæ— â€œæ‰¹æ¬¡â€ç»´åº¦ï¼‰
import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from gspread.exceptions import SpreadsheetNotFound
from datetime import datetime, timedelta

SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

def get_gspread_client():
    # 1) Cloudï¼šä¼˜å…ˆä» st.secrets è¯»å–ï¼ˆStreamlit Cloud é…ç½®çš„æœºå¯†ï¼‰
    if "gcp_service_account" in st.secrets:
        sa_info = st.secrets["gcp_service_account"]  # è¿™æ˜¯ä¸€ä¸ª dictï¼ˆæˆ‘ä»¬ç¨ååœ¨ Cloud é‡Œé…ç½®ï¼‰
        creds = Credentials.from_service_account_info(sa_info, scopes=SCOPES)
        return gspread.authorize(creds)
    # 2) æœ¬åœ°ï¼šå…¼å®¹ä½ åŸæ¥çš„ JSON æ–‡ä»¶
    else:
        creds = Credentials.from_service_account_file("service_accounts.json", scopes=SCOPES)
        return gspread.authorize(creds)

client = get_gspread_client()


# ========= è¡¨åé…ç½® =========
SHEET_ARRIVALS_NAME = "åˆ°ä»“æ•°æ®è¡¨"
SHEET_BOL_NAME = "BOLè‡ªæ"
SHEET_SHIP_DETAIL = "bolè‡ªææ˜ç»†"   # ä»…è¿½åŠ å†™å…¥ï¼Œä¸è¦†ç›–æ ‡é¢˜

# ========= å·¥å…·å‡½æ•° =========
def excel_serial_to_date(val):
    try:
        f = float(val)
        return datetime(1899, 12, 30) + timedelta(days=f)
    except Exception:
        return pd.NaT

@st.cache_data(ttl=60)
def load_bol_df():
    """è¯»å– BOLè‡ªæï¼›ä»¥æœªæ ¼å¼åŒ–å€¼è·å–ï¼Œæ—¥æœŸæŒ‰åºåˆ—å·è§£æ"""
    ws = client.open(SHEET_BOL_NAME).sheet1
    data = ws.get_all_values(
        value_render_option="UNFORMATTED_VALUE",
        date_time_render_option="SERIAL_NUMBER"
    )
    if not data:
        return pd.DataFrame()
    header = [h.replace("\u00A0", " ").replace("\n", "").strip() for h in data[0]]
    df = pd.DataFrame(data[1:], columns=header)

    # éœ€è¦å­—æ®µï¼šè¿å•å· / å®¢æˆ·å•å· / ETA(åˆ°BCF)
    for need in ["è¿å•å·", "å®¢æˆ·å•å·", "ETA(åˆ°BCF)"]:
        if need not in df.columns:
            df[need] = pd.NA

    df["è¿å•å·"] = df["è¿å•å·"].astype(str).str.strip()
    df = df.drop_duplicates(subset=["è¿å•å·"])

    parsed_serial = df["ETA(åˆ°BCF)"].apply(excel_serial_to_date)
    fallback = pd.to_datetime(df["ETA(åˆ°BCF)"], errors="coerce")
    df["ETA(åˆ°BCF)"] = parsed_serial.combine_first(fallback)

    return df[["è¿å•å·", "å®¢æˆ·å•å·", "ETA(åˆ°BCF)"]]

@st.cache_data(ttl=60)
def load_arrivals_df():
    """è¯»å– åˆ°ä»“æ•°æ®è¡¨ï¼›éœ€è¦ ä»“åº“ä»£ç  / è¿å•å· / æ”¶è´¹é‡"""
    ws = client.open(SHEET_ARRIVALS_NAME).sheet1
    data = ws.get_all_values()
    if not data:
        return pd.DataFrame()
    header = [h.replace("\u00A0", " ").replace("\n", "").replace(" ", "") for h in data[0]]
    df = pd.DataFrame(data[1:], columns=header)

    for need in ["è¿å•å·", "ä»“åº“ä»£ç ", "æ”¶è´¹é‡"]:
        if need not in df.columns:
            df[need] = pd.NA

    df["è¿å•å·"] = df["è¿å•å·"].astype(str).str.strip()
    df = df.drop_duplicates(subset=["è¿å•å·"])
    df["æ”¶è´¹é‡"] = pd.to_numeric(df["æ”¶è´¹é‡"], errors="coerce")
    return df[["ä»“åº“ä»£ç ", "è¿å•å·", "æ”¶è´¹é‡"]]

@st.cache_data(ttl=60)
def load_shipped_waybills():
    """è¯»å– bolè‡ªææ˜ç»† å·²ä¸Šä¼ çš„è¿å•å·é›†åˆï¼›åŸºäºç°æœ‰è¡¨å¤´å®šä½åˆ—"""
    try:
        ss = client.open(SHEET_SHIP_DETAIL)
        ws = ss.sheet1
    except SpreadsheetNotFound:
        return set()
    vals = ws.get_all_values()
    if not vals:
        return set()
    header = vals[0]
    rows = vals[1:]
    if "è¿å•å·" not in header:
        return set()
    idx = header.index("è¿å•å·")
    out = set()
    for r in rows:
        if len(r) > idx:
            wb = str(r[idx]).strip()
            if wb:
                out.add(wb)
    return out

# ========= é¡µé¢è®¾ç½® =========
st.set_page_config(page_title="å‘è´§è°ƒåº¦å¹³å°", layout="wide")
st.title("ğŸšš BCF å‘è´§è°ƒåº¦")

# ========= åˆ·æ–°ç¼“å­˜ =========
left, right = st.columns([1,6])
with left:
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®ç¼“å­˜"):
        st.cache_data.clear()
        st.rerun()

# ========= æ•°æ®æºï¼ˆåˆå¹¶ï¼‰=========
arrivals_df = load_arrivals_df()
bol_df = load_bol_df()

if arrivals_df.empty and bol_df.empty:
    st.warning("æ²¡æœ‰ä» Google Sheets è¯»å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥è¡¨å/æƒé™ã€‚")
    st.stop()

merged = bol_df.merge(arrivals_df, on="è¿å•å·", how="left")
base_cols = ["ä»“åº“ä»£ç ", "è¿å•å·", "å®¢æˆ·å•å·", "ETA(åˆ°BCF)", "æ”¶è´¹é‡"]
for c in base_cols:
    if c not in merged.columns:
        merged[c] = pd.NA

# è¿‡æ»¤ï¼šä¸å±•ç¤ºå·²ä¸Šä¼ è¿‡çš„è¿å•
already = load_shipped_waybills()
if already:
    merged = merged[~merged["è¿å•å·"].astype(str).isin(already)]

# æ—¥æœŸç­›é€‰ï¼ˆæŒ‰ ETA(åˆ°BCF)ï¼‰
st.markdown("### ğŸ” ç­›é€‰")
merged["ETA(åˆ°BCF)"] = pd.to_datetime(merged["ETA(åˆ°BCF)"], errors="coerce")
valid = merged["ETA(åˆ°BCF)"].dropna()
if not valid.empty:
    min_d, max_d = valid.min().date(), valid.max().date()
    default_start = max(max_d - timedelta(days=14), min_d)
    start_date, end_date = st.date_input(
        "æŒ‰ ETA(åˆ°BCF) é€‰æ‹©æ—¥æœŸèŒƒå›´",
        value=(default_start, max_d),
        min_value=min_d, max_value=max_d
    )
    mask = merged["ETA(åˆ°BCF)"].between(pd.to_datetime(start_date), pd.to_datetime(end_date))
    filtered_base = merged[mask].copy()
else:
    st.info("æœªæ£€æµ‹åˆ°å¯è§£æçš„ ETA(åˆ°BCF)ï¼›å°†å±•ç¤ºå…¨éƒ¨ã€‚")
    filtered_base = merged.copy()

# ä»“åº“ç­›é€‰ï¼ˆå¯é€‰ï¼‰
wh_options = filtered_base["ä»“åº“ä»£ç "].dropna().unique()
warehouse = st.selectbox("é€‰æ‹©ä»“åº“ä»£ç ï¼ˆå¯é€‰ï¼‰", options=["ï¼ˆå…¨éƒ¨ï¼‰"] + list(wh_options))
if warehouse != "ï¼ˆå…¨éƒ¨ï¼‰":
    filtered_base = filtered_base[filtered_base["ä»“åº“ä»£ç "] == warehouse]

# ========= è¡¨æ ¼å†…å‹¾é€‰ =========
st.markdown("### ğŸ“‹ å‹¾é€‰è¦å‘å¾€BCFçš„è¿å•å·ï¼ˆæ”¯æŒå¤šé€‰ï¼‰")
table = filtered_base[base_cols].sort_values(by=["ETA(åˆ°BCF)", "è¿å•å·"], na_position="last").reset_index(drop=True)
table["é€‰æ‹©"] = False
edited = st.data_editor(
    table,
    hide_index=True,
    use_container_width=True,
    height=380,
    column_config={
        "é€‰æ‹©": st.column_config.CheckboxColumn("é€‰æ‹©"),
        "ETA(åˆ°BCF)": st.column_config.DatetimeColumn("ETA(åˆ°BCF)", format="YYYY-MM-DD")
    },
    disabled=["ä»“åº“ä»£ç ", "è¿å•å·", "å®¢æˆ·å•å·", "ETA(åˆ°BCF)", "æ”¶è´¹é‡"],
    key="ship_select_editor"
)
selected = edited[edited["é€‰æ‹©"] == True].copy()
st.caption(f"å·²é€‰æ‹© {len(selected)} æ¡")
if selected.empty:
    st.stop()

# ========= å½•å…¥å¡è½¦ä¿¡æ¯ & è´¹ç”¨ =========
st.markdown("### ğŸ§¾ è½¦æ¬¡ä¿¡æ¯")
c1, c2 = st.columns([2,2])
with c1:
    truck_no = st.text_input("å¡è½¦å•å·ï¼ˆå¿…å¡«ï¼‰")
with c2:
    total_cost = st.number_input("æœ¬è½¦æ€»è´¹ç”¨ï¼ˆå¿…å¡«ï¼‰", min_value=0.0, step=1.0, format="%.2f")

if not truck_no or total_cost <= 0:
    st.info("è¯·å¡«å†™å¡è½¦å•å·ä¸æœ¬è½¦æ€»è´¹ç”¨ã€‚")
    st.stop()

# ========= è´¹ç”¨åˆ†æ‘Šï¼ˆæŒ‰æ”¶è´¹é‡ï¼‰=========
if selected["æ”¶è´¹é‡"].isna().any() or (selected["æ”¶è´¹é‡"] <= 0).any():
    st.error("æ‰€é€‰è¿å•å­˜åœ¨ç¼ºå¤±æˆ–éæ­£çš„ã€æ”¶è´¹é‡ã€ï¼Œæ— æ³•åˆ†æ‘Šã€‚è¯·å…ˆåœ¨ã€åˆ°ä»“æ•°æ®è¡¨ã€ä¿®æ­£ã€‚")
    st.stop()

sum_wt = selected["æ”¶è´¹é‡"].sum()
if sum_wt <= 0:
    st.error("æ€»æ”¶è´¹é‡ä¸º 0ï¼Œæ— æ³•åˆ†æ‘Šã€‚")
    st.stop()

selected["åˆ†æ‘Šæ¯”ä¾‹"] = selected["æ”¶è´¹é‡"] / sum_wt
selected["åˆ†æ‘Šè´¹ç”¨_raw"] = selected["åˆ†æ‘Šæ¯”ä¾‹"] * total_cost
selected["åˆ†æ‘Šè´¹ç”¨"] = selected["åˆ†æ‘Šè´¹ç”¨_raw"].round(2)
diff = round(total_cost - selected["åˆ†æ‘Šè´¹ç”¨"].sum(), 2)
if abs(diff) >= 0.01:
    selected.loc[selected.index[-1], "åˆ†æ‘Šè´¹ç”¨"] += diff

# ========= ç”Ÿæˆå¾…ä¸Šä¼ æ•°æ®ï¼ˆæ— â€œæ‰¹æ¬¡â€ç»´åº¦ï¼›ä¸å¼ºåˆ¶å†™æ—¥æœŸï¼‰=========
out_df = selected.copy()
out_df["å¡è½¦å•å·"] = truck_no
out_df["æ€»è´¹ç”¨"] = round(float(total_cost), 2)
out_df["ETA(åˆ°BCF)"] = pd.to_datetime(out_df["ETA(åˆ°BCF)"], errors="coerce").dt.strftime("%Y-%m-%d").fillna("")
out_df["åˆ†æ‘Šæ¯”ä¾‹"] = (out_df["åˆ†æ‘Šæ¯”ä¾‹"] * 100).round(2).astype(str) + "%"
out_df["åˆ†æ‘Šè´¹ç”¨"] = out_df["åˆ†æ‘Šè´¹ç”¨"].map(lambda x: f"{x:.2f}")
out_df["æ€»è´¹ç”¨"] = out_df["æ€»è´¹ç”¨"].map(lambda x: f"{x:.2f}")

# é¢„è§ˆï¼ˆæˆ‘ä»¬ç†æƒ³å±•ç¤ºåˆ—ï¼‰
preview_cols = [
    "å¡è½¦å•å·", "ä»“åº“ä»£ç ", "è¿å•å·", "å®¢æˆ·å•å·",
    "ETA(åˆ°BCF)", "æ”¶è´¹é‡", "åˆ†æ‘Šæ¯”ä¾‹", "åˆ†æ‘Šè´¹ç”¨", "æ€»è´¹ç”¨"
]
for c in preview_cols:
    if c not in out_df.columns:
        out_df[c] = ""

st.markdown("### âœ… ä¸Šä¼ é¢„è§ˆ")
st.dataframe(out_df[preview_cols], use_container_width=True, height=280)

# ========= åªè¿½åŠ ä¸Šä¼ ï¼ˆæŒ‰ç°æœ‰è¡¨å¤´å¯¹é½ï¼Œç»ä¸è¦†ç›–æ ‡é¢˜ï¼‰=========
if st.button("ğŸ“¤ è¿½åŠ ä¸Šä¼ åˆ°ã€bolè‡ªææ˜ç»†ã€"):
    try:
        ss = client.open(SHEET_SHIP_DETAIL)
        ship_sheet = ss.sheet1
    except SpreadsheetNotFound:
        st.error(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ã€Œ{SHEET_SHIP_DETAIL}ã€ã€‚è¯·å…ˆåœ¨ Google Drive ä¸­åˆ›å»ºï¼Œå¹¶è®¾ç½®ç¬¬ä¸€è¡Œè¡¨å¤´ã€‚")
        st.stop()

    existing = ship_sheet.get_all_values()
    if not existing:
        st.error("ç›®æ ‡è¡¨ä¸ºç©ºä¸”æ— è¡¨å¤´ã€‚è¯·å…ˆåœ¨ç¬¬ä¸€è¡Œå†™å¥½è¡¨å¤´ï¼ˆæ ‡é¢˜è¡Œï¼‰ï¼Œæˆ‘åªä¼šæŒ‰ç°æœ‰è¡¨å¤´çš„å­—æ®µé¡ºåºè¿½åŠ æ•°æ®ã€‚")
        st.stop()

    existing_header = existing[0]
    tmp = out_df.copy()

    # ä»…å½“ç°æœ‰è¡¨å¤´é‡ŒåŒ…å«â€œæ—¥æœŸâ€æ—¶ï¼Œæ‰è¡¥å†™ä»Šå¤©æ—¥æœŸï¼›å¦åˆ™ä¸å†™
    if "æ—¥æœŸ" in existing_header and "æ—¥æœŸ" not in tmp.columns:
        tmp["æ—¥æœŸ"] = datetime.today().strftime("%Y-%m-%d")

    # æŒ‰ç°æœ‰è¡¨å¤´é¡ºåºå¯¹é½ï¼›ç¼ºå¤±åˆ—è¡¥ç©ºï¼Œå¤šä½™åˆ—å¿½ç•¥
    for col in existing_header:
        if col not in tmp.columns:
            tmp[col] = ""
    rows = tmp.reindex(columns=existing_header).fillna("").values.tolist()

    ship_sheet.append_rows(rows, value_input_option="USER_ENTERED")

    st.success(f"å·²ä¸Šä¼  {len(rows)} æ¡åˆ°ã€{SHEET_SHIP_DETAIL}ã€ã€‚å¡è½¦å•å·ï¼š{truck_no}")

    # ä¸Šä¼ åï¼šæ¸…ç¼“å­˜ + æ¸…é™¤å‹¾é€‰çŠ¶æ€ + ç«‹åˆ»åˆ·æ–°ï¼ˆå·²ä¸Šä¼ çš„å•ä¸å†å‡ºç°ï¼‰
    st.cache_data.clear()
    st.session_state.pop("ship_select_editor", None)
    st.rerun()
